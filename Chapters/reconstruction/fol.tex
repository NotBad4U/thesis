%*****************************************
\chapter{Reconstructing FOL proofs}\label{ch:reconstruction-ul}
%*****************************************

\section{Tautologous rules and simple deduction}
\label{sec:elem-rules}

\begin{figure}[t]
  \scriptsize
  \begin{tabular}{@{}l|l@{}}
  \hline
  \multicolumn{2}{|l|}{R = \kw{assume}} \\ \hline
  \\
  $i.~\Gamma~\triangleright~ \varphi \quad (R)[]$  & $i : \pid (\E{\varphi} \veedot \nil)$  \\
  \\
  \hline
  \multicolumn{2}{|l|}{R = \kw{equiv\_pos2}} \\ \hline
  \\
  $i.~\Gamma~\triangleright~ \neg (a \approx b), \neg a, b  \quad (R)[]$  &
  $i : \begin{array}[t]{@{}l@{}}
          \pid (\neg (\E{a} = \E{b}) \veedot \neg \E{a} \veedot \E{a}  \veedot \nil) \\
          \coloneq \kw{apply}~\kw{equiv\_pos2}
       \end{array}$ \\
  \hline

  \multicolumn{2}{|l|}{R = \kw{cong}} \\ \hline
  \\
  $i_1 ~\quad \Gamma ~ \triangleright ~ t_1 \approx u_1 \quad (\dots) $   \\
  $i_2 ~\quad \Gamma ~ \triangleright ~ t_2 \approx u_2 \quad (\dots) $  \\
  \qquad \vdots  & \\
  $i_n. \quad \Gamma ~ \triangleright ~ t_n \approx u_n \quad (\dots)$  &  \\
  $j. ~\quad \Gamma ~ \triangleright~
      \begin{array}[t]{@{}l@{}}
          (f~t_1 \dots t_n) \approx (f~u_1 \dots u_n)\\
          (R~i_1~i_2 ~..~ i_n)[]
      \end{array}$ &
  $j : \begin{array}[t]{@{}l@{}}
        \pid (\E{f~t_1 \dots t_n} = \E{f~u_1 \dots u_n} \veedot \nil) \\
        \coloneq \kw{apply}~(\kw{cong}_n~f~\pid_l(i_1) \dots \pid_l(i_n)))
       \end{array}$
  \end{tabular}
  \caption{Translations for three representative Alethe commands.}
  \label{fig:fun-c}
\end{figure}


Many Alethe rules introduce tautologies or derive their conclusion from a single premise.
%
These rules are primarily used for clausification and to simplify Boolean connectives during
preprocessing.
%
\cref{fig:fun-c} illustrates the definition of $\cal{C}$ for the rules \kw{assume}, \kw{equiv\_pos2} and \kw{cong} from the running example of \cref{lst:smtexampleinput-fol}.
The definitions use the following lemmas proved in our Lambdapi encoding:
\begin{itemize}
\item $\kw{cong}_1 :
    \begin{array}[t]{@{}l@{}}
        \Pi (a\,b \colon \set),\ \Pi f \colon \el\,a \ra \el\,b, \\
        \Pi x\,x',\ \prf (x = x') \ra \prf (f\,x = f\,x'),
    \end{array}$
\item $\kw{equiv\_pos2} : \Pi (\varphi_1~\varphi_2: \prop),\ \pid (\neg (\varphi_1 = \varphi_2) \veedot \neg \varphi_1 \veedot \varphi_2 \veedot \nil )$,
% \item $\pid_l : \Pi [a : \set],\ \pid (a \veedot \nil) \ra \prf a$.
\end{itemize}\todo{cong might move due to nary-function, so no more details here}



\paragraph{resolution rule}

\begin{figure}[t]
  \centering
  \begin{tabular}{l c r}
  $i_1.~\triangleright$  & \qquad $l_1^1,\, \dots,\, l_{k^1}^1$ \qquad & (\dots)  \\
  $i_n.~\triangleright$  & \qquad $l_1^n,\, \dots,\, l_{k^n}^n$ \qquad & (\dots) \\
    & \vdots  &  \\
  $j.~~\triangleright$  & \qquad $l_{s_1}^{r_1},\, \dots,\, l_{s_m}^{r_m}$ \qquad & $(\kw{resolution}~i_1 \dots i_n)[]$
  \end{tabular}
  \caption{Resolution rule}
  \label{fig:resolution-rule}
\end{figure}

However, Alethe's \kw{resolution} rule, shown in \cref{fig:resolution-rule}, represents hyper-resolution applied to a set of ground first-order clauses $i_1 \dots i_n$,
where the resulting clause $l_{s_1}^{r_1} \dots l_{s_m}^{r_m}$ is obtained by a chain of predicate resolution steps that remove complementary literals from the input clauses, with double negations being removed implicitly.
For example, the formulas $\neg \neg \neg P$ and $\neg \neg P$ can serve as pivots during resolution.
The first formula is interpreted as $\neg P$ and the second as just $P$ to perform resolution steps.
Alethe allows resolution steps without providing the pivots; however, Carcara's elaborated proof incorporates the pivots as arguments in the resolution rule, eliminating the need for an additional intermediate step to search for the pivots in our translation to Lambdapi.
In addition, pivots may appear anywhere in a clause rather than just as the head literal.
To prove our resolution rule, we first establish a sequence of auxiliary lemmas.
Each lemma captures a structural property of disjunctions at the clause level,
and together they provide the tools needed for the final resolution argument.
We recall that clause of literals can be rewrite into disjunctions.

\begin{lemma}[Sublist disjunction]\label{lem:orN_subList}
Let $ps$ and $qs$ be two Clause and two index $i,j \in \mathbb{N}$. If
\[
\prfcl\bigl(ps\bigr)
\quad\text{and}\quad
\prf\bigl(ps = \mathrm{subclause}(qs,i,j)\bigr),
\]
then
\[
\prf\bigl(qs\bigr).
\]
Here $\mathrm{subclause}(qs,i,j)$ abbreviates $\mathrm{drop}~i~\bigl(\mathrm{take}~j~qs\bigr)$ which take the part of the clause $qs$ between positions $i$ and $j-1$.
So the result is simply the slice of $qs$ starting at index  $i$ and ending right before $j$.
\begin{proof}
The proof proceeds by structural induction on $qs$.
\begin{itemize}
  \item[] Case $qs=\nil$, the second premise forces $ps=\nil$; hence the hypothesis $\prfcl(ps)$ is $\prf(\bot)$, thus the goal follows immediately by \emph{ex falso quodlibet}.
  \item[] Case $qs=t \veedot \ell$ with the induction hypothesis saying that for every clause $xs$ and every pair of indices $n,m$, if $\prfcl(xs)$ and $xs$ is equal to the subclause of $\ell$ from position $n$ up to $m$, then $\prfcl(\ell)$.
    Now we must show that:
    \[
        \prfcl (t \veedot \ell).
    \]
    We reasons by cases on the index $j$ and then $i$.
    \begin{itemize}
      \item For $j=0$ we have $\mathrm{take}\,0\,(t \veedot \ell)=\nil$, hence the subclause $ps$ of $qs$ is empty i.e. $ps = \nil$.
      Similar to the previous case, the hypothesis $\prfcl(ps)$ is $\prf(\bot)$, thus the goal follows immediately by \emph{ex falso quodlibet}.

      \item When $j > 0$ we then analyze $i$.
        \begin{itemize}
          \item If $i=0$, then
            \[
              \mathrm{subclause}(t \veedot \ell,0,j{+}1)= t \veedot \mathrm{subclause}(\ell,0,j).
            \]
            and the equality hypothesis yields
            \[
              \prfcl\bigl(p = t \veedot \mathrm{take}\,j\,\ell\bigr).
            \]
            Thus, there are two subcases to consider.
            When $\prf(t)$ holds, we immediately obtain $\prfcl(t \veedot \ell)$ by left introduction.
            Otherwise, $\prfcl(\mathrm{take}\,j\,\ell)$ holds; by the induction hypothesis we lift provability to $\prfcl(\ell)$, and then conclude $\prfcl(t \veedot \ell)$ by right introduction.
          \item If $i > 0$, we peel one element from both $\mathrm{drop}$ and $qs$.
            So the hypothesis specializes to $ps=\mathrm{subclause}(\ell,i,j)$, and the desired claim follows from the induction hypothesis on $\ell$.
          \end{itemize}
    \end{itemize}
  In all cases we infer $\prfcl(qs)$, as required.
\end{itemize}
\end{proof}
\end{lemma}

The next two lemmas show that provability is stable under appending clauses on either side.
These capture the monotonicity of disjunction ($\veedot$) with respect to clause concatenation.

\begin{lemma}[Append preserves right disjunct]\label{lem:orN_append_right}
Let $ps,qs$ two clauses. If $\prfcl(qs)$ then also $\prfcl(ps \concat qs)$.
\begin{proof}
The clause $qs$ appears as a subclause of $ps \concat qs$, starting at position $\mathrm{size}(ps)$.
By Lemma~\ref{lem:orN_subList}, provability of the disjunction of a subclause lifts to provability of the whole clause.
Therefore from $\prfcl(qs)$ we conclude $\prfcl(ps \concat qs)$.

Concretely, if
\[
  qs = q_1 \veedot q_2 \veedot \cdots \veedot q_m,
\]
then
\[
  (ps \concat qs) = p_1 \veedot \cdots \veedot p_n \veedot q_1 \veedot \cdots \veedot q_m.
\]
Since $q_1 \veedot \cdots \veedot q_m$ is provable, the longer disjunction that includes all the $p_i$ as additional disjuncts is also provable.
This captures the monotonicity of $\veedot$ under extension of the clause.
\end{proof}
\end{lemma}

\begin{lemma}[Append preserves right disjunct]\label{lem:orN_append_left}
Let $ps,qs$ two clauses. If $\prfcl(ps)$, then also $\prfcl(ps \concat qs)$.
\begin{proof}
The proof follows analogously to that of \cref{lem:orN_append_right}.
\end{proof}
\end{lemma}

The final auxiliary lemma explains how a clause can be decomposed into the disjunction
of any chosen literal and the clause obtained by removing it.

\begin{lemma}[Remove disjunction]\label{lem:orN_remove}
Let $qs$ be a clause and an index $j$ with the condition that $j < \mathrm{size}(qs)$. Then
\[
  \prf\Bigl((qs[j] \veedot \kw{remove}(qs,j)) = qs\Bigr).
\]
Here $(\kw{remove}~qs~j)$ denotes the clause $qs$ with its $j$-th literal removed, and
$qs[j]$ denotes the $j$-th literal of $qs$ (with $\bot$ as default if $j$ is out of bounds).
\begin{proof}
We proceed by induction on the structure of $qs$.

\begin{itemize}
  \item[] Case $qs=\nil$.  The assumption $j < \mathrm{size}(qs)$ cannot hold, so this case is impossible.

  \item[] Case $qs= t \veedot \ell$. We must show that:
  \[
    \prf((t \veedot \kw{remove}(t \veedot \ell,j) = t \veedot \ell).
  \]
  We distinguish two subcases according to $j$.
  \begin{itemize}
    \item If $j=0$, then $\kw{remove}(qs,0)=\ell$ and $qs[0]=t$.
    Removing the head element $t$ and then reintroducing it yields the same clause.
    Hence the equality holds immediately.
    \item If $j>0$, then we have the identities
      \[
        \kw{remove}(t \veedot \ell,j) = t \veedot \kw{remove}(\ell,j-1)\\
        (t \veedot \ell)[j] = \ell[j-1].
      \]
      By the induction hypothesis applied to $\ell$ at index $j-1$, we know that
      \[
        \prf\bigl(\,\ell[j-1] \veedot \kw{remove}(\ell,j-1) = \ell\,\bigr).
      \]
      Combining this with the identities above, we obtain
      \[
        \prf\bigl(\,t \veedot \kw{remove}(t \veedot \ell,j) = t \veedot \ell\,\bigr),
      \]
      as required.
  \end{itemize}
\end{itemize}
In all cases we obtain the desired equality
\end{proof}
\end{lemma}

With these lemmas in hand, we are ready to state and prove the main resolution rule.

\begin{theorem}[Resolution]
Let $ps$ and $qs$ be two clauses such that $\prfcl(ps)$ and $\prfcl(qs)$ hold.
Suppose $i < (\mathrm{size} ps)$ and $j < (\mathrm{size} qs)$, and assume that the $i$-th literal of $ps$ is the negation of the $j$-th literal of $qs$.
Then the clause obtained by removing these two complementary literals and  concatenating the remaining parts of $ps$ and $qs$ is also provable, that is:
\[
\begin{array}{l}
  \tt{resolution}~(ps, qs : \tt{Clause})\; (i, j : \mathbb{N}) \\
  (hps : \prfcl(ps)) \\
  (hqs : \prfcl(qs)) \\
  (hi  : \prf(i < \tt{size} ps) \\
  (hj  : \prf(j < \tt{size} qs) \\
  (hij : \prf(ps[i] = \lnot(qs[j]))) \\
  : \prfcl((\tt{remove}~ps~i) \pp (\tt{remove}~qs~j))
\end{array}
\]
\begin{proof}
We reason by case analysis on the pivot literal truth.

\begin{itemize}
\item[] Case 1: \(\prf(ps[i])\).
  Then by the relation $ps[i] = \lnot ps[j]$, we immediately obtain $\prf(\lnot ps[j])$.
  But under this assumption and by a classical reasoning the $ps[j]$ is false.

  From \cref{lem:orN_remove} we know that
  \[
      ps = ps[i] \veedot \kw{remove}~ps~i\\
      qs = qs[j] \veedot \kw{remove}~qs~j
  \].
  Combining this with the fact that $qs[j]$ is false, we deduce $\prfcl(\kw{remove}(qs,j))$.
  Now observe that $\kw{remove}(qs,j)$ is appended on the right to $\kw{remove}(ps,i)$
  in the resolvent clause
  \[
    \kw{remove}(ps,i) \pp \kw{remove}(qs,j).
  \]
  By \cref{lem:orN_append_right}, whenever the right-hand clause is provable,
  appending it to any left-hand clause preserves provability.
  Therefore, applying the lemma with $ps =\kw{remove}~ps~i$ and $qs =\kw{remove}~qs~j$,
  we conclude
  \[
    \prfcl(\kw{remove}(ps,i) \pp \kw{remove}(qs,j)).
  \]
\item[] Case 2: \(\prf(\lnot ps[i])\). This case is analogous to the first, but uses \cref{lem:orN_append_left} instead.
\end{itemize}
\end{proof}
\end{theorem}


\begin{example}
  \cref{lst:smtexamplelambdapi} illustrates the result of our main function $\mathcal{C}$ applied to the first steps in the running example of \cref{lst:smtexampleinput-fol}.
  In the code below, all the \texttt{assume} commands (corresponding to the \texttt{assert}s of the input problem) are transformed into constants by~$\mathcal{C}$. A symbol without a definition is considered as an axiom.
  Each step is encoded as an \lpinline{opaque symbol} that represents a lemma. Splitting the proof into multiple lemmas is beneficial for larger proofs because it reduces Lambdapi's checking time for the proof.
\end{example}

\begin{lstlisting}[mathescape=true, caption={Trace from \cref{lst:smtexampleinput} encoded in Lambdapi.}, label={lst:smtexamplelambdapi}, language=Lambdapi]
symbol p2 ≔ p b;
symbol p4 ≔ p a = p b;
symbol p5 ≔ p a;
symbol a0 : Prf$\textcolor{purple}{\smash{^\bullet}}$ (p5 ⟇ ▩);
symbol a1 : Prf$\textcolor{purple}{\smash{^\bullet}}$ (a = b ⟇ ▩);
symbol a2 : Prf$\textcolor{purple}{\smash{^\bullet}}$ (¬ p b ⟇ ▩);
opaque symbol t1 : Prf$\textcolor{purple}{\smash{^\bullet}}$ ((¬ ((p_5 = p_2))) ⟇ (¬ (p_5)) ⟇ p_2 ⟇ ▩) ≔
begin apply equiv_pos2; end;

opaque symbol t2 : Prf$\textcolor{purple}{\smash{^\bullet}}$ (p_4 ⟇ ▩) ≔
begin apply ∨ᵢ₁; apply feq (p) (Prf$\textcolor{purple}{\smash{^\bullet}}$ₗ a1) end;

opaque symbol t3 : Prf$\textcolor{purple}{\smash{^\bullet}}$ (p_2 ⟇ ▩) ≔
begin
have t0_t1 : Prf$\textcolor{purple}{\smash{^\bullet}}$ ((¬ (p_5))  ⟇ p_2 ⟇ ▩) {
  apply resolution 0 0 t1 t2 ⊤ᵢ ⊤ᵢ (eq_refl _)
};
have t0_t1_a0 : Prf$\textcolor{purple}{\smash{^\bullet}}$ (p_2 ⟇ ▩) {
    apply resolution 0 0 t0_t1 a0 ⊤ᵢ ⊤ᵢ (eq_refl _)
}; refine t0_t1_a0;
end;

opaque symbol t4 : Prf$\textcolor{purple}{\smash{^\bullet}}$ ▩ ≔
begin
  apply resolution 0 0 a2 t3 ⊤ᵢ ⊤ᵢ (eq_refl _);
end;
\end{lstlisting}

\section{Simplification rules}

The Alethe format includes rules that encode operator-level simplifications typically performed by SMT solvers. \info{ac}{The introduction of Alethe will contain the description of RARE, so we do not need to introduce it here anymore}
A key challenge arises from the fact that the solver does not explicitly specify which transformations are applied, nor the order in which they are performed. This makes certain rules, such as \tt{or\_simplify}, difficult to certify.
For instance, the rule \texttt{or\_simplify}, presented in \cref{eqn:or-simp}, simplifies disjunctions by applying equivalence-preserving transformations repeatedly until a fixpoint is reached. Its general form is:

\begin{equation}\label{eqn:or-simp}
i. \quad \Gamma~\triangleright \quad l_1 \lor \dots \lor l_n ~ \approx \psi \quad \texttt{or\_simplify}
\end{equation}
where $\psi$ is the transformed term. The possible transformations are:
\begin{enumerate}
\item[(1)] $\bot \lor \dots \lor \bot \Rightarrow \bot$
\item[(2)] $l_1 \lor \dots \lor l_n \Rightarrow l_1' \lor \dots \lor l_m'$ where the right-hand side has some $\bot$ literals removed.
\item[(3)]  $l_1 \lor \dots \lor l_n \Rightarrow l_1' \lor \dots \lor l_m'$ where the right-hand side has some repeated literals removed.
\item[(4)] $l_1 \lor \dots \lor \top \lor \dots \lor l_n \Rightarrow \top$
\item[(5)] $l_1 \lor \dots \lor l_i \lor \dots \lor l_j \lor \dots \lor  l_n \Rightarrow \top$ where $l_i = \neg^{2p} x$, $l_j = \neg^{2q+1} x$.
\end{enumerate}
\info{ac}{reconstruction of or\_simplify need to be improve so I still prove not\_simplify only has example}

To manage these transformations, we leverage the RARE language provided by cvc5 \cite{rare}, which supports elaborated rewrite proofs.
As detailed in \cref{sec:rare-intro}, RARE generates explicit proof terms on demand, using built-in rewrite rules.
The RARE rule used and its arguments are made explicit in the \smtinline{:args} parameter of the rule $\kw{rare\_rewrite}$ in the proof trace.

However, in some cases, cvc5 may emit proof traces using the legacy simplification rules instead of RARE. In such situations, we reconstruct the simplification steps using tactic scripts, as detailed in \cref{ch:intro-lambdapi}.
These scripts enable us to approach a fixpoint-style interpretation.\question{ac}{is it enough to say "approach" the Fix?}

To illustrate this process, we describe how we reconstruct a step involving the \kw{not\_simplify} rule, summarized in \cref{fig:not-simplify} since it is simple than \kw{or\_simplify} rule.
Each transformation associated with this rule is implemented by a separate lemma e.g., \kw{not\_simplify1}, \kw{not\_simplify2}, etc. which are then tried sequentially on the current goal.

\begin{figure}
  \footnotesize
  \begin{tabular}{l|l}
  \hline
  \multicolumn{2}{|l|}{R = \kw{not\_simplify}} \\ \hline
  \\
  $i. \quad \Gamma~\triangleright \quad \neg \psi \approx \varphi \quad (\kw{not\_simplify})$ & $\C{i} = \pid (\neg \E{\psi} = \E{\varphi} \veedot \nil) $ \\
  $(1) \neg \neg \varphi \Rightarrow \varphi$ &  $\is$ \lpinline{eval not_simplify} \\
  $(2) \neg \bot \Rightarrow \top$  &   \\
  $(3) \neg \top \Rightarrow \bot$  &
  \end{tabular}
  \caption{Translating the command \kw{not\_simplify}.}
  \label{fig:not-simplify}
\end{figure}

To apply these tactics sequentially, we define a meta-tactic $\mathop{\mathtt{applyAny}}$ that attempts each tactic in the list until one succeeds:

\begin{align*}
&\mathop{\mathtt{all\_not\_simplify}} \is (\rewrite \kw{not\_simplify1}) \cons  \\
&\quad (\rewrite \kw{not\_simplify2}) \cons (\rewrite \kw{not\_simplify3})
\end{align*}

The combinator $t_1 \orelse t_2$ tries $t_1$ on the current goal; if it fails to make progress, $t_2$ is applied instead. We then define the tactic for reconstructing the simplification step as follows:

\begin{align*}
&\mathop{\mathtt{applyAny}} : \bb{L} \, \kw{tactic} \ra \kw{Tactic} \\
&\mathop{\mathtt{applyAny}} \Box \re \fail \\
&\mathop{\mathtt{applyAny}} (\kw{t} \cons \kw{ts}) \re t \orelse (\mathop{\mathtt{applyAny}} \kw{ts}) \\[1em]
&\mathop{\mathtt{not\_simplify}} \is \repeatT (\mathop{\mathtt{applyAny}}~\mathop{\mathtt{all\_not\_simplify}}) \\
&\quad \andT \reflexivity
\end{align*}

Here, $\repeatT$ repeatedly applies the simplification tactics until none can be applied further.
Finally, a step using the \kw{not\_simplify} rule can be reconstructed as shown in \cref{fig:not-simplify}, by simply running the tactic script using the meta-tactic $\eval$.


\section{Quantifiers}

\begin{figure}
\centering
\begin{tabular}{|l|}
\hline
  R = \kw{forall\_inst} \\ \hline
  %
  \ruleAlethe{i}{(\neg \forall \bar{x},\, \varphi) \lor (\varphi[\bar{t}])}{forall\_inst} \\ \hline
  %
  \begin{tabular}[t]{@{}l}
    $i: \pid (\forall x_1,\dots~x_n, \E{\varphi} = \E{\psi} \veedot \nil) \coloneq$\\
    begin
    \ \ \begin{tabular}[t]{@{}l}
          apply $\lor_{i1}$;\\ %
          apply imply\_to\_or;\\
          assume H;\\
          refine $\forall_e H$\\
        \end{tabular}\\
    end
  \end{tabular}
\\ \hline
\end{tabular}
\caption{Translating the \kw{forall\_inst} command.}
\label{fig:forall-inst-recon}
\end{figure}

The Alethe format defines rules for quantifier instantiation, substitution, and other manipulations of bound variables.
For instance, the rule \tt{forall\_inst} is used to express quantifier instantiation. It produces a unit clause with a formula of the form $(\neg \forall \bar{x},\, \varphi) \lor (\varphi[\bar{t}])$,
where $\varphi$ is a term containing the free variables $\bar{x}$, and each term $t$ is a ground term of the same sort as the corresponding variable $x$.

\begin{example}[Quantifier instantiation]
The following example shows a simple Alethe proof expressed in the abstract
notation used in this document. It uses quantifier instantiation and resolution to show a
contradiction. The paragraphs below describe the concepts necessary to understand the
proof step by step.
\begin{center}
\begin{tabular}{ l l r}
a0.& $\triangleright \quad \forall x, (P~x)$  & \kw{(assume)}[\,] \\
a1.& $\triangleright \quad \neg(P~a)$  & \kw{(assume)}[\,] \\
t1.& $\triangleright \quad \neg(\forall\,x, P~x) \lor (P~a)$  & \kw{(forall\_inst)}[($x$,$a$)] \\
t2.& $\triangleright \quad \neg(\forall\,x, P~x), (P~a)$  & \kw{(or t1)}[\,] \\
t3.& $\triangleright \quad \bot$ & \kw{(resolution a0 a1 t2)}[\,] \\
\end{tabular}
\end{center}
\end{example}

As described \cref{ssec:encoding-prop}, we encode universal and existential quantifiers using a shallow embedding into Lambdapi's dependent function type $\Pi A, B$.
This allows us to reconstruct the rule \tt{forall\_inst} directly, as shown in \cref{fig:forall-inst-recon}.

\section{Skolemization}


\begin{figure}
  \centering
\begin{tabular}{|l|}
\hline
  R = \kw{sko\_forall} \\ \hline
  %
  \begin{tabular}[t]{@{}l}
    $i.$  \begin{tabular}[t]{@{}l}
      $\Gamma, x_1 \mapsto \epsilon\,x_1. \neg \varphi \dots x_n \mapsto \epsilon\, x_n. \neg \varphi$\\
      $\triangleright \varphi \approx \psi~(\dots)$
    \end{tabular}\\
    $k.$ $\Gamma \quad \forall x_1, \dots x_n.~ \varphi \approx \psi$ \qquad $(R)$
  \end{tabular} \\ \hline
  %
  \begin{tabular}[t]{@{}l}
    $i: \pid (\E{\varphi} = \E{\psi} \veedot \nil ) \dots $\\
    $k: \pid (\forall x_1,\dots~x_n, \E{\varphi} = \E{\psi} \veedot \nil) \coloneq$\\
    begin
    \ \ \begin{tabular}[t]{@{}l}
          apply $\lor_{i1}$;\\ %
          (\,\begin{tabular}[t]{@{}l}
            apply \kw{sko\_forall}; assume $x_i$ $H_i$; rewrite $H_i$;\,)$^n$
          \end{tabular} \\
          reflexivity;
        \end{tabular}\\
    end
  \end{tabular}
\\ \hline
\end{tabular}
\caption{Translating the \kw{sko\_forall} command.}
\label{fig:sko-forall}
\end{figure}


The skolemization rules \kw{sko\_forall} and \kw{sko\_exists} replace the bound variables with \kw{choice} terms instead of fresh symbols. Note that some functions can introduce fresh symbols in the proof trace with the command \smtinline{(define-fun)}.
Nevertheless, Carcara eliminates those commands by unfolding the definition during the elaboration process.
Moreover, cvc5 preprocesses the input formula by converting existential quantifiers into negated universal quantifiers, thus, the proof traces we are working with only use the \kw{sko\_forall} rule.

We now prove a lemma that underlies the translation of the Alethe rule \kw{sko\_forall}.
We first prove that the universal quantifier can be interpreted by the epsilon operator in our encoding.

\smallskip

\begin{lemma}[Reduction of $\forall$ to choice]\label{lemma:eps-forall}
For every $a : \set$ and predicate $p: \el~a \ra \prop$, $(\forall x, p~x) \Leftrightarrow p~(\epsilon\,x, \neg (p~x))$
\end{lemma}
\begin{proof}
\begin{itemize}
\item[\textbf{``$\Rightarrow$'':}]  We have to prove that $\forall x, p\,x$ implies $p(\epsilon\,x, \neg (p\,x))$, which follows immediately from the hypothesis.
\item[\textbf{``$\Leftarrow$'':}]  We prove the contrapositive assertion. Assuming $\neg \forall x, p\,x$, we obtain $\exists x, \neg p\,x$. Combining the elimination rule for $\exists$ and the introduction rule $\epsilon_i$, we conclude $\neg p(\epsilon\,x, \neg (p~x))$.
\end{itemize}
\end{proof}

We now prove the Skolemization lemma for the universal quantifier that used to reconstruct steps using the rule \kw{sko\_forall}.

\smallskip

\begin{lemma}[skolemize forall]\label{lem:sko-forall}
For any $a : \set$, predicate $p : \el{}\,a \ra \prop$ and $q : \prop$, if for every $x: \el{}\,a$, $\prf (x = (\epsilon \, y, \neg (p\,y)))$ implies $\prf (p\,x = q)$,  we have that $\prf ((\forall x, p\,x) = q)$.
\end{lemma}
\begin{proof} We apply rule \kw{prop\_ext} and then prove both directions,
\begin{itemize}
\item[\textbf{``$\Rightarrow$'':}]  We have to prove that $\forall x, p~x$ implies $q$. By \cref{lemma:eps-forall}, the former is equivalent to $p~(\epsilon\,y,~\neg (p~y))$, and together with the assumption of the lemma, we obtain $q$.
\item[\textbf{``$\Leftarrow$'':}]  Conversely, we have to prove that $q$ implies $\forall x, p~x$. For $x$ defined as $(\epsilon~y, \neg (p~y))$, we have $p~x = q$ by assumption and thus obtain $p~(\epsilon~y, \neg (p~y))$. By \cref{lemma:eps-forall}, the latter is equivalent to $\forall x, p~x$.
\end{itemize}
\end{proof}

\cref{fig:sko-forall} describes the translation of the \kw{sko\_forall} command. We use the notation $(T)^n$ to express that the tactic $T$ will be repeated $n$ times where $n$ is the number of bound variables on the left, and $x_i, H_i$ are fresh new variables in the context.
The $H_i$ hypotheses stand for the equalities $\prf (x_i = (\epsilon\,y, \neg (p~y)))$ in \cref{lem:sko-forall}.

\section{Alethe subproofs}
\label{app:subproof}

Alethe uses subproofs to prove lemmas and to create and manipulate the context $\Gamma$. To prove lemmas, a subproof can introduce local assumptions.
From an assumption $\varphi$ and a formula $\psi$ proved from $\varphi$, the subproof rule deduces the clause $\neg \varphi, \psi$ that discharges the local assumption $\varphi$.
A subproof step cannot use a premise from a subproof nested within the current subproof. Subproofs are also used to manipulate the context.
Alethe contexts are a general mechanism to write substitutions and to change them by attaching new elements.
We recall that a context is a possibly empty list $x_1 \dots x_n$ where each element is either a variable or a variable-term tuple denoted $x \mapsto t$.

As shown in the example of \cref{lst:subproof}, the \smtinline{anchor} command indicates that a subproof will be introduced and it is concluded by a concluding rule such as \texttt{subproof},
\texttt{bind} or \texttt{sko\_forall}. Anchors are provided with two annotations. The annotation \smtinline{:step} provides the name of the step that concludes the subproof whereas the annotation \smtinline{:args} provides the context as sorted variables and assignments. The example shows a proof that uses a subproof with a context to rename a bound variable.
The subproof starts at the \smtinline{anchor} command at line 1 and ends at line 5 with the \emph{bind} rule that concludes the $\alpha$-conversion proof of $z2$ to $vr4$. The sub-steps $t9.t1$ and $t9.t2$ are carried out in the context $\Gamma = \{ z2 \mapsto vr4 \}$, hence, all occurrences of $z2$ in the clauses are substituted by $vr4$, allowing in particular step \texttt{t9.t1} to succeed using rule \texttt{refl}.

\begin{lstlisting}[language=SMT,mathescape=true, caption={Alethe subproof example.}, label={lst:subproof}]
(anchor :step t9 :args ((vr4 U) (:= (z2 U) vr4)))
(step t9.t1 (cl (= z2 vr4)) :rule refl)
(step t9.t2 (cl (= (p z2) (p vr4))) :rule cong :premises (t9.t1))
(step t9 (cl (= (forall ((z2 U)) (p z2))
                (forall ((vr4 U)) (p vr4)))) :rule bind)
\end{lstlisting}

\begin{figure}
\centering
\begin{tabular}{|l|}
\hline
\textbf{R = \kw{subproof}} \\
\hline
$i_1.\ \Gamma \triangleright \varphi_1$ \quad $(\kw{assume})$ \\
$\vdots$ \\
$i_n.\ \Gamma \triangleright \varphi_n$ \quad $(\kw{assume})$ \\
$\vdots$ \\
$i_j.\ \Gamma \triangleright \psi$ \quad $(\dots)$ \quad with $u \in 1 \dots n$ \\
\ruleAlethe{k}{\neg \varphi_1, \dots, \neg \varphi_n, \psi}{subproof} \\

\hline

$\C{k} = \pid (( \neg \E{\varphi_1} \veedot \dots \veedot \neg \E{\varphi_n} \veedot \E{\psi} ) \veedot \nil)$ \\
$\quad \is \kw{apply}~\kw{subproof}_n$ \\
\hline
\textbf{R = \kw{bind}} \\
\hline
$j.\ \Gamma~\overline{y}, \overline{x} \mapsto \overline{y} \triangleright \varphi \approx \psi$ \quad $(\dots)$ \\
$\quad$ with $\overline{a} = a_1 \dots a_n$ and $Q \in \{\forall, \exists\}$ \\
$k.\ \Gamma \triangleright (Q~\overline{x}, \varphi) \approx (Q~\overline{y}, \psi)$ \quad $(\kw{bind})$ \\

\hline

$\C{k} = \pid (\E{Q~\overline{x}, \varphi \approx Q~\overline{y}, \psi} \veedot \nil) \is$ \\
 begin
    \ \ \begin{tabular}[t]{@{}l}
          $\kw{apply}~\lor_{i1}; \kw{apply~bindQ};$ \\
          $\kw{assume}~x_j; \kw{apply}~ (\pid{}_l~j);$
        \end{tabular}\\
    end
    \\
\hline
\end{tabular}
\caption{Translating \kw{subproof} and \kw{bind} commands.}
\label{table:subproof-c}
\end{figure}

We define in \cref{table:subproof-c} the definitions of the function $\mathcal{C}$ for the \kw{subproof} and \kw{bind} commands. The translation of \kw{bind} and \kw{subproof} relies on the following lemmas that have been proved in Lambdapi.


\begin{lemma}[$\kw{subproof}_1$]\label{lem:subproof}
For $\varphi, \psi : \prop{}$, if $\prf{} \varphi$ implies $\prf{} \psi$ then $\pid (\neg \varphi \veedot \psi)$.
\end{lemma}


\begin{lemma}[bind$\forall$]\label{lem:bind-forall}
Given an arbitrary $a : \kw{Clause}$ and predicates $p, q : \el{}\,a \ra \prop$, if $\Pi x : \el{}\,a,~ \prf (p~x = q~x)$ then $\prf ((\forall x, p~x) = (\forall y, q~y))$.
\end{lemma}


\begin{lemma}[bind$\exists$]\label{lem:bind-exists}
  Given an arbitrary $a : \kw{Clause}$ and predicates $p, q : \el{}\,a \ra \prop$, if $\Pi x : \el{}\,a,~ \prf (p~x = q~x)$ then $\prf ((\exists x, p~x) = (\exists y, q~y))$.
\end{lemma}


%================= reflection introduction ====================

Since proof by reflection is a key methodological ingredient of our reconstruction framework, 
we dedicate the next section to introduce this concept in detail before applying it to specific rules.

\input{Chapters/reconstruction/reflection}

%=============================================================

\section{N-ary rules}
\label{sec:nary-rule-recon}

\begin{table}
\centering
\caption{N-ary operators rules}
\begin{tabular}{ll}
Rule & Description \\ \hline
and (i)[k] & $i. \triangleright \quad (\varphi_1 \land \dots \land \varphi_n)$ \\
    & $j. \triangleright \quad \varphi_k $ with $1 \leq k \leq n$\\[1em]
not\_and (i) & $i. \triangleright \quad \neg (\varphi_1 \land \dots \land \varphi_n)$ \\
    & $j. \triangleright \quad \neg \varphi_1, \dots, \neg \varphi_n $\\[1em]
not\_or (i)[k] & $i. \triangleright \quad \neg (\varphi_1 \lor \dots \lor \varphi_n)$\\
    & $j. \triangleright \quad \neg \varphi_k$ with $1 \leq k \leq n$\\[1em]
and\_pos [k] & $\triangleright \quad \neg (\varphi_1 \land \dots \land \varphi_n), \varphi_k$ with $1 \leq k \leq n$ \\[1em]
and\_neg & $\triangleright \quad (\varphi_1 \land \dots \land \varphi_n), \neg \varphi_1, \dots, \neg \varphi_n$ \\[1em]
or\_pos & $\triangleright \quad \neg (\varphi_1 \lor \dots \lor \varphi_n), \varphi_1, \dots, \varphi_n$ \\[1em]
or\_neg [k] & $\triangleright \quad \neg (\varphi_1 \lor \dots \lor \varphi_n), \neg \varphi_k$ with $1 \leq k \leq n$ \\
\end{tabular}
\label{table:nary-rules}
\end{table}

The Alethe format includes n-ary tautological rules—relying on arbitrary n-ary conjunctions and disjunctions as outlined in \cref{table:nary-rules}.
A direct approach to reconstruct these rules would involve generating tactic scripts during the translation in Carcara.
However, this could lead to proofs requiring hundreds of tactic applications.
To address this, we adopt an alternative strategy: reconstructing these rules via a \emph{proof by reflection} of the first kind.
We illustrate our approach by detailing the reconstruction of \tt{and\_pos}.
In our encoding, n-ary conjunctions and disjunctions are interpreted as values of the abstract type list of proposition: $\bb{L}\,o$.
We begin by introducing the following configuration:

\begin{itemize}
  \item The function $\kw{indexes}: \Pi [a: \set],\, \bb{L}~a \ra \bb{L}~\kw{nat}$  takes a list of propositions and returns a list where each proposition is replaced by its position in the list.
  \begin{example}[indexes]
  \(
    \mathop{\mathtt{indexes}} (x \mathbin{\cons} y \mathbin{\cons} x  \mathbin{\cons} z \mathbin{\cons} \Box) \equivL 0 \mathbin{\cons} 1 \mathbin{\cons} 2 \mathbin{\cons} 3 \mathbin{\cons} \Box
  \)
  \end{example}
  \item The function $\in_k : \N \rightarrow \bb{L}~\kw{nat} \rightarrow \bb{B}$  determines whether a given index is present in a list of indexes ($\bb{L}~\kw{nat}$).
  \item The denotation function $\kw{conj}: \bb{L}~o \ra \prop$ decodes a list of propositions into an n-ary conjunction:
  \[
    \begin{aligned}
    & \kw{conj}~(x \cons b \cons \ell) \re (x \land \kw{conj}~(b \cons \ell))\\
    & \kw{conj}~(x \cons \Box) \re x\\
    & \kw{conj}~\Box \re \top
    \end{aligned}
    \]
  \item The total function $\kw{literal}: \Pi (k: \N),\, \bb{L}~o \ra \prop$ returns the $k$-th element of the list, or $\bot$ otherwise.
\end{itemize}

The rule \kw{and\_pos} is an instance of the classical reasoning \(\prfcl (\neg A \veedot B) \equiv \prf A \ra \prfcl B\),
with $A$ is $\varphi_1 \land \dots \land \varphi_n$, and $B$ is the singleton clause $\varphi_k$.
Hence, after reification, it suffices to prove $\kw{conj}~\mathit{cnf}$ implies $\kw{literal}~\mathit{cnf}~k$.
Given the hypothesis that \(\prf\,(k \in_k \kw{indexes}~\mathit{cnf})\), the $k$-th member is indeed one literal in the conjunction, so from \(\prf\,(\kw{conj}~\mathit{cnf})\) we may project \(\prf\,(\kw{literal}~\mathit{cnf}~k)\).
In other words, if all formulas in \(\kw{conj}~\mathit{cnf}\) hold, then the $k$-th one holds.

\begin{lemma}[and\_pos]
Given an index $k: \N$ and a list $\mathit{cnf}: \List{o}$ representing a reified $n$-ary conjunction, if
\[
  \prf (k \in_k (\kw{indexes}~\mathit{cnf}))
\]
i.e. the literal at index $k$ is in the conjunction then
\[
  \prfcl (\neg (\kw{conj}~\mathit{cnf}) \veedot (\kw{literal}~k~\mathit{cnf}) \veedot \nil)
\]
\begin{proof}
By interpreting clause as disjunction it suffices to prove:
\[
    \neg (\kw{conj}~\mathit{cnf}) \lor (\kw{literal}~\mathit{cnf}~k).
\]
We proceed by outer induction on $k$, and inner induction on the list $\mathit{cnf}$.
\begin{itemize}
  \item (Case $k = 0$),
    \begin{itemize}
      \item (Case $\mathit{cnf} = \Box$), so the hypothesis $0 \in_k (\kw{indexes}~\Box)$ leads to a contradiction since the reified conjunction is empty.
      \item (Case $\mathit{cnf} = a \cons \ell$),  then the element $k$ is the head literal $a$ so we can immediately conclude.
    \end{itemize}
  \item (Case $k > 0$),
      \begin{itemize}
      \item (Case $\mathit{cnf} = \Box$), so the hypothesis $k + 1 \in_k (\kw{indexes}~\Box)$ leads to a contradiction since the reified conjunction is empty.
      \item (Case $\mathit{cnf} = a \cons \ell$), we have to show that:
        \[
            \kw{literal}~(a \cons \ell)~(k+1)
        \]
        It is suffisant to prove that \( \kw{literal}~\ell~k \) since validity of the index $k+1$ in the whole list implies validity of $k$ in $\ell$.
        By the induction reasoning, using that $k+1 \in_k \kw{indexes}\,(a \cons \ell)$ implies $k \in_k \kw{indexes}\,\ell$, we obtain a proof of the literal at position $k$ in $\ell$.
        Thus, the conclusion follows directly from this argument.
    \end{itemize}
\end{itemize}
\end{proof}
\label{lem:and-pos}
\end{lemma}

\begin{figure}
\centering
\begin{tabular}{|l|}
\hline
  R = \kw{pos\_and} \\ \hline
  $i. \triangleright \quad \neg (\varphi_1 \land \dots \land \varphi_n),~ \varphi_k$ \quad (\kw{pos\_and})[k] \\ \hline
  \begin{tabular}[t]{@{}l}
    $i: \pid (\neg (\E{\varphi_1} \land \dots \land \E{\varphi_n}) \veedot \E{\varphi_k} \veedot \nil ) $\\
    begin
    \ \ \begin{tabular}[t]{@{}l}
          apply $\lor_{i1}$;\\ %
          apply $\kw{and\_pos}~\E{k}$ $(\E{\varphi_1} \cons \dots \cons \E{\varphi_n} \cons \Box)~ \top_i$
        \end{tabular}\\
    end
  \end{tabular}
  \\\hline
\end{tabular}
\caption{Translating the \kw{pos\_and} command.}
\label{fig:pos-and-recon}
\end{figure}

We can reconstruct the proof such as described in \cref{fig:pos-and-recon}.
We first need to retrieve a disjunctions from a clause by applying the disjunction introduction rule $\lor_{i1}$,
and then we apply \cref{lem:and-pos} with the index $k$ given by Alethe, the conjunction reified $(\E{\varphi_1} \cons \dots \cons \E{\varphi_n} \cons \Box)$ and a proof that $\prf (k \in_k (\kw{indexes}~c))$
which should reduce to $\top$.



\section{The \texttt{\upshape{evaluate}} cvc5 rule}
\label{sec:evaluation-recon}

The SMT solver cvc5 can produce proof traces with steps generated by internal theories: \kw{evaluate}, \kw{TRUST\_THEORY\_REWRITE} (TTR).
The clauses derived using \kw{evaluate} are propositional and numerical constant equalities proved internally by cvc5, using constant propagation.
The solver will then use the special rule ``\kw{hole}'', a placeholder for proof steps that cannot be expressed with Alethe rules.
The Carcara checker accepts the conclusion of these \kw{hole} steps without further justification.
In contrast, we attempt to reconstruct them using a combination of simple internal solvers and external tools.

\smallskip

\begin{lstlisting}[language=SMT,caption={An example of proof trace using the cvc5 $\kw{evaluate}$ rule.},label={lst:eval-step}]
(step t1 (cl (= (not true) false)) :rule hole :args ("evaluate"))
(step t2 (cl (= (>= 0.0 -1.0) true)) :rule hole :args ("evaluate"))
\end{lstlisting}

\smallskip

For propositional formulas such as line 1 in \cref{lst:eval-step}, we reconstruct the proof using an embedded proof procedure based on proof by reflection of the first kind.
For equalities over numerical constants, such as line 2, we simplify the expressions using the rewriting rules defined in $\mathcal{R}{\mathbb{Z}}$ and $\mathcal{R}{\mathbb{P}}$, and aim to conclude by \lpinline{reflexivity}.
The rule \kw{TTR} (TRUST\_THEORY\_REWRITE) describes steps performed by cvc5’s internal theory rewriter.
These steps may involve rewriting quantified propositions or other expressions too complex for the tautology solver.
Instead, we attempt reconstruct them by invoking the first-order automated theorem prover Zenon Modulo \cite{zenonmodulo} with the tactic \lpinline{why3} of Lambdapi, configured to call Zenon Modulo.
This prover produces proof certificates in both Lambdapi and Dedukti formats, which are currently not integrated,  though this step could potentially be automated.
Although Zenon modulo could in principle be used more extensively during the certification of Alethe proof traces, in order to control the complexity of proof reconstruction we restrict the usage of an external solver to the \kw{TTR} command.

We now describe the propositional tautological solver based on \emph{proof by reflection} of first kind.
We start by defining the target theory that represents formulas of propositional logic.

\begin{definition}[$\cal{P}$]\label{def:prop}
This is represented by the inductive type $\mathcal{P}$, with seven constructors listed in \cref{def:prop}.

\begin{align*}
& \cal{P} : \type \\
& |~\textbf{pTrue} : \cal{P} \\
& |~\textbf{pAnd} : \cal{P} \ra \cal{P} \ra \cal{P} \\
& |~\textbf{pFalse} : \cal{P} \\
& |~\textbf{pOther} : \N \ra \cal{P} \\
& |~\textbf{pOr} : \cal{P} \ra \cal{P} \ra \cal{P} \\
& |~\textbf{pImpl} : \cal{P} \ra \cal{P} \ra \cal{P} \\
& \kw{propS}: \set \\
& \el\,\kw{propS} \re \cal{P}
\end{align*}
We define the constant $propS: \set$ to be able to quantify over $\cal{P}$.
Each \texttt{pOther} term carries an index in $\mathbb{N}$, which serves as a pointer into a context map $\sigma : \mathbb{L}~o$.
\end{definition}

A context $\sigma$ stores the corresponding uninterpreted expressions of type $\prop$.
Although the automation does not inspect the contents of $\sigma$, it can determine whether two \texttt{pOther} terms reference the same index and are thus syntactically equal.
Note that during reification, repeated expressions are assigned the same index in $\sigma$ whenever possible.
However, we do not attempt to prove that different indices refer to distinct expressions.

\begin{definition}[Reification and denotation $\cal{P} \rightleftarrows \prop$]
We define a reification function $\reify{\_} : \mathbb{L}~o \rightarrow \prop \rightarrow \mathcal{P}$ written $\reify{\_}\, x \, \sigma$,
and an interpretation function $\deno{\_} : \mathbb{L}~o \rightarrow \mathcal{P} \rightarrow \prop$ written $\deno{\_} \, x \, \sigma$,
which convert between the source logic $\prop$ and the target theory $\mathcal{P}$ using the context map $\sigma$.

\begin{minipage}{0.6\linewidth}
\small
\begin{flalign*}
&\reify{}: \bb{L}~o \ra \prop \ra \cal{P} && \\
&\reify{\top}_\sigma \re  \kw{pTrue} && \\
&\reify{\bot}_\sigma \re  \kw{pFalse} && \\
&\reify{x \lor y}_\sigma \re  \kw{pOr}~(\reify{x}_\sigma) (\reify{y}_\sigma) && \\
&\reify{x \land y}_\sigma \re \kw{pAnd} ~(\reify{x}_\sigma) (\reify{y}_\sigma) && \\
&\reify{x \Rightarrow y}_\sigma \re \kw{pImpl}~(\reify{x}_\sigma) (\reify{y}_\sigma) && \\
&\reify{x}_\sigma \re  \kw{pOther}~(\kw{Index}(\sigma, x)) && \\
\end{flalign*}
\end{minipage}%
\begin{minipage}{0.5\linewidth}
\small
\begin{flalign*}
&\deno{}: \bb{L}~o \ra \cal{P} \ra \prop && \\
&\deno{\kw{pTrue}} = \top  &&\\
&\deno{\kw{pFalse}} = \bot  &&\\
&\deno{\kw{pOr}\,x\,y} = \deno{x} \lor \deno{y}  &&\\
&\deno{\kw{pAnd}\,x\,y} = \deno{x} \land \deno{y}  &&\\
&\deno{\kw{pImpl}\,x\,y} = \deno{x} \Rightarrow \deno{y}  &&\\
&\deno{\kw{pOther}~i} = \sigma[i] &&
\end{flalign*}
\end{minipage}
\end{definition}

\begin{example}[Reification]
Let $\sigma \is a \cons b \cons \Box$, the reification of $a \land b$ is:
\[
  \reify{(a \land b)}_\sigma \equivL \mathop{\mathtt{pAnd}} (\mathop{\mathtt{pOther}} 0) (\mathop{\mathtt{pOther}} 1)
\]
and its denotation
\[
  \deno{(\mathop{\mathtt{pAnd}} (\mathop{\mathtt{pOther}} 0) (\mathop{\mathtt{pOther}} 1))}_\sigma \equivL a \land b.
\]
\end{example}

Next, we define a decidable equality between terms of type $\cal{P}$.

\begin{definition}[Decidable equality $=_\cal{P} \colon \cal{P} \ra \cal{P} \ra \mathbb{B}$]
\begin{flalign*}
&\kw{pTrue} =_\cal{P} \kw{pTrue} \re \true &&\\
&\kw{pFalse} =_\cal{P} \kw{pFalse} \re \true &&\\
&\kw{pAnd}~l_1\,r_1 =_\cal{P} \kw{pAnd}~l_2\,r_2  \re l_1 =_\cal{P} l_2 ~\kw{andb}~r_1 =_\cal{P} =r_2 &&\\
&\kw{pOr}~l_1\,r_1 =_\cal{P} \kw{pOr}~l_2\,r_2  \re l_1 =_\cal{P} l_2 ~\kw{andb}~r_1 =_\cal{P} =r_2 &&\\
&\kw{pImpl}~l_1\,r_1 =_\cal{P} \kw{pImpl}~l_2\,r_2  \re l_1 =_\cal{P} l_2 ~\kw{andb}~r_1 =_\cal{P} =r_2 &&\\
&\kw{pOther}~x =_\cal{P} \kw{pOther}~y  \re x =_\mathbb{N} y  &&
\end{flalign*}
with $=_\N: \N \ra \N \ra \B$ a decidable equality between $\N$.
\end{definition}

We know describes the notion of context $\hyps$ that is encoded as a $\bb{L}~\kw{propS}$.
The context will be used for learning propositions introduced by implication $(\kw{pImpl})$ in the reified goal.
We define what it means for all members of a context $\hyps$ to represent true propositions,
and we prove some lemmas about this notion.

The predicate \kw{all} (\cref{eq:all-func}) transform a list of $\cal{P}$ into conjunctions to represent a context.
It used a fold right function from the Lambdapi standard library.
\begin{equation}
\kw{all}: \kw{list}~\cal{P} \ra \cal{P} \coloneqq \kw{foldr}~(\kw{pAnd})~\kw{pTrue}
\label{eq:all-func}
\end{equation}
The function \kw{knows} (\cref{eq:know-func}) searches for an element decidably equal to $p$. It also use the function \kw{existsb} from the standard library.
\begin{equation}
\kw{knows}~(p: \cal{P})~(\Gamma: \kw{list}~\cal{P}) \coloneqq \kw{existsb}~(=_\cal{P})~\Gamma
\label{eq:know-func}
\end{equation}

The function \kw{learn} extends the list of known facts $\Gamma$ to include one more fact.
We destruct conjunctions so that we can prove theorems such as $p \land q \Rightarrow p$. For simplicity, in the case of other constructors, we just learn it.
%
\begin{flalign*}
&\kw{learn}~(p: \cal{P})~(\hypst): \kw{list}~\cal{P} &&\\
&\kw{learn}~\kw{pTrue}~\hyps \re \hyps &&\\
&\kw{learn}~\kw{pFalse}~\hyps \re (\kw{pFalse}::\hyps) &&\\
&\kw{learn}~(\kw{pAnd}~x~y)~\hyps \re \kw{learn}~x~(\kw{learn}~y~\hyps) &&\\
&\kw{learn}~p~\hyps \re \kw{learn}~(p :: \hyps)
\end{flalign*}

Correctness of \kw{learn} says that if the original context is valid, and the fact that learning is valid, then the learned context is valid.

\begin{lemma}[Correctness of learning]\label{lemma:learning_sound}
Given $\mapty$ and a context $\hypst$ then for any $\kw{p}: \cal{P}$, if
\[
  \prf (\deno{\kw{all}~\hyps}) \text{ and } \prf (\deno{p})
\]
then
\[
  \prf (\deno{\kw{all} (\kw{learn}~\kw{p}~\hyps)})
\]
\end{lemma}
\begin{proof} By induction on $p$.

Since all the cases follow the same patterns, we provide the case for \kw{pAnd}, and a similar approach can be follow for the rest.
We want to prove that $\prf (\deno{\kw{all} (\kw{learn}~(\kw{pAnd}~a~b)~\hyps))}$ which rewrites to $\prf (\deno{(a)} \land \deno{(b)} \land \deno{(\kw{foldr}~\kw{pTrue}~\Gamma))}$ by definition of \kw{all},
and we suppose that $\prf (\deno{\kw{all}~\hyps}$ and $\prf \deno{\kw{pAnd}~a~b)}$.
Then we apply the introduction rule of the conjunction ($\land_i$) giving us two case to prove.
\begin{itemize}
\item Case $\prf \deno{a}$ which follows directly from the hypothesis that $\prf (\deno{\kw{pAnd}~a~b)}$,
\item Case $\prf (\deno{b} \land \deno{\kw{foldr}~\kw{pTrue}~\Gamma)}$ which follows from the hypothesis that $\prf \deno{(\kw{pAnd}~a~b)}$ and $\prf (\deno{\kw{all}~\hyps})$.
\end{itemize}
\end{proof}

Now we want to prove that if our function \kw{knows} returns \kw{true}, then the proposition is implied by the meaning of the context:

\smallskip

\begin{lemma}[knows correct] \label{lemma:know_correct}
Given a mapping $\mapty$ with a context $\hypst$ and a proposition $\kw{p}: \cal{P}$, if
$\prf \deno{\kw{all}~\Gamma}$ and $\kw{knowns}~\kw{p}~\Gamma = \true$ then $\prf \deno{\kw{p}}$.
\end{lemma}
\begin{proof}
By induction on the context list $\Gamma$.
\begin{itemize}
\item[] \textbf{Case} $\Gamma = \square$, trivial because we cannot have $\kw{knows}~p~\square = true$.
\item[] \textbf{Case} $\Gamma = x :: xs $, assume we have $H: \kw{knows}~p~(x::xs) = true$ and $H2: \deno{\kw{all}~(x::xs)}$.
We know by $H$, that $p$ is equal to $x$ or $p$ is equal to an element in $xs$. If $x$ is equal to $p$, one has $\deno{\kw{x}}$ from $H2$, hence we have $\deno{\kw{p}}$.
In the other case, $\deno{\kw{p}}$ follows from the induction hypothesis and H2.
\end{itemize}
\end{proof}


The function \kw{provable} implements our decision procedure. It checks if a proposition $goal: \cal{P}$ is provable in the context $\Gamma$.
%
\begin{flalign*}
&\kw{provable}~(goal: \cal{P})~(\hypst): \mathbb{B} &&\\
&\kw{provable}~\kw{pTrue}~\hyps \re \true &&\\
&\kw{provable}~\kw{pFalse}~\hyps \re \kw{knows}~\kw{pFalse}~\hyps &&\\
&\kw{provable}~(\kw{pAnd}~x~y)~\hyps \re (\kw{provable}~x~\hyps)~\kw{and}~(\kw{provable}~y~\hyps) &&\\
&\kw{provable}~(\kw{pOr}~x~y)~\hyps \re (\kw{provable}~x~\hyps)~\kw{or}~(\kw{provable}~y~\hyps) &&\\
&\kw{provable}~(\kw{pImpl}~x~y)~\hyps \re \kw{provable}~y~(\kw{learn}~x~\hyps) &&\\
&\kw{provable}~(\kw{pOther}~i)~\hyps \re \kw{knows}~(\kw{pOther}~i)~\hyps ~\kw{or}~ \kw{knows}~\kw{pFalse}~\hyps  &&\\
\end{flalign*}

\begin{theorem}[Correctness of \kw{provable}]
For any $\kw{goal}: \cal{P}$ and context $\hypst$, if $\prf (\kw{provable}~\kw{goal}~\hyps = \true)$
then given a mapping $\sigma$, if the context $\prf (\deno{\kw{All}~\hyps})$ represent true propositions then the $\prf (\deno{\kw{goal}})$ is true.
\begin{proof} By induction on $p$.
\begin{itemize}
\item[] \textbf{Case} (p = \kw{pTrue}), we have to prove $\deno{\kw{pTrue}}$ which rewrites into $\top$ which holds trivially.
\item[] \textbf{Case} (p = \kw{pFalse}), It follow from the \cref{lemma:know_correct} with our hypothesis \kw{provable} \kw{pFalse} $\hyps = \true$ and $\deno{\kw{All}~\hyps}$ that $\deno{\text{pFalse}}$ hold.
\item[] \textbf{Case} (p = \kw{pAnd a b}), follow directly by induction hypothesis since \kw{provable} \kw{(pAnd a b)} $\hyps = \true$ implies $\kw{provable}~a~\hyps = \true$ and $\kw{provable}~b~\hyps = \true$.
\item[] \textbf{Case} (p = \kw{pOr}\,a\,b), follow directly by induction hypothesis since \kw{provable}\,\kw{pOr}\,a\,b\,$\hyps = \true$ implies $\kw{provable}\,a\,\hyps = \true$ or $\kw{provable}\,b\,\hyps = \true$.
\item[] \textbf{Case} (p = \kw{pImpl}\,a\,b), follow directly by induction hypothesis and \cref{lemma:learning_sound}.
\item[] \textbf{Case} (p = \kw{pOther}~i), let's consider an index $i: \N$, by the hypothesis $\prf (\kw{provable}~\kw{pOther}~i~\hyps = \true)$  we know that $(\kw{pOther}\,i) \in \Gamma$ or $\kw{pFalse} \in \Gamma$. Therefore,
if $(\kw{pOther}\,i) \in \Gamma$ then by \cref{lemma:know_correct} and the hypothesis $\deno{\kw{All}~\hyps}$ we have $\deno{\kw{pOther}\,i}$. However,
in the case that $\kw{pFalse} \in \Gamma$, by using \cref{lemma:know_correct} and the hypothesis $\deno{\kw{All}~\hyps}$ we derive ex falso quodlibet.
\end{itemize}
\end{proof}
\end{theorem}

\begin{lstlisting}[language=Lambdapi, caption={Usage of Tauto}, label={lst:tauto-ex}]
symbol reify goal ≔ propReify □ goal;

symbol tauto_aux [goal] ≔
  let res ≔ reify goal in provable_sound (res ₁) □ (res ₂);

symbol tauto ≔ #refine "(tauto_aux ⊤ᵢ ⊤ᵢ)";

private symbol example1: π ((⊤ ∧ ⊤) ⇒ ⊤ ∨ ⊤ ∧ (⊤ ⇒ ⊤)) ≔
begin eval tauto; end;
\end{lstlisting}

As shown in \cref{lst:tauto-ex}, we define a new tactic \kw{tauto} using a tactic script at line 5, and demonstrate its usage at lines 8-9.


\section{The \texttt{\upshape{contraction}} rule}
\label{sec:contraction-recon}

The Alethe rule \kw{contraction} removes duplicate literals from a clause without changing its truth.
Because of the challenges posed by associativity and commutativity (AC), reconstructing this rule requires using the second kind of proof-by-reflection method.

\begin{align*}
&i.~\triangleright &  &l_1,\, \dots,\, l_{n}       & & (\dots)  \\
&j.~\triangleright &  &l_{k_1},\, \dots,\, l_{k_m} & & (\kw{contraction}~i) 
\end{align*}

where $m \leq n$ and $k_1 \dots k_m$ is a monotonic map to $1 \dots n$ such that: $l_{k_1},\, \dots,\, l_{k_m}$ are pairwise distinct, and Hence, this rule removes duplicated literals.

In our reconstruction, we use an assignment $\sigma: \bb{L}~o$ computed automatically from the literals of the clause $l_{k_1},\, \dots,\, l_{k_m}$.
Each literal is associated with its position index in $\sigma$, which induces a total order on terms. 
This order allows us to define a canonical representation of clauses: we turn a clause into a list of literal identifiers, stably sort this list using mergesort, and then remove adjacent duplicates.  
Correctness follows from three ingredients: a denotational interpreter $\Downarrow$ parameterized by $\sigma$, a mergesort whose denotation is extensionally equal to its input, and a duplicate-removal pass whose denotation is idempotent with respect to disjunction.

We first encode a simple canonical algebra of literals:

\begin{align*}
&\cal{C} : \type & \kw{cl}: \set  \\
&\pipe p : \N \ra \cal{C} &\el~\kw{cl} \re \cal{C}
\end{align*}

A clause is then represented as a list of elements of $\cal{C}$.
In this construction, contraction is performed solely on the left-hand side term $t_1$ representing the unreduce clause $l_1,\, \dots,\, l_{n}$ of step $i$.

\begin{center}
\(\begin{tikzcd}[ampersand replacement=\&,column sep=small]
	{\Uparrow\,t_1 \,=\, \Uparrow\,t_2} \& \bb{L}~\kw{cl} \&\& \bb{L}~\kw{cl} \& {[\Uparrow t_1] \,=\, \Uparrow t_2} \\
	\\
	{t_1 = t_2} \& \kw{Clause} \&\& \kw{Clause} \& {(\den{[\Uparrow g_1]}) = (\den{\Uparrow g_2})}
	\arrow["({[\_], id)}", dashed, from=1-2, to=1-4]
	\arrow["\lrcorner"{anchor=center, pos=0.125}, draw=none, from=1-2, to=3-4]
	\arrow["{\Downarrow(\_)}", from=1-4, to=3-4]
	\arrow["{\Uparrow(\_)}", from=3-2, to=1-2]
	\arrow["\iff"{description}, dotted, no head, from=3-2, to=3-4]
\end{tikzcd}\)
\[
  \text{with } [\_] = \kw{remove} \circ \kw{sort}
\]
\end{center}


\begin{definition}[Denotation]\label{def:denotation}
Given an assignment $\sigma : \bb{L}~o$, the denotation function
\[
  \Downarrow : \bb{L}~o \to \bb{L}\,\kw{cl} \to \prop
\]
maps a list of identifiers to the big disjunction of the corresponding literals:
\begin{align*}
&\Downarrow\,\sigma\,\Box \re \bot \\
&\Downarrow\,\sigma\,(p\,i :: \ell) \re \sigma[i] \mathbin{\veedot} \Downarrow\,\sigma\,\ell.
\end{align*}
\end{definition}

\begin{definition}[Reification into $\bb{L}~\kw{cl}$]\label{def:reify}
Reification translates a clause into its canonical list of identifiers together with 
the remaining syntactic literals. It proceeds by traversing the clause, 
looking up each literal in the current environment, and assigning it a fresh identifier if none is found.
\[
  \Uparrow  : \bb{L}~o \to \kw{Clause} \to \el (\kw{list}~\kw{cl} \times \kw{list}~o)
\]
\begin{align*}
&\Uparrow (l,\;\Box) \re (\Box,\,l) \\
&\Uparrow (l,\; x \veedot xs) \re \\
&\begin{cases}
  (p\,i :: l,\; l) & \text{if }  i \text{ index already exists} \\
  (p\,i :: (l \concat (x::\Box)),\; l) & \text{if } i \text{ new index},
\end{cases} \\
&\qquad \text{then recursively reify the tail: } (xs',\,l') \coloneq \Uparrow~l~xs, \\
&\qquad \text{and return } (p\,i :: xs',\, l').
\end{align*}

\noindent
We then define the top-level reification function
\[
  \Uparrow \;c \;\coloneqq\; \Uparrow \,\Box\,c.
\]
\end{definition}

\begin{example}[Reification]
Given $\sigma \eqcolon x \cons y \cons \Box$, the clause:
\[
    x \veedot y \veedot x \veedot y \veedot \nil 
\]
is then reified into:
\[
    p\,0 \cons p\,1 \cons p\,0 \cons p\,1 \cons \nil
\]
\end{example}

We now can start to define the necessary functions and lemmas for the mergesort.

\begin{definition}[split]
The function \kw{split} divides a generic list into two sublists by alternating elements:
\begin{align*}
&\kw{split}: \Pi\,a:\set, \bb{L}~a \ra \el (\kw{list}~a \times \kw{list}~a)\\
&\kw{split}\,\Box \re (\Box , \Box) \\
&\kw{split}\,(x::\Box) \re (\,x::\Box , \Box\,) \\
&\kw{split}\,(x::y::\ell) \re \bigl(x::(\kw{split}\,\ell)_1, y::(\kw{split}\,\ell)_2 \bigr)
\end{align*}
\end{definition}

To reason semantically about these lists, we define $\Downarrow\,\sigma\,g$ as the denotation of $g$ under assignment $\sigma$.  
The following two lemmas show that $\Downarrow$ interacts well with list concatenation and with the splitting procedure.


\begin{lemma}[Concatenation distributes over \(\Downarrow\)]\label{lem:den-cat}
For all lists \(x,y\) of identifiers and any assignment \(\sigma\),
\[
\prf\bigl(\Downarrow\,\sigma\,(x \concat y) \;=\; \Downarrow\,\sigma\,x \ \vee\ \Downarrow\,\sigma\,y\bigr).
\]
\end{lemma}

\begin{lemma}[Split preserves denotation]\label{lem:split-correct}
For all identifier lists \(g\) and assignments \(\sigma\),
\[
  \prf\bigl(\Downarrow\,\sigma\,((\kw{split} g)_1 \concat (\kw{split} g)_2) \;=\; \Downarrow\,\sigma\,g\bigr).
\]
\end{lemma}

\begin{definition}[merge]
The merge function combines two sorted lists into a single sorted list:
\begin{align*}
& \kw{merge}: \bb{L}~\kw{cl} \ra \bb{L}~\kw{cl} \ra \bb{L}~\kw{cl} \\
&\kw{merge}~\Box~\ell \re \ell \\
&\kw{merge}~\ell~\Box \re \ell \\
&\kw{merge}~(p~i :: \ell_1)~(p~j::\ell_2) \re
\begin{cases}
p~i :: p~j :: \kw{merge}(\ell_1,\ell_2) & \text{if } i = j \\
p~i :: \kw{merge}(\ell_1, p~j::\ell_2) & \text{if } i < j \\
p~j :: \kw{merge}(p~i::\ell_1, \ell_2) & \text{if } i > j
\end{cases}
\end{align*}
\end{definition}

\begin{lemma}[Merge is denotationally additive]\label{lem:merge-correct}
For all \(g_1,g_2\) and any context \(\sigma\),
\[
\prf\bigl(\Downarrow\,\sigma\,(\kw{merge}\,g_1\,g_2) = \Downarrow\,\sigma\,g_1 \ \vee\ \Downarrow\,\sigma\,g_2 \bigr).
\]
\end{lemma}

With \kw{split} and \kw{merge}, we can now define mergesort.


\begin{definition}[mergesort]
\begin{align*}
&\kw{mergesort}~\Box \re \Box \\
&\kw{mergesort}~(x :: \Box) \re x :: \Box \\
&\kw{mergesort}~(x :: y :: \ell) \re \\
  & \quad \text{let } (l_1,l_2) \coloneqq \kw{split}~(x :: y :: \ell)\ \text{ in }\ \\
  & \qquad \kw{merge}~(\kw{mergesort}~l_1)~(\kw{mergesort}~l_2)
\end{align*}
\end{definition}

After sorting, duplicate literals appear as adjacent elements. We now define a function that removes these duplicates.


\begin{definition}[remove identical literals]
\begin{align*}
&\kw{remove}~\Box \re \Box \\
&\kw{remove}~(p\,i :: \Box) \re p\,i :: \Box \\
&\kw{remove}~(p\,i :: p\,j :: \ell) \re
\begin{cases}
  \kw{remove}~(p\,j :: \ell) & \text{if } i = j, \\
  p\,i :: \kw{remove}(p\,j :: \ell) & \text{if } i \neq j
\end{cases}
\end{align*}
\end{definition}

\begin{theorem}[Mergesort correctness]\label{thm:mergesort-correct}
For all \(g: \bb{L}~\kw{cl}\) and context \(\sigma\),
\[
  \prf\bigl(\Downarrow\,\sigma\,(\kw{mergesort}\,g) \;=\; \Downarrow\,\sigma\,g\bigr).
\]
\end{theorem}

\begin{theorem}[Contraction correctness]\label{thm:contraction-correct}
Define
\[
  \kw{contraction}\,g \coloneq \kw{remove} (\kw{mergesort}\,g).
\]
Then, for all \(g\) and \(\sigma\),
\[
\prf\bigl(\Downarrow\,\sigma\,(\kw{contraction}\,g) = \Downarrow\,\sigma\,g\bigr).
\]
\begin{proof}
By size-bounded induction on \(g\), using \cref{lem:split-correct,lem:merge-correct} and the distributivity \cref{lem:den-cat} in the combine step.
\end{proof}
\end{theorem}

\begin{example}[Contraction]
To illustrate the use of contraction in practice, consider the clause with a duplicated literal $: \prfcl (a \veedot b \veedot b \veedot \nil)$.
We show how to reconstruct the proof for the contracted clause $\prfcl (a \veedot b \veedot \nil)$ by appealing to the correctness of contraction.

\begin{lstlisting}[language=Lambdapi,mathescape=true,]
opaque symbol ti: $\prfcl$ (a ⟇ b ⟇ b ⟇ ▩) ≔ begin ... end;

opaque symbol tj:  $\prfcl$ (a ⟇ b ⟇ ▩) ≔
begin
  have eqh : $\prf$ ($\cltodisj$ (a ⟇ b ⟇ b ⟇ ▩) = $\cltodisj$ (a ⟇ b ⟇ ▩)) {
    set r ≔ $\Uparrow$ X;
    change $\prf$ ($\Downarrow$ (r ₂) (r ₁) = $\cltodisj$ (a ⟇ b ⟇ ▩));
    rewrite left contraction_correct;
    reflexivity
  };
  refine subst_cl eqh ti
end;
\end{lstlisting}
Here, the intermediate proof \kw{eqh} establishes that the denotations of the original clause
$(a \veedot b \veedot b)$ and the contracted clause $(a \veedot b)$ are equal by \cref{thm:contraction-correct}.
The lemma
\[
  \kw{subst\_cl}~x~y: 
    \prf(\cltodisj\,x = \cltodisj\,y)
    \;\ra\; \prfcl(x) \;\ra\; \prfcl(y)
\]
is then applied to transfer the proof of the original clause $t_i$ to the contracted clause $t_j$.
\end{example}