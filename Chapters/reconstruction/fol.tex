%*****************************************
\chapter{Reconstructing first order proofs}\label{ch:reconstruction-ul}
%*****************************************

\section{Tautologous rules and simple deduction}
\label{sec:elem-rules}

Many Alethe rules introduce tautologies or derive their conclusion from a single premise.
%
These rules are primarily used for clausification and to simplify Boolean connectives during
preprocessing.
%
\cref{fig:fun-c} illustrate the definition of $\cal{C}$ for the rules \kw{assume}, \kw{equiv\_pos2} and \kw{cong} from the running example of \cref{lst:smtexampleinput}.
The definitions use the following lemmas proved in our Lambdapi encoding:
\begin{itemize}
\item $\kw{cong}_1 :
    \begin{array}[t]{@{}l@{}}
        \Pi (a\,b \colon \set),\ \Pi f \colon \el\,a \ra \el\,b, \\
        \Pi x\,x',\ \prf (x = x') \ra \prf (f\,x = f\,x'),
    \end{array}$
\item $\kw{equiv\_pos2} : \Pi (\varphi_1~\varphi_2: \prop),\ \pid (\neg (\varphi_1 = \varphi_2) \veedot \neg \varphi_1 \veedot \varphi_2 \veedot \nil )$,
\item $\pid_l : \Pi [a : \set],\ \pid (a \cons \nil) \ra \prf a$.
\end{itemize}


\begin{figure}[bt]
  \scriptsize
  \begin{tabular}{@{}l|l@{}}
  \hline
  \multicolumn{2}{|l|}{R = \kw{assume}} \\ \hline
  \\
  $i.~\Gamma~\triangleright~ \varphi \quad (R)[]$  & $i : \pid (\E{\varphi} \veedot \nil)$  \\
  \\
  \hline
  \multicolumn{2}{|l|}{R = \kw{equiv\_pos2}} \\ \hline
  \\
  $i.~\Gamma~\triangleright~ \neg (a \approx b), \neg a, b  \quad (R)[]$  &
  $i : \begin{array}[t]{@{}l@{}}
          \pid (\neg (\E{a} = \E{b}) \veedot \neg \E{a} \veedot \E{a}  \veedot \nil) \\
          \coloneq \kw{apply}~\kw{equiv\_pos2}
       \end{array}$ \\
  \hline

  \multicolumn{2}{|l|}{R = \kw{cong}} \\ \hline
  \\
  $i_1 ~\quad \Gamma ~ \triangleright ~ t_1 \approx u_1 \quad (\dots) $   \\
  $i_2 ~\quad \Gamma ~ \triangleright ~ t_2 \approx u_2 \quad (\dots) $  \\
  \qquad \vdots  & \\
  $i_n. \quad \Gamma ~ \triangleright ~ t_n \approx u_n \quad (\dots)$  &  \\
  $j. ~\quad \Gamma ~ \triangleright~
      \begin{array}[t]{@{}l@{}}
          (f~t_1 \dots t_n) \approx (f~u_1 \dots u_n)\\
          (R~i_1~i_2 ~..~ i_n)[]
      \end{array}$ &
  $j : \begin{array}[t]{@{}l@{}}
        \pid (\E{f~t_1 \dots t_n} = \E{f~u_1 \dots u_n} \veedot \nil) \\
        \coloneq \kw{apply}~(\kw{cong}_n~f~\pid_l(i_1) \dots \pid_l(i_n)))
       \end{array}$
  \end{tabular}
  \caption{Translations for three representative Alethe commands.}
  \label{fig:fun-c}
\end{figure}

\begin{example}
  \cref{lst:smtexamplelambdapi} illustrates the result of our main function $\mathcal{C}$ applied to the first steps in the running example of \cref{lst:smtexampleinput}.
  In the code below, all the \texttt{assume} commands (corresponding to the \texttt{assert}s of the input problem) are transformed into constants by~$\mathcal{C}$. A symbol without a definition is considered as an axiom.
  Each step is encoded as an \lpinline{opaque symbol} that represents a lemma. Splitting the proof into multiple lemmas is beneficial for larger proofs because it reduces Lambdapi's checking time for the proof.
\end{example}

% \begin{minipage}{0.95\linewidth}
\begin{lstlisting}[mathescape=true, caption={Trace from \cref{lst:smtexampleinput} encoded in Lambdapi.}, label={lst:smtexamplelambdapi}, language=Lambdapi]
symbol p2 ≔ (p b); 
symbol p4 ≔ ((p a) = (p b));
symbol p5 ≔ (p a);
symbol a0 : Prf$\textcolor{purple}{\smash{^\bullet}}$ (p5 ⟇ ▩);
symbol a1 : Prf$\textcolor{purple}{\smash{^\bullet}}$ ((a = b) ⟇ ▩);
symbol a2 : Prf$\textcolor{purple}{\smash{^\bullet}}$ ((¬ ((p b))) ⟇ ▩);
opaque symbol t0 : Prf$\textcolor{purple}{\smash{^\bullet}}$ ((¬ ((p5 = p2))) ⟇ (¬ (p5)) ⟇ p2 ⟇ ▩) ≔
  begin apply equiv_pos2; end;
opaque symbol t1 : Prf$\textcolor{purple}{\smash{^\bullet}}$ (p4 ⟇ ▩) ≔
  begin apply $\smash{\lor_{i1}}$; apply cong$_1$ p ($\smash{\dot{\pi}_l}$ a1); end;

opaque symbol t2 : Prf$\textcolor{purple}{\smash{^\bullet}}$ (p_4 ⟇ ▩) ≔ 
begin
  have t0_t1 : Prf$\textcolor{purple}{\smash{^\bullet}}$ ((¬ (p_1)) ⟇ p_4 ⟇ ▩) 
  { apply resolution t0 t1 };
  have t0_t1_a0 : Prf$\textcolor{purple}{\smash{^\bullet}}$ (p_4 ⟇ ▩)
  { apply resolution t0_t1 a0 };
  refine t0_t1_a0;
end;

opaque symbol t3 : Prf$\textcolor{purple}{\smash{^\bullet}}$ ▩ ≔ 
begin
  have a2_t2 : Prf$\textcolor{purple}{\smash{^\bullet}}$ ▩ { apply resolution a2 t2 };
  refine a2_t2;
end;
\end{lstlisting}
% \end{minipage}


\section{Resolution rule}
\label{ssec:resolution}

\change{Alessio}{The algorithm to reconstruct resolution will be modified}

Binary resolution on ground clauses can be expressed as the following proof rule, which we have proved in Lambdapi.

\begin{lemma}[Resolution]\label{lemma:resolution}
Given $a,b: \texttt{Clause}$, and a pivot $x: \prop$, $\pid (x \veedot a)$ and $\pid (\neg x \veedot b)$ imply $\pid (a \cal{P} b)$.
\end{lemma}

% FIXME: remove float?
\begin{figure}[h]
  \centering
  \begin{tabular}{l c r}
  $i_1.~\triangleright$  & \qquad $l_1^1,\, \dots,\, l_{k^1}^1$ \qquad & (\dots)  \\
  $i_n.~\triangleright$  & \qquad $l_1^n,\, \dots,\, l_{k^n}^n$ \qquad & (\dots) \\
    & \vdots  &  \\
  $j.~~\triangleright$  & \qquad $l_{s_1}^{r_1},\, \dots,\, l_{s_m}^{r_m}$ \qquad & $(\kw{resolution}~i_1 \dots i_n)[]$
  \end{tabular}
  \caption{Resolution rule}
  \label{fig:resolution-rule}
\end{figure}


However, Alethe's \kw{resolution} rule, shown in \cref{fig:resolution-rule}, represents hyper-resolution applied to a set of ground first-order clauses $i_1 \dots i_n$,
where the resulting clause $l_{s_1}^{r_1} \dots l_{s_m}^{r_m}$ is obtained by a chain of predicate resolution steps that remove complementary literals from the input clauses, with double negations being removed implicitly.
For example, the formulas $\neg \neg \neg P$ and $\neg \neg P$ can serve as pivots during resolution.
The first formula is interpreted as $\neg P$ and the second as just $P$ to perform resolution steps.
Alethe allows resolution steps without providing the pivots; however, Carcara's elaborated proof incorporates the pivots as arguments in the resolution rule, eliminating the need for an additional intermediate step to search for the pivots in our translation to Lambdapi.
In addition, pivots may appear anywhere in a clause rather than just as the head literal. Hence, Alethe \kw{resolution} involves reasoning modulo associativity and commutativity (AC) on clauses.

In \cite{ColtellacciMD24}, we simulated Alethe's \kw{resolution} rule as compositions of multiple binary resolution steps, combined with additional proof steps for justifying reasoning modulo AC used to move pivots to the heads of clauses.
However, the practical application of this approach suffered from inefficiency and did not allow us to reconstruct proofs of some benchmarks in SMT-LIB that involved hundreds of clauses in a single resolution.
In the following, we present an approach where we prove clause permutation through \emph{proof by reflection}\index{proof by reflection}, enabling more efficient pivot movement.
Given the central role of \emph{proof by reflection} in our translation, we dedicate the following section to a more detailed introduction of this concept, which is key to reconstructing certain proof rules in the Alethe format. 

\section{Proof by reflection}
\label{ssec:reflection-intro}

Proof by reflection~\cite{reflection-origin-coq} is a technique for constructing certified procedures for automated reasoning by reducing the verification of a logical statement to a symbolic computation.
This method is particularly applicable to two broad classes of problems. In the first class, we consider a predicate $P \colon T \to \prop$, where $T$ is a data type,
together with a semi decision procedure $f: T \to \mathbb{B}$ (or $\tt{Comp}$) such that, whenever $f$ returns $\tt{true}$ on input $x$, the predicate $P(x)$ holds.
Formally, this relationship is captured by the following correctness theorem:

\begin{equation*}
\mathop{f\_correct} \colon \Pi x \colon T, \prf (f~x = \tt{true}) \ra \prf (P~x).
\end{equation*}

Hence, to establish $P~y$ for a particular value $y$, it suffices to verify that $f(y)$ reduces to  $\tt{true}$.
In that case, we can simply apply the lemma $\mathop{f\_correct}$ to $y$ along with a proof that $true = true$ i.e. $(\mathop{eq\_refl} \tt{true})$ with $eq\_refl: \Pi [a \colon \set], \Pi (x: \el\,a), \prf (x = x)$. 
The resulting proof of $P~y$ is thus given by:

\begin{equation*}
\mathop{f\_correct} ~y~ (\mathop{refl} \tt{true}) \colon P~y
\end{equation*}

As an illustration, consider the property of a natural number being even. In Lambdapi, this can be expressed using a computable boolean function $\texttt{even} \colon \N \ra \B$ that checks whether a given number is even.
The connection between the boolean value and the logical property is established through a correctness lemma stating that if \texttt{even n = true}, then $n$ is even.
Thus, to prove that a specific number, such as $4$, is even, one can reduce the goal to the boolean check \texttt{even 4 = true}, which is decidable by computation.
Applying the correctness lemma then lifts this computational fact back into the logical framework to conclude that $4$ is even.
This approach automates routine reasoning steps involving decidable predicates, allowing for concise and efficient proofs.
This first class of reflection is particularly suited for properties such as arithmetic equalities, inequalities, and simple inductive predicates.

The size of such a proof only depends on the size of a particular argument $y$ and does not depend on the number of implicit $\equivL$ steps: explicit rewriting steps have been replaced by implicit $\equivL$ reductions.
The efficiency of this technique of course strongly depends on the efficiency of the system to reduce the application of the decision procedure $f(y)$, hence on the efficiency of the decision procedure ($f$) itself.


Moreover, while the proof term of the correctness lemma for $f$ may be large, it needs to be constructed only once. This proof can be shared across all instantiations and does not require rechecking by the type-checker in subsequent uses.

\medskip

The second class of problems where computation can help is the class of algebraic proofs such as proofs relying on rewriting modulo the associativity or the commutativity of some operators e.g. disjunction $(\lor)$ or conjunction $(\land)$.
For these proofs, we again consider a type $B: \set$ and we exhibit an "abstract type" $A: \set$, with two functions $\mathop{denote} \colon {\el}\,A \ra {\el}\,B$ and $g: \el{}\,A \ra \el{}\,A$.
The function $\mathop{denote}$ is an interpretation function that we can use to associate terms in the concrete type $B$ with abstract terms of type $A$.
The function $g$ reasons on the abstract terms. The reflection process relies on a theorem that expresses that the function $g$ does not change the value of the interpreted
term:

\begin{equation*}
  g\_ident : \Pi x: A, \prf (\mathop{denote}(g~x) = \mathop{denote} x)
\end{equation*}

Thus, to prove that two terms $t_1$ and $t_2$ are equal in $B$ , we only need to show that they are the images of two terms $a_1$ and $a_2$ in $A$ such that $g\,a_1 = g\,a_2$.
As an illustration of this second class of proofs by reflection, consider the commutativity of disjunction: for any two propositions $P$ and $Q$, we wish to prove that $P \lor Q$ is logically equivalent to $Q \lor P$.
To apply reflection, we first define an \emph{abstract} syntax for formulas, for instance, a type $\mathsf{Monoid}$ with constructors for atomic propositions and for disjunction.
We then define an \emph{interpretation function} $\mathsf{denote} \colon \mathsf{Monoid} \to \prop$ that maps abstract formulas to their logical meaning. 
Next, we define a normalization function $\mathop{norm}: \mathsf{Monoid} \to \mathsf{Monoid}$ that rewrites disjunctions into a canonical order, such as ordering operands lexicographically.
The key theorem states that this normalization preserves meaning:
\[
\mathsf{norm\_mono} : \forall x : \mathsf{Monoid}, \mathsf{denote}(\mathop{norm} x) = \mathsf{denote}(x).
\]
Hence to prove that $P \lor Q$ and $Q \lor P$, are logically equivalent, it suffices to represent them as abstract expressions $m_1$ and $m_2$ of type $\mathsf{Monoid}$, apply the function $\mathop{norm}$ with the lemma $\mathsf{norm\_mono}$ to normalize both, and check that $\mathop{norm}(m_1) = \mathop{norm}(m_2)$.
By correctness of the interpretation, their meanings must then coincide.


In this thesis, we make use of both classes of reflection to encode certain \texttt{Alethe} rules. For example, the reconstruction of arithmetic steps (\textbf{LIA} and \textbf{LRA}) and bitvector (\textbf{BV}) Alethe rules primarily relies on the first class,
while the permutation of clauses for the \texttt{resolution} rule relies on the second class.

\section{Computing hyper-resolvents with proof by reflection}
\label{ssec:refl-reso}


Whereas the technique described in \cref{ssec:resolution} can be used to reconstruct resolution proofs in Alethe proof traces, it suffers from poor scalability.
Specifically, the permutation proof generated for pivot movement due to reasoning modulo AC may become excessively lengthy. We will now describe an alternative technique based on computational reflection that allows us to prove the permutation of clauses efficiently.
Relying on the rewriting facilities of Lambdapi, we implemented a decision procedure that checks equality between clauses by rewriting modulo AC-canonization.

The core idea is to put clauses with pivots in different positions into a canonical form, allowing them to be compared. To achieve this, we present a proof by reflection of the second class in the following.
If two clauses are determined to be equal, the current clause can be substituted with one where the pivot is placed at the head position, allowing for the subsequent application of \cref{lemma:resolution}.
To handle associative and commutative symbols, Lambdapi provides the modifiers \lpinline{associative commutative} \info{ac}{the introduction of Lambdapi will present AC and its builtin order},
ensuring that terms are systematically placed into a canonical form given a builtin ordering relation, following the technique described in \cite{ACorigin} and \cite[\S 5]{univAC}.

Additionally, as discussed in \cref{sect:elabration-resolution} \change{ac}{Need Alethe intro}, the solver can introduce implicit $\tt{contraction}$ steps between binary resolution steps.
We leverage the elaboration process in Carcara to avoid implementing a proof by reflection for $\tt{contraction}$, which would require structures not present in the standard library of Lambdapi to reason about collections modulo duplicate terms, such as finite sets.

\begin{figure}[t]
  \centering
  \begin{tikzcd}[column sep=tiny]
    {C_1 =_{\bb{C}} C_2} & {\bb{C}} && {\bb{C}} & {[C_1] =_{\bb{C}} [C_2]} \\
    \\
    {c_1 =_{\tt{Clause}} c_2} & \kw{Clause} && \kw{Clause} & {\den{[C_1]} =_{\tt{Clause}} \den{[C_2]}}
    \arrow["{{[\_]}}", dotted, from=1-2, to=1-4]
    \arrow["{{\den{\_}}}", from=1-4, to=3-4]
    \arrow["{{\reify{\_}}}"', from=3-2, to=1-2]
    \arrow["{\Leftrightarrow}"{marking, allow upside down}, draw=none, from=3-2, to=3-4]
  \end{tikzcd}
  \caption{Checking resolution steps via reification in the algebra $\bb{C}$.}
  \label{fig:reflective-process}
\end{figure}

The \cref{fig:reflective-process} provides an overview of the realization of this technique in Lambdapi.
It relies on \emph{reifying} clauses into terms of an algebra $\bb{C}$, using the operator $\reify{}$ defined in \cref{def:reify-def},
and we denote by $[t]$ the normalization of term $t$ done from \lpinline{associative commutative} modifiers.
This normalization corresponds to the function $g$ introduced in \cref{ssec:reflection-intro}.
Since we rely on the lambda modifiers, normalization is implicitly handled by $\lpm$, and thus the function $[_]$ is simply the identity: $[_]: \bb{C} \rightarrow \bb{C} \coloneq \lambda x., x$.

\begin{definition}[The abstract type $\bb{C}$]
The \emph{abstract type} $\bb{C}$ is an inductive type defined as follows:
\begin{align*}
&\bb{C} : \type \\
&|~\eps: \bb{C} \\
&|~\kw{P}: \prop \ra \bb{C} \\
&|~\sqcup: \bb{C} \ra \bb{C} \ra \bb{C} \quad \text{(written infix)} \\
&\kw{clauseAC} : \set \\
&\el\, \kw{clauseAC} \re \bb{C} \\
\end{align*}
where the constructor $\eps: \bb{C}$ representing $\nil$ and the constructor $\sqcup$ is declared \lpinline{associative commutative}, which is the analogue of $\cons$.
Propositions are injected into the algebra by the operator $\tt{P}$.
\end{definition}

\begin{definition}[reification function]
\begin{align*}
& \reify{}: \texttt{Clause} \ra \bb{C} \\
&\reify{(x \cons y)} \re \reify{x} \,\sqcup \reify{y} \\
&\reify{ \blacksquare } \re \epsilon \\
&\reify{ x } \re \cal{P}(x)
\end{align*}
where the $\reify{}$ is defined with the modifier \lpinline{sequential}.
\label{def:reify-def}
\end{definition}
\graffito{x}
It then remains to decide the equality of two terms in $\bb{C}$, and this is accomplished using the operator $=_\bb{C}$ introduced in \cref{def:eqC}.
Its definition relies on Boolean conjunction \kw{andb} (written infix), which is predefined in Lambdapi's standard library, as well as on the operator \kw{eq} that checks equality of two terms of type $\prop$.

\begin{definition}[decidable equivalence relation]
The operators $=_\bb{C} : \bb{C} \ra \bb{C} \ra \kw{bool}$ is defined by the following rewrite rules.

\begin{align*}
&x_1 \sqcup y_1 =_\bb{C} x_2 \sqcup y_2 \re (x_1  =_\bb{C} x_2) ~\kw{andb}~ (y_1  =_\bb{C} y_2) \\
&\_ \sqcup \_ =_\bb{C} \epsilon \re \false \\
&\_ \sqcup \_ =_\bb{C} \cal{P}(\_) \re \false \\
&\cal{P}(x) =_\bb{C} \cal{P}(y) \re (\kw{eq}~x~y) \\
&\cal{P}(\_) =_\bb{C} \_ \sqcup \_ \re \false \\
&\cal{P}(\_) =_\bb{C} \epsilon \re \false \\
&\epsilon =_\bb{C} \epsilon \re \true \\
&\epsilon =_\bb{C} \cal{P}(\_) \re \false \\
&\epsilon =_\bb{C} \_ \sqcup \_ \re \false
\end{align*}
with:
\begin{align*}
&\eq~x~x~ \re \true  & \kw{andb}~\kw{true}~\kw{true} \re \kw{true} \\
&\eq~x~y~ \re \false & \kw{andb}~\kw{false}~\_ \re \kw{false} \\
& & \kw{andb}~\_ \kw{false} \re \kw{false} 
\end{align*}
\label{def:eqC}
The binary operator \kw{eq} is declared as \kw{sequential} so that the second rewrite rule will be applied only if the first one fails.
Its definition ensures that $\kw{eq}~x~y$ holds if and only if the two propositions $x$ and $y$ are identical.
\end{definition}

We now state the correctness theorem, demonstrating that a given clause is a permutation of another.

\begin{lemma}[P-injective]\label{lem:p-inj}
For any $x, y: \prop$, if $\kw{istrue}(\cal{P}(x) =_{\bb{C}} \cal{P}(y))$ then $x = y$.
\begin{proof}
From the definition of $=_{\bb{C}}$ that uses a non-linear sequential rewriting rule,
it follows directly that if $\cal{P}(x) =_{\bb{C}} \cal{P}(y)$ is true then $x$ and $y$ have to be the same.
\end{proof}
\end{lemma}


\begin{theorem}[Correctness]\label{lem:eq-C}
For $c_1, c_2 : \tt{Clause}$, if $\tt{istrue} (\reify{c_1} =_{\bb{C}} \reify{c_2})$ then $\cal{F}\,c_1 = \cal{F}\,c_2$.
\end{theorem}
\begin{proof}
By induction on $c_1$ and $c_2$.
\begin{itemize}
  \item First suppose $c_1 = \blacksquare$ and $c_2 = \blacksquare$. We must show that $\tt{istrue} (\epsilon =_{\bb{C}} \epsilon)$ implies $\cal{F}\, \blacksquare = \cal{F}\, \blacksquare$ which follows directly by reflexivity.
  \item Next, suppose $c_1 = \blacksquare$ and $c_2 = x \veedot xs$. Then it follows from the the rewriting rules of $=_{\bb{C}}$ that we have a contradiction since we supposed that $\tt{istrue}(\epsilon =_{\bb{C}} \cal{P}(x) \sqcup \reify{xs})$.
  \item The case where $c_1 = x \veedot xs$ and $c_2 = \blacksquare$ is symmetrical.
  \item Lastly, suppose $c_1 = x \veedot xs$ and $c_2 = y \veedot ys$, and
  assume that $\tt{istrue}(\reify{c_1} =_{\bb{C}} \reify{c_2})$. 
  Let $d_1 = \reify{(x \veedot xs)}$ and $d_2 = \reify{(y \veedot ys)}$, then $d_1$ must be of the form 
  $\cal{P}(u) \sqcup \reify{u'}$ and $d_2$ must be of the form $\cal{P}(v) \sqcup \reify{v'}$ where 
  the clauses $u'$ and $v'$ are shorter than $xs$ and $ys$, respectively, and such that 
  $\cal{F}\,(u \veedot u') = \cal{F}\,(c_1)$ and similarly
  $\cal{F}\,(v \veedot v') = \cal{F}\,(c_2)$.
  Moreover, from the assumption $\tt{istrue}(d_1 =_{\bb{C}} d_2)$ and \cref{lem:p-inj} it follows that 
  $u = v$, and by induction hypothesis we obtain that $\cal{F}\,u' = \cal{F}\,v'$. Taking everything
  together, we finally obtain that $\cal{F}\,c_1 = \cal{F}\,c_2$.
\end{itemize}
\end{proof}

\begin{example}
The code in \cref{lst:new-reso} demonstrates how \cref{lem:eq-C} is used to move the pivot within a clause.
It introduces a proof of clause permutation using a cut at line 8, where \cref{lem:eq-C} is used to show, by computation, that the clause of step $t1$ is a permutation of another clause with the pivot at the head.
Line 10, the $\tt{trivial}$ is the constructor for the proposition $\top$, and it concludes the proof if the $=_{\bb{C}}$ of \cref{lem:eq-C} returns $\tt{true}$. % AC: Should we mention again that this is because (istrue true) -> True?
Additionally, we utilize the lemma $\tt{subst\_equiv\_clause}$, which states that for any clauses $c_1$ and $c_2$, if $\cal{F}(c_1) = \cal{F}(c_2)$ and there exists a proof of $c_1$, then we can derive a proof of $c_2$.
Thus, we combine in the $\tt{resolution}$ (line 12) this lemma with the permutation proof of $t1$ and the clause of $t2$ to derive the clause asserted by $t3$.

\begin{lstlisting}[mathescape=true, caption={Reflective resolutions}, label={lst:new-reso}, language=Lambdapi]
opaque symbol t1 : Prf$\textcolor{purple}{\smash{^\bullet}}$ (a ⟇ b ⟇ p ⟇ ▩) ≔  begin ... end;

opaque symbol t2 : Prf$\textcolor{purple}{\smash{^\bullet}}$ ((¬ (p)) ⟇ c ⟇ d ⟇ ▩) ≔  begin ... end;

opaque symbol t3 : Prf$\textcolor{purple}{\smash{^\bullet}}$ (a ⟇ b ⟇ c ⟇ d ⟇ ▩) ≔ 
begin
have t1_t2 : Prf$\textcolor{purple}{\smash{^\bullet}}$ (a  ⟇ b  ⟇ c  ⟇ d ⟇ ▩) {
have t1_perm : Prf$\textcolor{purple}{\smash{}}$ (($\cal{F}$ (a ⟇ b ⟇ p ⟇ ▩)) = ($\cal{F}$ (p ⟇ a ⟇ b ⟇ ▩))) {
  apply cl_perm_correct (a  ⟇ b  ⟇ p ⟇ ▩) (p  ⟇ a  ⟇ b ⟇ ▩);
  apply trivial;
};
apply resolution (subst_equiv_clause t1_perm t1) t2;
};
refine t1_t2;
end;
\end{lstlisting}

\end{example}

\section{Simplification rules}

The Alethe format includes rules that encode operator-level simplifications typically performed by SMT solvers. \info{ac}{The introduction of Alethe will contain the description of RARE, so we do not need to introduce it here anymore}
A key challenge arises from the fact that the solver does not explicitly specify which transformations are applied, nor the order in which they are performed. This makes certain rules, such as \tt{or\_simplify}, difficult to certify. 
For instance, the rule \texttt{or\_simplify}, presented in \cref{eqn:or-simp}, simplifies disjunctions by applying equivalence-preserving transformations repeatedly until a fixpoint is reached. Its general form is:

\begin{equation}\label{eqn:or-simp}
i. \quad \Gamma~\triangleright \quad l_1 \lor \dots \lor l_n ~ \approx \psi \quad \texttt{or\_simplify}
\end{equation}
where $\psi$ is the transformed term. The possible transformations are:
\begin{enumerate}
\item[(1)] $\bot \lor \dots \lor \bot \Rightarrow \bot$
\item[(2)] $l_1 \lor \dots \lor l_n \Rightarrow l_1' \lor \dots \lor l_m'$ where the right-hand side has some $\bot$ literals removed.
\item[(3)]  $l_1 \lor \dots \lor l_n \Rightarrow l_1' \lor \dots \lor l_m'$ where the right-hand side has some repeated literals removed.
\item[(4)] $l_1 \lor \dots \lor \top \lor \dots \lor l_n \Rightarrow \top$
\item[(5)] $l_1 \lor \dots \lor l_i \lor \dots \lor l_j \lor \dots \lor  l_n \Rightarrow \top$ where $l_i = \neg^{2p} x$, $l_j = \neg^{2q+1} x$.
\end{enumerate}
\info{ac}{reconstruction of or\_simplify need to be improve so I still prove not\_simplify only has example}

To manage these transformations, we leverage the RARE language provided by cvc5 \cite{rare}, which supports elaborated rewrite proofs.
As detailed in \cref{sec:rare-intro}, RARE generates explicit proof terms on demand, using built-in rewrite rules.
The RARE rule used and its arguments are made explicit in the \smtinline{:args} parameter of the rule $\kw{rare\_rewrite}$ in the proof trace.

However, in some cases, cvc5 may emit proof traces using the legacy simplification rules instead of RARE. In such situations, we reconstruct the simplification steps using tactic scripts, as detailed in \cref{ch:intro-lambdapi}.
These scripts allow us to interpret fixpoint-style transformations.

To illustrate this process, we describe how we reconstruct a step involving the \kw{not\_simplify} rule, summarized in \cref{fig:not-simplify}.
Each transformation associated with this rule is implemented by a separate lemma e.g., \kw{not\_simplify1}, \kw{not\_simplify2}, etc. which are then tried sequentially on the current goal.

\begin{figure}
  \footnotesize
  \begin{tabular}{l|l}
  \hline
  \multicolumn{2}{|l|}{R = \kw{not\_simplify}} \\ \hline
  \\
  $i. \quad \Gamma~\triangleright \quad \neg \psi \approx \varphi \quad (\kw{not\_simplify})$ & $\C{i} = \pid (\neg \E{\psi} = \E{\varphi} \cons \nil) $ \\
  $(1) \neg \neg \varphi \Rightarrow \varphi$ &  $\is$ \lpinline{eval not_simplify} \\
  $(2) \neg \bot \Rightarrow \top$  &   \\
  $(3) \neg \top \Rightarrow \bot$  & 
  \end{tabular}
  \caption{Translating the command \kw{not\_simplify}.}
  \label{fig:not-simplify}
\end{figure}

To apply these tactics sequentially, we define a meta-tactic $\mathop{\mathtt{applyAny}}$ that attempts each tactic in the list until one succeeds: 

\begin{align*}
&\mathop{\mathtt{all\_not\_simplify}} \is (\rewrite \kw{not\_simplify1}) \colon\colon  \\
&\quad (\rewrite \kw{not\_simplify2}) \colon\colon (\rewrite \kw{not\_simplify3})
\end{align*}

The combinator $t_1 \orelse t_2$ tries $t_1$ on the current goal; if it fails to make progress, $t_2$ is applied instead. We then define the tactic for reconstructing the simplification step as follows:

\begin{align*}
&\mathop{\mathtt{applyAny}} : \bb{L} \, \kw{tactic} \ra \kw{Tactic} \\
&\mathop{\mathtt{applyAny}} \Box \re \fail \\
&\mathop{\mathtt{applyAny}} (\kw{t} \colon\colon \kw{ts}) \re t \orelse (\mathop{\mathtt{applyAny}} \kw{ts}) \\
\end{align*}

The $t_1 \orelse t_2$ are evaluated respectively to $t_1$ and $t_2$ which must be tactic values.
The tactic value $t_1$ is applied in the current goal and if it fails to progress then $t_2$ is applied.

\begin{align*}
&\mathop{\mathtt{not\_simplify}} \is \repeatT (\mathop{\mathtt{applyAny}} \mathop{\mathtt{all\_not\_simplify}}) \\
&\quad \andT \reflexivity
\end{align*}

Here, $\repeatT$ repeatedly applies the simplification tactics until none can be applied further.
Finally, a step using the \kw{not\_simplify} rule can be reconstructed as shown in \cref{fig:not-simplify}, by simply running the tactic script using the meta-tactic $\eval$.

\section{N-ary rules}

\begin{table}
\centering
\caption{N-ary operators rules}
\begin{tabular}{ll}
Rule & Description \\ \hline
and (i)[k] & $i. \triangleright \quad (\varphi_1 \land \dots \land \varphi_n)$ \\
    & $j. \triangleright \quad \varphi_k $ with $1 \leq k \leq n$\\
not\_and (i) & $i. \triangleright \quad \neg (\varphi_1 \land \dots \land \varphi_n)$ \\
    & $j. \triangleright \quad \neg \varphi_1, \dots, \neg \varphi_n $\\
not\_or (i)[k] & $i. \triangleright \quad \neg (\varphi_1 \lor \dots \lor \varphi_n)$\\
    & $j. \triangleright \quad \neg \varphi_k$ with $1 \leq k \leq n$\\
and\_pos [k] & $\triangleright \quad \neg (\varphi_1 \land \dots \land \varphi_n), \varphi_k$ with $1 \leq k \leq n$ \\
and\_neg & $\triangleright \quad (\varphi_1 \land \dots \land \varphi_n), \neg \varphi_1, \dots, \neg \varphi_n$ \\
or\_pos & $\triangleright \quad \neg (\varphi_1 \lor \dots \lor \varphi_n), \varphi_1, \dots, \varphi_n$ \\
or\_neg [k] & $\triangleright \quad \neg (\varphi_1 \lor \dots \lor \varphi_n), \neg \varphi_k$ with $1 \leq k \leq n$ \\
\end{tabular}
\label{table:nary-rules}
\end{table}

The Alethe format includes n-ary tautological rules—relying on arbitrary n-ary conjunctions and disjunction as outlined in \cref{table:nary-rules}.
A direct approach to reconstruct these rules would involve generating tactic scripts during the translation in Carcara.
However, this could lead to proofs requiring hundreds of tactic applications.
To address this, we adopt an alternative strategy: reconstructing these rules via a \emph{proof by reflection} of the first kind.
We illustrate our approach by detailing the reconstruction of \tt{and\_pos}.
In our encoding, n-ary conjunctions and disjunctions are interpreted as values of the abstract type $\kw{list},o$.
We begin by introducing the following configuration:

\begin{itemize}
  \item We define the function $\kw{indexes}: \Pi [a: \set],\, \el\,\bb{L}~a, \ra \bb{L}~\kw{nat}$ that maps a list of elements
  to a list of natural numbers representing the positions (or indices) of the elements in the original list.
  The behavior of indexes is independent of the values of the elements - it is purely structural.
  So, even if the list contains duplicated elements, the indexes function simply returns the list of their positions, not caring whether elements are equal or not.

  \begin{example}[indexes]
  \[
  \mathop{\mathtt{indexes}} (x \colon\colon y \colon\colon x  \colon\colon z \colon\colon \Box) \equivL 0 \colon\colon 1 \colon\colon 2 \colon\colon 3 \colon\colon \Box
  \]
  \end{example}
  \item The function $\in_k : \N \rightarrow \bb{L}~\kw{nat} \rightarrow \bb{B}$  determines whether a given index is present in a list.
  \item The denotation function $\kw{conj}: \bb{L}~o \ra \prop$ decodes a list of propositions into an n-ary conjunction.
  \item The total function $\kw{literal}: \Pi (k: \N),\, \bb{L}~o \ra \prop$ returns the $k$-th element of the list, or $\bot$ otherwise.
\end{itemize}

% ∈ₙ : τ nat → 𝕃 nat → 𝔹

% select (id : τ nat) (cnf: 𝕃 o) : π (id ∈ₙ (indexes cnf)) → π (conj cnf) → π (literal cnf id) ≔
\begin{lemma}[select]
Let $k : \N$ be an index and $c : \bb{L}~o$ a reified conjunction, represented as a list of literals. If
\[
  \prf (\kw{istrue}~(k \in_k (\kw{indexes}~c))) \text{ and } \prf (\kw{conj}~c)
\]
then
\[
  \prf (\neg (\kw{conj}~c) \lor (\kw{literal}~k~c))
\]
That is, if a literal indexed by $k$ appears in the reified conjunction $c$ and the conjunction as a whole holds, then the corresponding literal must also hold.
\label{lemma:select}
\begin{proof}
\question{ac}{Do I need to provide the proof}  
\end{proof}
\end{lemma}

% and_pos2 (id : τ nat) (cnf: 𝕃 o) : π (id ∈ₙ (indexes cnf)) → π (¬ (conj cnf) ∨ (literal cnf id)) ≔
\begin{lemma}[and\_pos]
Given an index $k: \N$ and a list $c: \bb{L}~o$, If
\[
  \prf (\kw{istrue} (k \in_k (\kw{indexes}~c)))
\]
then
\[
  \prf (\neg (\kw{conj}~c) \lor (\kw{literal}~k~c))
\]
\begin{proof}
The proof is direct with \cref{lemma:select}.
\end{proof}
\label{lem:and-pos}
\end{lemma}



\begin{figure}
\centering
\begin{tabular}{|l|}
\hline
  R = \kw{pos\_and} \\ \hline
  $i. \triangleright \quad \neg (\varphi_1 \land \dots \land \varphi_n),~ \varphi_k$ \quad (\kw{pos\_and})[k] \\ \hline
  \begin{tabular}[t]{@{}l}
    $i: \pid (\neg (\E{\varphi_1} \land \dots \land \E{\varphi_n}) \cons \E{\varphi_k} \cons \nil ) $\\
    begin
    \ \ \begin{tabular}[t]{@{}l}
          apply $\lor_{i1}$;\\ %
          apply $\kw{and\_pos}~\E{k}$ $(\E{\varphi_1} \colon\colon \dots \colon\colon \E{\varphi_n} \colon\colon \Box)~ \top_i$
        \end{tabular}\\
    end
  \end{tabular}
  \\\hline
\end{tabular}
\caption{Translating the \kw{pos\_and} command.}
\label{fig:pos-and-recon}
\end{figure}

We can reconstruct the proof such as described in \cref{fig:pos-and-recon}.
We first need to retrieve a disjunctions from a clause by applying the disjunction introduction rule $\lor_{i1}$,
and then we apply \cref{lem:and-pos} with the index $k$ given by Alethe, the conjunction reified $(\E{\varphi_1} \colon\colon \dots \colon\colon \E{\varphi_n} \colon\colon \Box)$ and a proof that $\prf (k \in_k (\kw{indexes}~c))$
which should reduce to $\top$.

% Proof by reflection

\section{Quantifiers}

\begin{figure}
\centering
\begin{tabular}{|l|}
\hline
  R = \kw{sko\_forall} \\ \hline
  %
  \ruleAlethe{i}{(\neg \forall \bar{x},\, \varphi) \lor (\varphi[\bar{t}])}{forall\_inst} \\ \hline
  %
  \begin{tabular}[t]{@{}l}
    $i: \pid (\E{\varphi} = \E{\psi} \cons \nil ) \dots $\\
    $k: \pid (\forall x_1,\dots~x_n, \E{\varphi} = \E{\psi} \cons \nil) \coloneq$\\
    begin
    \ \ \begin{tabular}[t]{@{}l}
          apply $\lor_{i1}$;\\ %
          apply imply\_to\_or;\\
          assume H;\\
          refine $\forall_e H$\\
        \end{tabular}\\
    end
  \end{tabular}
\\ \hline
\end{tabular}
\caption{Translating the \kw{forall\_inst} command.}
\label{fig:forall-inst-recon}
\end{figure}

The Alethe format defines rules for quantifier instantiation, substitution, and other manipulations of bound variables.
For instance, the rule \tt{forall\_inst} is used to express quantifier instantiation. It produces a unit clause with a formula of the form $(\neg \forall \bar{x},\, \varphi) \lor (\varphi[\bar{t}])$,
where $\varphi$ is a term containing the free variables $\bar{x}$, and each term $t$ is a ground term of the same sort as the corresponding variable $x$.

\begin{example}[Quantifier instantiation]
The following example shows a simple Alethe proof expressed in the abstract
notation used in this document. It uses quantifier instantiation and resolution to show a
contradiction. The paragraphs below describe the concepts necessary to understand the
proof step by step.
\begin{center}
\begin{tabular}{ l l r}
a0.& $\triangleright \quad \forall x, (P~x)$  & \kw{(assume)}[\,] \\
a1.& $\triangleright \quad \neg(P~x)$  & \kw{(assume)}[\,] \\
t1.& $\triangleright \quad \neg(\forall\,x, P~x) \lor (P~a)$  & \kw{(forall\_inst)}[($x$,$a$)] \\
t2.& $\triangleright \quad \neg(\forall\,x, P~x), (P~a)$  & \kw{(or t1)}[\,] \\
t3.& $\triangleright \quad \bot$ & \kw{(resolution a0 a1 t2)}[\,] \\
\end{tabular}
\end{center}
\end{example}

As described \cref{ssec:encoding-prop}, we encode universal and existential quantifiers using a shallow embedding into Lambdapi's dependent function type $\Pi A, B$.
This allows us to reconstruct the rule \tt{forall\_inst} directly, as shown in \cref{fig:forall-inst-recon}. \question{ac}{need more details?}

\section{Skolemization}


\begin{figure}
  \centering
\begin{tabular}{|l|}
\hline
  R = \kw{sko\_forall} \\ \hline
  %
  \begin{tabular}[t]{@{}l}
    $i.$  \begin{tabular}[t]{@{}l}
      $\Gamma, x_1 \mapsto \epsilon\,x_1. \neg \varphi \dots x_n \mapsto \epsilon\, x_n. \neg \varphi$\\
      $\triangleright \varphi \approx \psi~(\dots)$
    \end{tabular}\\
    $k.$ $\Gamma \quad \forall x_1, \dots x_n.~ \varphi \approx \psi$ \qquad $(R)$
  \end{tabular} \\ \hline
  %
  \begin{tabular}[t]{@{}l}
    $i: \pid (\E{\varphi} = \E{\psi} \cons \nil ) \dots $\\
    $k: \pid (\forall x_1,\dots~x_n, \E{\varphi} = \E{\psi} \cons \nil) \coloneq$\\
    begin
    \ \ \begin{tabular}[t]{@{}l}
          apply $\lor_{i1}$;\\ %
          (\,\begin{tabular}[t]{@{}l}
            apply \kw{sko\_forall}; assume $x_i$ $H_i$; rewrite $H_i$;\,)$^n$
          \end{tabular} \\
          reflexivity;
        \end{tabular}\\
    end
  \end{tabular}
\\ \hline
\end{tabular}
\caption{Translating the \kw{sko\_forall} command.}
\label{fig:sko-forall}
\end{figure}


The skolemization rules \kw{sko\_forall} and \kw{sko\_exists} replace the bound variables with \kw{choice} terms instead of fresh symbols. Note that some functions can introduce fresh symbols in the proof trace with the command \smtinline{(define-fun)}.
Nevertheless, Carcara eliminates those commands by unfolding the definition during the elaboration process.
Moreover, cvc5 preprocesses the input formula by converting existential quantifiers into negated universal quantifiers, thus, the proof traces we are working with only use the \kw{sko\_forall} rule.

We now prove a lemma that underlies the translation of the Alethe rule \kw{sko\_forall}.
We first prove that the universal quantifier can be interpreted by the epsilon operator in our encoding.

\smallskip

\begin{lemma}[Reduction of $\forall$ to choice]\label{lemma:eps-forall}
For every $a : \set$ and predicate $p: \el~a \ra \prop$, $(\forall x, p~x) \Leftrightarrow p~(\epsilon\,x, \neg (p~x))$
\end{lemma}
\begin{proof}
\begin{itemize}
\item[\textbf{``$\Rightarrow$'':}]  We have to prove that $\forall x, p\,x$ implies $p(\epsilon\,x, \neg (p\,x))$, which follows immediately from the hypothesis.
\item[\textbf{``$\Leftarrow$'':}]  We prove the contrapositive assertion. Assuming $\neg \forall x, p\,x$, we obtain $\exists x, \neg p\,x$. Combining the elimination rule for $\exists$ and the introduction rule $\epsilon_i$, we conclude $\neg p(\epsilon\,x, \neg (p~x))$.
\end{itemize}
\end{proof}

We now prove the Skolemization lemma for the universal quantifier that used to reconstruct steps using the rule \kw{sko\_forall}.

\smallskip

\begin{lemma}[skolemize forall]\label{lem:sko-forall}
For any $a : \set$, predicate $p : \el{}\,a \ra \prop$ and $q : \prop$, if for every $x: \el{}\,a$, $\prf (x = (\epsilon \, y, \neg (p\,y)))$ implies $\prf (p\,x = q)$,  we have that $\prf ((\forall x, p\,x) = q)$.
\end{lemma}
\begin{proof} We apply rule \kw{prop\_ext} and then prove both directions,
\begin{itemize}
\item[\textbf{``$\Rightarrow$'':}]  We have to prove that $\forall x, p~x$ implies $q$. By \cref{lemma:eps-forall}, the former is equivalent to $p~(\epsilon~\neg (p~x))$, and together with the assumption of the lemma, we obtain $q$.
\item[\textbf{``$\Leftarrow$'':}]  Conversely, we have to prove that $q$ implies $\forall x, p~x$. For $x$ defined as $(\epsilon~y, \neg (p~y))$, we have $p~x = q$ by assumption and thus obtain $p~(\epsilon~y, \neg (p~y))$. By \cref{lemma:eps-forall}, the latter is equivalent to $\forall x, p~x$.
\end{itemize}
\end{proof}

\cref{fig:sko-forall} describes the translation of the \kw{sko\_forall} command. We use the notation $(T)^n$ to express that the tactic $T$ will be repeated $n$ times where $n$ is the number of bound variables on the left, and $x_i, H_i$ are fresh new variables in the context.
The $H_i$ hypotheses stand for the equalities $\prf (x_i = (\epsilon\,y, \neg (p~y)))$ in \cref{lem:sko-forall}.

\section{Alethe subproofs}
\label{app:subproof}

Alethe uses subproofs to prove lemmas and to create and manipulate the context $\Gamma$. To prove lemmas, a subproof can introduce local assumptions.
From an assumption $\varphi$ and a formula $\psi$ proved from $\varphi$, the subproof rule deduces the clause $\neg \varphi, \psi$ that discharges the local assumption $\varphi$.
A subproof step cannot use a premise from a subproof nested within the current subproof. Subproofs are also used to manipulate the context.
Alethe contexts are a general mechanism to write substitutions and to change them by attaching new elements.
We recall that a context is a possibly empty list $x_1 \dots x_n$ where each element is either a variable or a variable-term tuple denoted $x \mapsto t$.

As shown in the example of \cref{lst:subproof}, the \smtinline{anchor} command indicates that a subproof will be introduced and it is concluded by a concluding rule such as \texttt{subproof},
\texttt{bind} or \texttt{sko\_forall}. Anchors are provided with two annotations. The annotation \smtinline{:step} provides the name of the step that concludes the subproof whereas the annotation \smtinline{:args} provides the context as sorted variables and assignments. The example shows a proof that uses a subproof with a context to rename a bound variable.
The subproof starts at the \smtinline{anchor} command at line 1 and ends at line 5 with the \emph{bind} rule that concludes the $\alpha$-conversion proof of $z2$ to $vr4$. The sub-steps $t9.t1$ and $t9.t2$ are carried out in the context $\Gamma = \{ z2 \mapsto vr4 \}$, hence, all occurrences of $z2$ in the clauses are substituted by $vr4$, allowing in particular step \texttt{t9.t1} to succeed using rule \texttt{refl}.

\begin{lstlisting}[language=SMT,mathescape=true, caption={Alethe subproof example.}, label={lst:subproof}]
(anchor :step t9 :args ((vr4 U) (:= (z2 U) vr4)))
(step t9.t1 (cl (= z2 vr4)) :rule refl)
(step t9.t2 (cl (= (p z2) (p vr4))) :rule cong :premises (t9.t1))
(step t9 (cl (= (forall ((z2 U)) (p z2))
                (forall ((vr4 U)) (p vr4)))) :rule bind)
\end{lstlisting}

\begin{figure}
\centering
\begin{tabular}{|l|}
\hline
\textbf{R = \kw{subproof}} \\
\hline
$i_1.\ \Gamma \triangleright \varphi_1$ \quad $(\kw{assume})$ \\
$\vdots$ \\
$i_n.\ \Gamma \triangleright \varphi_n$ \quad $(\kw{assume})$ \\
$\vdots$ \\
$i_j.\ \Gamma \triangleright \psi$ \quad $(\dots)$ \quad with $u \in 1 \dots n$ \\
\ruleAlethe{k}{\neg \varphi_1, \dots, \neg \varphi_n, \psi}{subproof} \\

\hline

$\C{k} = \pid (( \neg \E{\varphi_1} \cons \dots \cons \neg \E{\varphi_n} \cons \E{\psi} ) \cons \nil)$ \\
$\quad \is \kw{apply}~\kw{subproof}_n$ \\
\hline
\textbf{R = \kw{bind}} \\
\hline
$j.\ \Gamma~\overline{y}, \overline{x} \mapsto \overline{y} \triangleright \varphi \approx \psi$ \quad $(\dots)$ \\
$\quad$ with $\overline{a} = a_1 \dots a_n$ and $Q \in \{\forall, \exists\}$ \\
$k.\ \Gamma \triangleright (Q~\overline{x}, \varphi) \approx (Q~\overline{y}, \psi)$ \quad $(\kw{bind})$ \\

\hline

$\C{k} = \pid (\E{Q~\overline{x}, \varphi \approx Q~\overline{y}, \psi} \cons \nil) \is$ \\
 begin
    \ \ \begin{tabular}[t]{@{}l}
          $\kw{apply}~\lor_{i1}; \kw{apply~bindQ};$ \\
          $\kw{assume}~x_j; \kw{apply}~ (\pid{}_l~j);$ 
        \end{tabular}\\
    end
    \\
\hline
\end{tabular}
\caption{Translating \kw{subproof} and \kw{bind} commands.}
\label{table:subproof-c}
\end{figure}

We define in \cref{table:subproof-c} the definitions of the function $\mathcal{C}$ for the \kw{subproof} and \kw{bind} commands. The translation of \kw{bind} and \kw{subproof} relies on the following lemmas that have been proved in Lambdapi.


\begin{lemma}[$\kw{subproof}_1$]\label{lem:subproof}
For $\varphi, \psi : \prop{}$, if $\prf{} \varphi$ implies $\prf{} \psi$ then $\pid (\neg \varphi \cons \psi)$.
\end{lemma}


\begin{lemma}[bind$\forall$]\label{lem:bind-forall}
Given an arbitrary $a : \kw{Clause}$ and predicates $p, q : \el{}\,a \ra \prop$, if $\Pi x : \el{}\,a,~ \prf (p~x = q~x)$ then $\prf ((\forall x, p~x) = (\forall y, q~y))$.
\end{lemma}


\begin{lemma}[bind$\exists$]\label{lem:bind-exists}
  Given an arbitrary $a : \kw{Clause}$ and predicates $p, q : \el{}\,a \ra \prop$, if $\Pi x : \el{}\,a,~ \prf (p~x = q~x)$ then $\prf ((\exists x, p~x) = (\exists y, q~y))$.
\end{lemma}

\section{The \texttt{\upshape{evaluate}} cvc5 rule}
\label{ssec:eval-recon}

The smt solver cvc5 can produce proof traces with steps generated by an internal theory: \kw{evaluate}, \kw{TRUST\_THEORY\_REWRITE} (TTR).
The clauses derived using \kw{evaluate} are propositional and numerical constant equalities proved internally by cvc5, using constant propagation.
The solver will then use the special rule ``\kw{hole}'', a placeholder for proof steps that cannot be expressed with Alethe rules.
The Carcara checker accepts the conclusion of these \kw{hole} steps without further justification.
In contrast, we attempt to reconstruct them using a combination of simple internal solvers and external tools.

\smallskip

\begin{lstlisting}[language=SMT,caption={An example of proof trace using the cvc5 $\kw{evaluate}$ rule.},label={lst:eval-step}]
(step t1 (cl (= (not true) false)) :rule hole :args ("evaluate"))
(step t2 (cl (= (>= 0.0 -1.0) true)) :rule hole :args ("evaluate"))
\end{lstlisting}

\smallskip

For propositional formulas such as line 1 in \cref{lst:eval-step}, we reconstruct the proof using an embedded proof procedure based on proof by reflection of the first kind.
For equalities over numerical constants, such as line 2, we simplify the expressions using the rewriting rules defined in $\mathcal{R}{\mathbb{Z}}$ and $\mathcal{R}{\mathbb{P}}$, and aim to conclude by \lpinline{reflexivity}.
The rule \kw{TTR} (TRUST\_THEORY\_REWRITE) describes steps performed by cvc5’s internal theory rewriter.
These steps may involve rewriting quantified propositions or other expressions too complex for the tautology solver.
Instead, we reconstruct them by invoking the first-order automated theorem prover Zenon Modulo \cite{zenonmodulo} with the tactic \lpinline{why3} of Lambdapi, configured to call Zenon Modulo.
This prover produces proof certificates in both Lambdapi and Dedukti formats, which are currently not integrated,  though this step could potentially be automated.
Although Zenon modulo could in principle be used more extensively during the certification of Alethe proof traces, in order to control the complexity of proof reconstruction we restrict the usage of an external solver to the \kw{TTR} command.

\begin{figure}
\begin{align*}
& \cal{P} : \type \\
& |~\textbf{pTrue} : \cal{P} \\
& |~\textbf{pAnd} : \cal{P} \ra \cal{P} \ra \cal{P} \\
& |~\textbf{pFalse} : \cal{P} \\
& |~\textbf{pOther} : \N \ra \cal{P} \\
& |~\textbf{pOr} : \cal{P} \ra \cal{P} \ra \cal{P} \\
& |~\textbf{pImpl} : \cal{P} \ra \cal{P} \ra \cal{P} \\
& \kw{propS}: \set \\
& \el\,\kw{propS} \re \cal{P}
\end{align*}
\caption{An inductive type for propositional logic.}
\label{fig:prop}
\end{figure}

\begin{figure}
\begin{minipage}{0.6\linewidth}
\small
\begin{flalign*}
&\reify{}: \bb{L}~o \ra \prop \ra \cal{P} && \\
&\reify{\top}_\sigma \re  \kw{pTrue} && \\
&\reify{\bot}_\sigma \re  \kw{pFalse} && \\
&\reify{x \lor y}_\sigma \re  \kw{pOr}~(\reify{x}_\sigma) (\reify{y}_\sigma) && \\
&\reify{x \land y}_\sigma \re \kw{pAnd} ~(\reify{x}_\sigma) (\reify{y}_\sigma) && \\
&\reify{x \Rightarrow y}_\sigma \re \kw{pImpl}~(\reify{x}_\sigma) (\reify{y}_\sigma) && \\
&\reify{x}_\sigma \re  \kw{pOther}~(\kw{Index}(\sigma, x)) && \\
\end{flalign*}
\end{minipage}%
\begin{minipage}{0.5\linewidth}
\small
\begin{flalign*}
&\deno{}: \bb{L}~o \ra \cal{P} \ra \prop && \\
&\deno{\kw{pTrue}} = \top  &&\\
&\deno{\kw{pFalse}} = \bot  &&\\
&\deno{\kw{pOr}\,x\,y} = \deno{x} \lor \deno{y}  &&\\
&\deno{\kw{pAnd}\,x\,y} = \deno{x} \land \deno{y}  &&\\
&\deno{\kw{pImpl}\,x\,y} = \deno{x} \Rightarrow \deno{y}  &&\\
&\deno{\kw{pOther}~i} = \sigma[i] &&
\end{flalign*}
\end{minipage}
\caption{Reification and denotation function for $\cal{P} \rightleftarrows \prop$}
\label{fig:reify-den-propS}
\end{figure}

We now describe the propositional tautological solver based on \emph{proof by reflection} of first kind.
We start by defining the target theory that represents formulas of propositional logic.
This is represented by the inductive type $\mathcal{P}$, with seven constructors listed in \cref{fig:prop}.
Each \texttt{pOther} term carries an index in $\mathbb{N}$, which serves as a pointer into a context map $\sigma : \mathbb{L}~o$.
This context $\sigma$ stores the corresponding uninterpreted expressions of type $\prop$.
Although the automation does not inspect the contents of $\sigma$, it can determine whether two \texttt{pOther} terms reference the same index and are thus syntactically equal.
Note that during reification, repeated expressions are assigned the same index in $\sigma$ whenever possible.
However, we do not attempt to prove that different indices refer to distinct expressions.
Finally, as shown in \cref{fig:reify-den-propS}, we define an interpretation function $\reify{_} : \mathbb{L}~o \rightarrow \prop \rightarrow \mathcal{P}$
and a reification function $\deno{_} : \mathbb{L}~o \rightarrow \mathcal{P} \rightarrow \prop$,
which convert between the source logic $\prop$ and the target theory $\mathcal{P}$ using the context map $\sigma$.


\begin{example}[Reification]
Let $\sigma \is a \colon\colon b \colon\colon \Box$, the reification of $a \land b$ is:
\[
  \reify{(a \land b)}_\sigma \equivL \mathop{\mathtt{pAnd}} (\mathop{\mathtt{pOther}} 0) (\mathop{\mathtt{pOther}} 1)
\]
and its denotation
\[
  \deno{(\mathop{\mathtt{pAnd}} (\mathop{\mathtt{pOther}} 0) (\mathop{\mathtt{pOther}} 1))}_\sigma \equivL a \land b.
\]
\end{example}

Next, we define a decidable equality between terms of type $\cal{P}$.

\begin{definition}[Decidable equality $=_\cal{P} \colon \cal{P} \ra \cal{P} \ra \mathbb{B}$]
\begin{flalign*}
&\kw{pTrue} =_\cal{P} \kw{pTrue} \re \true &&\\
&\kw{pFalse} =_\cal{P} \kw{pFalse} \re \true &&\\
&\kw{pAnd}~l_1\,r_1 =_\cal{P} \kw{pAnd}~l_2\,r_2  \re l_1 =_\cal{P} l_2 ~\kw{andb}~r_1 =_\cal{P} =r_2 &&\\
&\kw{pOr}~l_1\,r_1 =_\cal{P} \kw{pOr}~l_2\,r_2  \re l_1 =_\cal{P} l_2 ~\kw{andb}~r_1 =_\cal{P} =r_2 &&\\
&\kw{pImpl}~l_1\,r_1 =_\cal{P} \kw{pImpl}~l_2\,r_2  \re l_1 =_\cal{P} l_2 ~\kw{andb}~r_1 =_\cal{P} =r_2 &&\\
&\kw{pOther}~x =_\cal{P} \kw{pOther}~y  \re x =_\mathbb{N} y  &&
\end{flalign*}
with $=_\N: \N \ra \N \ra \B$ a decidable equality between $\N$.
\end{definition}

We know describes the notion of context $\hyps$ that is encoded as a $\bb{L}~\kw{propS}$.
The context will be use for learning proposition introduce by implication $(\kw{pImpl})$ in the reified goal.
We define what it means for all members of a context $\hyps$ to represent true propositions,
and we prove some lemmas about this notion.

The predicate \kw{all} (\cref{eq:all-func}) transform a list of $\cal{P}$ into conjonctions to represent a context.
It use a fold right function from the Lambdapi standard library \info{ac}{present it in \cref{ch:intro-lambdapi}}.
\begin{equation}
\kw{all}: \kw{list}~\cal{P} \ra \cal{P} \coloneqq \kw{foldr}~(\kw{pAnd})~\kw{pTrue}
\label{eq:all-func}
\end{equation}
The function \kw{knows} (\cref{eq:know-func}) searches for an element decidably equal to $p$. It also use the function \kw{existsb} from the standard library.
\begin{equation}
\kw{knows}~(p: \cal{P})~(\Gamma: \kw{list}~\cal{P}) \coloneqq \kw{existsb}~(=_\cal{P})~\Gamma
\label{eq:know-func}
\end{equation}

The function \kw{learn} extends the list of known facts $\Gamma$ to include one more fact.
We destruct conjunctions so that we can prove theorems such as $p \land q \Rightarrow p$. For simplicity, in the case of other constructor, we just learn it.
%
\begin{flalign*}
&\kw{learn}~(p: \cal{P})~(\hypst): \kw{list}~\cal{P} &&\\
&\kw{learn}~\kw{pTrue}~\hyps \re \hyps &&\\
&\kw{learn}~\kw{pFalse}~\hyps \re (\kw{pFalse}::\hyps) &&\\
&\kw{learn}~(\kw{pAnd}~x~y)~\hyps \re \kw{learn}~x~(\kw{learn}~y~\hyps) &&\\
&\kw{learn}~p~\hyps \re \kw{learn}~(p :: \hyps)
\end{flalign*}

Correctness of \kw{learn} says that if the original context is valid, and the fact that you are learning is valid, then the learned context is valid.

\begin{lemma}[Correctness of learning]\label{lemma:learning_sound}
Given $\mapty$ and a context $\hypst$ then for any $\kw{p}: \cal{P}$, if
\[
  \prf (\deno{\kw{all}~\hyps}) \text{ and } \prf (\deno{p})
\]
then
\[
  \prf (\deno{\kw{all} (\kw{learn}~\kw{p}~\hyps)})
\]
\end{lemma}
\begin{proof} By induction on $p$.

Since all the cases follow the same patterns, we provide the case for \kw{pAnd}, and a similar approach can be follow for the rest.
We want to prove that $\prf (\deno{\kw{all} (\kw{learn}~(\kw{pAnd}~a~b)~\hyps))}$ which rewrites to $\prf (\deno{(a)} \land \deno{(b)} \land \deno{(\kw{foldr}~\kw{pTrue}~\Gamma))}$ by definition of \kw{All},
and we suppose that $\prf (\deno{\kw{all}~\hyps}$ and $\prf \deno{\kw{pAnd}~a~b))}$.
Then we apply the introduction rule of the conjunction ($\land_i$) giving us two case to prove.
\begin{itemize}
\item Case $\prf \deno{a}$ which follows directly from the hypothesis that $\prf (\deno{\kw{pAnd}~a~b)}$,
\item Case $\prf (\deno{b} \land \deno{\kw{foldr}~\kw{pTrue}~\Gamma)}$ which follows from the hypothesis that $\prf \deno{(\kw{pAnd}~a~b)}$ and $\prf (\deno{\kw{all}~\hyps})$.
\end{itemize}
\end{proof}

Now we want to prove that if our function \kw{knows} returns \kw{true}, then the proposition is implied by the meaning of the context:

\smallskip

\begin{lemma}[knows correct] \label{lemma:know_correct}
Given a mapping $\mapty$ with a context $\hypst$ and a proposition $\kw{p}: \cal{P}$, if the context
$\deno{\kw{all}~\Gamma}$ is sound and $\kw{knowns}~\kw{p}~\Gamma = \true$ then $\deno{\kw{p}}$ is sound.
\end{lemma}
\begin{proof}
By induction on the context list $\Gamma$.
\begin{itemize}
\item[] \textbf{Case} $\Gamma = \square$, trivial because we cannot have $\kw{knows}~p~\square = true$.
\item[] \textbf{Case} $\Gamma = x :: xs $, assume we have $H: \kw{knows}~p~(x::xs) = true$ and $H2: \deno{\kw{all}~(x::xs)}$.
We know by $H$, that $p$ is equal to $x$ or $p$ is equal to an element in $xs$. If $x$ is equal to $p$, one has $\deno{\kw{x}}$ from $H2$, hence we have $\deno{\kw{p}}$.
In the other case, $\deno{\kw{p}}$ follows from the induction hypothesis and H2.
\end{itemize}
\end{proof}


The function \kw{provable} implements our decision procedure. It checks if a proposition $goal: \cal{P}$ is provable in the context $\Gamma$.
%
\begin{flalign*}
&\kw{provable}~(goal: \cal{P})~(\hypst): \mathbb{B} &&\\
&\kw{provable}~\kw{pTrue}~\hyps \re \true &&\\
&\kw{provable}~\kw{pFalse}~\hyps \re \kw{knows}~\kw{pFalse}~\hyps &&\\
&\kw{provable}~(\kw{pAnd}~x~y)~\hyps \re (\kw{provable}~x~\hyps)~\&\&~(\kw{provable}~y~\hyps) &&\\
&\kw{provable}~(\kw{pOr}~x~y)~\hyps \re (\kw{provable}~x~\hyps)~||~(\kw{provable}~y~\hyps) &&\\
&\kw{provable}~(\kw{pImpl}~x~y)~\hyps \re \kw{provable}~y~(\kw{learn}~x~\hyps) &&\\
&\kw{provable}~(\kw{pOther}~i)~\hyps \re \kw{knows}~(\kw{pOther}~i)~\hyps ~||~\kw{knows}~\kw{pFalse}~\hyps  &&\\
\end{flalign*}

\begin{theorem}[Correctness of \kw{provable}]
For any $\kw{goal}: \cal{P}$ and context $\hypst$, if $\prf (\kw{provable}~\kw{goal}~\hyps = \true)$
then given a mapping $\sigma$, if the context $\prf (\deno{\kw{All}~\hyps})$ represent true propositions then the $\prf (\deno{\kw{goal}})$ is true.
\begin{proof} By induction on $p$.
\begin{itemize}
\item[] \textbf{Case} (p = \kw{pTrue}), we have to prove $\deno{\kw{pTrue}}$ which rewrites into $\top$ which hold trivially.
\item[] \textbf{Case} (p = \kw{pFalse}), It follow from the \cref{lemma:know_correct} with our hypothesis \kw{provable} \kw{pFalse} $\hyps = \true$ and $\deno{\kw{All}~\hyps}$ that $\deno{\text{pFalse}}$ hold.
\item[] \textbf{Case} (p = \kw{pAnd a b}), follow directly by induction hypothesis since \kw{provable} \kw{(pAnd a b)} $\hyps = \true$ implies $\kw{provable}~a~\hyps = \true$ and $\kw{provable}~b~\hyps = \true$.
\item[] \textbf{Case} (p = \kw{pOr}\,a\,b), follow directly by induction hypothesis since \kw{provable}\,\kw{pOr}\,a\,b\,$\hyps = \true$ implies $\kw{provable}\,a\,\hyps = \true$ or $\kw{provable}\,b\,\hyps = \true$.
\item[] \textbf{Case} (p = \kw{pImpl}\,a\,b), follow directly by induction hypothesis and \cref{lemma:learning_sound}.
\item[] \textbf{Case} (p = \kw{pOther}~i), let's consider an index $i: \N$, by the hypothesis $\prf (\kw{provable}~\kw{pOther}~i~\hyps = \true)$  we know that $(\kw{pAtom}\,i) \in \Gamma$ or $\kw{pFalse} \in \Gamma$. Therefore,
if $(\kw{pOther}\,i) \in \Gamma$ then by \cref{lemma:know_correct} and the hypothesis $\deno{\kw{All}~\hyps}$ we have $\deno{\kw{pOther}\,i}$. However,
in the case that $\kw{pFalse} \in \Gamma$, by using \cref{lemma:know_correct} and the hypothesis $\deno{\kw{All}~\hyps}$ we derive a contradiction.
\end{itemize}
\end{proof}
\end{theorem}

\begin{lstlisting}[language=Lambdapi, caption={Usage of Tauto}, label={lst:tauto-ex}]
symbol reify goal ≔ propReify □ goal; 

symbol tauto_aux [goal] ≔
  let res ≔ reify goal in provable_sound (res ₁) □ (res ₂);

symbol tauto ≔ #refine "(tauto_aux ⊤ᵢ ⊤ᵢ)";

private symbol example1: π ((⊤ ∧ ⊤) ⇒ ⊤ ∨ ⊤ ∧ (⊤ ⇒ ⊤)) ≔
begin eval tauto; end;
\end{lstlisting}

As shown in \cref{lst:tauto-ex}, we define a new tactic \kw{tauto} using a tactic script at line 5, and demonstrate its usage at lines 8-9.
\todo{ac: improve presentation of tauto tactic, but it is not a priority for now}
