\section{Tautologous rules and simple deduction}
\label{sec:elem-rules}

Many Alethe rules introduce tautologies or derive their conclusion from a single premise.
%
These rules are primarily used for clausification and to simplify Boolean connectives during
preprocessing.
%
\cref{fig:fun-c} illustrate the definition of $\cal{C}$ for the rules \kw{assume}, \kw{equiv\_pos2} and \kw{cong} from the running example of \cref{lst:smtexampleinput}.
The definitions use the following lemmas proved in our Lambdapi encoding:
\begin{itemize}
\item $\kw{cong}_1 :
    \begin{array}[t]{@{}l@{}}
        \Pi (a\,b \colon \set),\ \Pi f \colon \el\,a \ra \el\,b, \\
        \Pi x\,x',\ \prf (x = x') \ra \prf (f\,x = f\,x'),
    \end{array}$
\item $\kw{equiv\_pos2} : \Pi (\varphi_1~\varphi_2: \prop),\ \pid (\neg (\varphi_1 = \varphi_2) \veedot \neg \varphi_1 \veedot \varphi_2 \veedot \nil )$,
\item $\pid_l : \Pi [a : \set],\ \pid (a \cons \nil) \ra \prf a$.
\end{itemize}


\begin{figure}[bt]
  \scriptsize
  \begin{tabular}{@{}l|l@{}}
  \hline
  \multicolumn{2}{|l|}{R = \kw{assume}} \\ \hline
  \\
  $i.~\Gamma~\triangleright~ \varphi \quad (R)[]$  & $i : \pid (\E{\varphi} \veedot \nil)$  \\
  \\
  \hline
  \multicolumn{2}{|l|}{R = \kw{equiv\_pos2}} \\ \hline
  \\
  $i.~\Gamma~\triangleright~ \neg (a \approx b), \neg a, b  \quad (R)[]$  &
  $i : \begin{array}[t]{@{}l@{}}
          \pid (\neg (\E{a} = \E{b}) \veedot \neg \E{a} \veedot \E{a}  \veedot \nil) \\
          \coloneq \kw{apply}~\kw{equiv\_pos2}
       \end{array}$ \\
  \hline

  \multicolumn{2}{|l|}{R = \kw{cong}} \\ \hline
  \\
  $i_1 ~\quad \Gamma ~ \triangleright ~ t_1 \approx u_1 \quad (\dots) $   \\
  $i_2 ~\quad \Gamma ~ \triangleright ~ t_2 \approx u_2 \quad (\dots) $  \\
  \qquad \vdots  & \\
  $i_n. \quad \Gamma ~ \triangleright ~ t_n \approx u_n \quad (\dots)$  &  \\
  $j. ~\quad \Gamma ~ \triangleright~
      \begin{array}[t]{@{}l@{}}
          (f~t_1 \dots t_n) \approx (f~u_1 \dots u_n)\\
          (R~i_1~i_2 ~..~ i_n)[]
      \end{array}$ &
  $j : \begin{array}[t]{@{}l@{}}
        \pid (\E{f~t_1 \dots t_n} = \E{f~u_1 \dots u_n} \veedot \nil) \\
        \coloneq \kw{apply}~(\kw{cong}_n~f~\pid_l(i_1) \dots \pid_l(i_n)))
       \end{array}$
  \end{tabular}
  \caption{Translations for three representative Alethe commands.}
  \label{fig:fun-c}
\end{figure}

\begin{example}
  \cref{lst:smtexamplelambdapi} illustrates the result of our main function $\mathcal{C}$ applied to the first steps in the running example of \cref{lst:smtexampleinput}.
  In the code below, all the \texttt{assume} commands (corresponding to the \texttt{assert}s of the input problem) are transformed into constants by~$\mathcal{C}$. A symbol without a definition is considered as an axiom.
  Each step is encoded as an \lpinline{opaque symbol} that represents a lemma. Splitting the proof into multiple lemmas is beneficial for larger proofs because it reduces Lambdapi's checking time for the proof.
\end{example}

% \begin{minipage}{0.95\linewidth}
\begin{lstlisting}[mathescape=true, caption={Trace from \cref{lst:smtexampleinput} encoded in Lambdapi.}, label={lst:smtexamplelambdapi}, language=Lambdapi]
symbol p2 ≔ (p b); 
symbol p4 ≔ ((p a) = (p b));
symbol p5 ≔ (p a);
symbol a0 : Prf$\textcolor{purple}{\smash{^\bullet}}$ (p5 ⟇ ▩);
symbol a1 : Prf$\textcolor{purple}{\smash{^\bullet}}$ ((a = b) ⟇ ▩);
symbol a2 : Prf$\textcolor{purple}{\smash{^\bullet}}$ ((¬ ((p b))) ⟇ ▩);
opaque symbol t0 : Prf$\textcolor{purple}{\smash{^\bullet}}$ ((¬ ((p5 = p2))) ⟇ (¬ (p5)) ⟇ p2 ⟇ ▩) ≔
  begin apply equiv_pos2; end;
opaque symbol t1 : Prf$\textcolor{purple}{\smash{^\bullet}}$ (p4 ⟇ ▩) ≔
  begin apply $\smash{\lor_{i1}}$; apply cong$_1$ p ($\smash{\dot{\pi}_l}$ a1); end;

opaque symbol t2 : Prf$\textcolor{purple}{\smash{^\bullet}}$ (p_4 ⟇ ▩) ≔ 
begin
  have t0_t1 : Prf$\textcolor{purple}{\smash{^\bullet}}$ ((¬ (p_1)) ⟇ p_4 ⟇ ▩) 
  { apply resolution t0 t1 };
  have t0_t1_a0 : Prf$\textcolor{purple}{\smash{^\bullet}}$ (p_4 ⟇ ▩)
  { apply resolution t0_t1 a0 };
  refine t0_t1_a0;
end;

opaque symbol t3 : Prf$\textcolor{purple}{\smash{^\bullet}}$ ▩ ≔ 
begin
  have a2_t2 : Prf$\textcolor{purple}{\smash{^\bullet}}$ ▩ { apply resolution a2 t2 };
  refine a2_t2;
end;
\end{lstlisting}
% \end{minipage}


\subsection{Resolution rule}
\label{ssec:resolution}

\change{Alessio}{The algorithm to reconstruct resolution will be modified}

Binary resolution on ground clauses can be expressed as the following proof rule, which we have proved in Lambdapi.

\begin{lemma}[Resolution]\label{lemma:resolution}
Given $a,b: \texttt{Clause}$, and a pivot $x: \prop$, $\pid (x \veedot a)$ and $\pid (\neg x \veedot b)$ imply $\pid (a \cal{P} b)$.
\end{lemma}

% FIXME: remove float?
\begin{figure}[h]
  \centering
  \begin{tabular}{l c r}
  $i_1.~\triangleright$  & \qquad $l_1^1,\, \dots,\, l_{k^1}^1$ \qquad & (\dots)  \\
  $i_n.~\triangleright$  & \qquad $l_1^n,\, \dots,\, l_{k^n}^n$ \qquad & (\dots) \\
    & \vdots  &  \\
  $j.~~\triangleright$  & \qquad $l_{s_1}^{r_1},\, \dots,\, l_{s_m}^{r_m}$ \qquad & $(\kw{resolution}~i_1 \dots i_n)[]$
  \end{tabular}
  \caption{Resolution rule}
  \label{fig:resolution-rule}
\end{figure}


However, Alethe's \kw{resolution} rule, shown in \cref{fig:resolution-rule}, represents hyper-resolution applied to a set of ground first-order clauses $i_1 \dots i_n$,
where the resulting clause $l_{s_1}^{r_1} \dots l_{s_m}^{r_m}$ is obtained by a chain of predicate resolution steps that remove complementary literals from the input clauses, with double negations being removed implicitly.
For example, the formulas $\neg \neg \neg P$ and $\neg \neg P$ can serve as pivots during resolution.
The first formula is interpreted as $\neg P$ and the second as just $P$ to perform resolution steps.
Alethe allows resolution steps without providing the pivots; however, Carcara's elaborated proof incorporates the pivots as arguments in the resolution rule, eliminating the need for an additional intermediate step to search for the pivots in our translation to Lambdapi.
In addition, pivots may appear anywhere in a clause rather than just as the head literal. Hence, Alethe \kw{resolution} involves reasoning modulo associativity and commutativity (AC) on clauses.

In \cite{ColtellacciMD24}, we simulated Alethe's \kw{resolution} rule as compositions of multiple binary resolution steps, combined with additional proof steps for justifying reasoning modulo AC used to move pivots to the heads of clauses.
However, the practical application of this approach suffered from inefficiency and did not allow us to reconstruct proofs of some benchmarks in SMT-LIB that involved hundreds of clauses in a single resolution.
In the following, we present an approach where we prove clause permutation through \emph{proof by reflection}\index{proof by reflection}, enabling more efficient pivot movement.
Given the central role of \emph{proof by reflection} in our translation, we dedicate the following section to a more detailed introduction of this concept, which is key to reconstructing certain proof rules in the Alethe format. 

\subsection{Proof by reflection}
\label{ssec:reflection-intro}

Proof by reflection~\cite{reflection-origin-coq} is a technique for constructing certified procedures for automated reasoning by reducing the verification of a logical statement to a symbolic computation.
This method is particularly applicable to two broad classes of problems. In the first class, we consider a predicate $P \colon T \to \prop$, where $T$ is a data type,
together with a semi decision procedure $f: T \to \mathbb{B}$ (or $\tt{Comp}$) such that, whenever $f$ returns $\tt{true}$ on input $x$, the predicate $P(x)$ holds.
Formally, this relationship is captured by the following correctness theorem:

\begin{equation*}
\mathop{f\_correct} \colon \Pi x \colon T, \prf (f~x = \tt{true}) \ra \prf (P~x).
\end{equation*}

Hence, to establish $P~y$ for a particular value $y$, it suffices to verify that $f(y)$ reduces to  $\tt{true}$.
In that case, we can simply apply the lemma $\mathop{f\_correct}$ to $y$ along with a proof that $true = true$ i.e. $(\mathop{eq\_refl} \tt{true})$ with $eq\_refl: \Pi [a \colon \set], \Pi (x: \el\,a), \prf (x = x)$. 
The resulting proof of $P~y$ is thus given by:

\begin{equation*}
\mathop{f\_correct} ~y~ (\mathop{refl} \tt{true}) \colon P~y
\end{equation*}

As an illustration, consider the property of a natural number being even. In Lambdapi, this can be expressed using a computable boolean function $\texttt{even} \colon \N \ra \B$ that checks whether a given number is even.
The connection between the boolean value and the logical property is established through a correctness lemma stating that if \texttt{even n = true}, then $n$ is even.
Thus, to prove that a specific number, such as $4$, is even, one can reduce the goal to the boolean check \texttt{even 4 = true}, which is decidable by computation.
Applying the correctness lemma then lifts this computational fact back into the logical framework to conclude that $4$ is even.
This approach automates routine reasoning steps involving decidable predicates, allowing for concise and efficient proofs.
This first class of reflection is particularly suited for properties such as arithmetic equalities, inequalities, and simple inductive predicates.

The size of such a proof only depends on the size of a particular argument $y$ and does not depend on the number of implicit $\equivL$ steps: explicit rewriting steps have been replaced by implicit $\equivL$ reductions.
The efficiency of this technique of course strongly depends on the efficiency of the system to reduce the application of the decision procedure $f(y)$, hence on the efficiency of the decision procedure ($f$) itself.


Moreover, while the proof term of the correctness lemma for $f$ may be large, it needs to be constructed only once. This proof can be shared across all instantiations and does not require rechecking by the type-checker in subsequent uses.

\medskip

The second class of problems where computation can help is the class of algebraic proofs such as proofs relying on rewriting modulo the associativity or the commutativity of some operators e.g. disjunction $(\lor)$ or conjunction $(\land)$.
For these proofs, we again consider a type $B: \set$ and we exhibit an "abstract type" $A: \set$, with two functions $\mathop{denote} \colon {\el}\,A \ra {\el}\,B$ and $g: \el{}\,A \ra \el{}\,A$.
The function $\mathop{denote}$ is an interpretation function that we can use to associate terms in the concrete type $B$ with abstract terms of type $A$.
The function $g$ reasons on the abstract terms. The reflection process relies on a theorem that expresses that the function $g$ does not change the value of the interpreted
term:

\begin{equation*}
  g\_ident : \Pi x: A, \prf (\mathop{denote}(g~x) = \mathop{denote} x)
\end{equation*}

Thus, to prove that two terms $t_1$ and $t_2$ are equal in $B$ , we only need to show that they are the images of two terms $a_1$ and $a_2$ in $A$ such that $g\,a_1 = g\,a_2$.
As an illustration of this second class of proofs by reflection, consider the commutativity of disjunction: for any two propositions $P$ and $Q$, we wish to prove that $P \lor Q$ is logically equivalent to $Q \lor P$.
To apply reflection, we first define an \emph{abstract} syntax for formulas, for instance, a type $\mathsf{Monoid}$ with constructors for atomic propositions and for disjunction.
We then define an \emph{interpretation function} $\mathsf{denote} \colon \mathsf{Monoid} \to \prop$ that maps abstract formulas to their logical meaning. 
Next, we define a normalization function $\mathop{norm}: \mathsf{Monoid} \to \mathsf{Monoid}$ that rewrites disjunctions into a canonical order, such as ordering operands lexicographically.
The key theorem states that this normalization preserves meaning:
\[
\mathsf{norm\_mono} : \forall x : \mathsf{Monoid}, \mathsf{denote}(\mathop{norm} x) = \mathsf{denote}(x).
\]
Hence to prove that $P \lor Q$ and $Q \lor P$, are logically equivalent, it suffices to represent them as abstract expressions $m_1$ and $m_2$ of type $\mathsf{Monoid}$, apply the function $\mathop{norm}$ with the lemma $\mathsf{norm\_mono}$ to normalize both, and check that $\mathop{norm}(m_1) = \mathop{norm}(m_2)$.
By correctness of the interpretation, their meanings must then coincide.


In this thesis, we make use of both classes of reflection to encode certain \texttt{Alethe} rules. For example, the reconstruction of arithmetic steps (\textbf{LIA} and \textbf{LRA}) and bitvector (\textbf{BV}) Alethe rules primarily relies on the first class,
while the permutation of clauses for the \texttt{resolution} rule relies on the second class.

\subsection{Computing hyper-resolvents with proof by reflection}
\label{ssec:refl-reso}


Whereas the technique described in \cref{ssec:resolution} can be used to reconstruct resolution proofs in Alethe proof traces, it suffers from poor scalability.
Specifically, the permutation proof generated for pivot movement due to reasoning modulo AC may become excessively lengthy. We will now describe an alternative technique based on computational reflection that allows us to prove the permutation of clauses efficiently.
Relying on the rewriting facilities of Lambdapi, we implemented a decision procedure that checks equality between clauses by rewriting modulo AC-canonization.

The core idea is to put clauses with pivots in different positions into a canonical form, allowing them to be compared. To achieve this, we present a proof by reflection of the second class in the following.
If two clauses are determined to be equal, the current clause can be substituted with one where the pivot is placed at the head position, allowing for the subsequent application of \cref{lemma:resolution}.
To handle associative and commutative symbols, Lambdapi provides the modifiers \lpinline{associative commutative} \info{ac}{the introduction of Lambdapi will present AC and its builtin order},
ensuring that terms are systematically placed into a canonical form given a builtin ordering relation, following the technique described in \cite{ACorigin} and \cite[\S 5]{univAC}.

Additionally, as discussed in \cref{sect:elabration-resolution} \change{ac}{Need Alethe intro}, the solver can introduce implicit $\tt{contraction}$ steps between binary resolution steps.
We leverage the elaboration process in Carcara to avoid implementing a proof by reflection for $\tt{contraction}$, which would require structures not present in the standard library of Lambdapi to reason about collections modulo duplicate terms, such as finite sets.

\begin{figure}[t]
  \centering
  \begin{tikzcd}[column sep=tiny]
    {C_1 =_{\bb{C}} C_2} & {\bb{C}} && {\bb{C}} & {[C_1] =_{\bb{C}} [C_2]} \\
    \\
    {c_1 =_{\tt{Clause}} c_2} & \kw{Clause} && \kw{Clause} & {\den{[C_1]} =_{\tt{Clause}} \den{[C_2]}}
    \arrow["{{[\_]}}", dotted, from=1-2, to=1-4]
    \arrow["{{\den{\_}}}", from=1-4, to=3-4]
    \arrow["{{\reify{\_}}}"', from=3-2, to=1-2]
    \arrow["{\Leftrightarrow}"{marking, allow upside down}, draw=none, from=3-2, to=3-4]
  \end{tikzcd}
  \caption{Checking resolution steps via reification in the algebra $\bb{C}$.}
  \label{fig:reflective-process}
\end{figure}

The \cref{fig:reflective-process} provides an overview of the realization of this technique in Lambdapi.
It relies on \emph{reifying} clauses into terms of an algebra $\bb{C}$, using the operator $\reify{}$ defined in \cref{def:reify-def},
and we denote by $[t]$ the normalization of term $t$ done from \lpinline{associative commutative} modifiers.
This normalization corresponds to the function $g$ introduced in \cref{ssec:reflection-intro}.
Since we rely on the lambda modifiers, normalization is implicitly handled by $\lpm$, and thus the function $[_]$ is simply the identity: $[_]: \bb{C} \rightarrow \bb{C} \coloneq \lambda x., x$.

\begin{definition}[The abstract type $\bb{C}$]
The \emph{abstract type} $\bb{C}$ is an inductive type defined as follows:
\begin{align*}
&\bb{C} : \type \\
&|~\eps: \bb{C} \\
&|~\kw{P}: \prop \ra \bb{C} \\
&|~\sqcup: \bb{C} \ra \bb{C} \ra \bb{C} \quad \text{(written infix)} \\
&\kw{clauseAC} : \set \\
&\el\, \kw{clauseAC} \re \bb{C} \\
\end{align*}
where the constructor $\eps: \bb{C}$ representing $\nil$ and the constructor $\sqcup$ is declared \lpinline{associative commutative}, which is the analogue of $\cons$.
Propositions are injected into the algebra by the operator $\tt{P}$.
\end{definition}

\begin{definition}[reification function]
\begin{align*}
& \reify{}: \texttt{Clause} \ra \bb{C} \\
&\reify{(x \cons y)} \re \reify{x} \,\sqcup \reify{y} \\
&\reify{ \blacksquare } \re \epsilon \\
&\reify{ x } \re \cal{P}(x)
\end{align*}
where the $\reify{}$ is defined with the modifier \lpinline{sequential}.
\label{def:reify-def}
\end{definition}
\graffito{x}
It then remains to decide the equality of two terms in $\bb{C}$, and this is accomplished using the operator $=_\bb{C}$ introduced in \cref{def:eqC}.
Its definition relies on Boolean conjunction \kw{andb} (written infix), which is predefined in Lambdapi's standard library, as well as on the operator \kw{eq} that checks equality of two terms of type $\prop$.

\begin{definition}[decidable equivalence relation]
The operators $=_\bb{C} : \bb{C} \ra \bb{C} \ra \kw{bool}$ is defined by the following rewrite rules.

\begin{align*}
&x_1 \sqcup y_1 =_\bb{C} x_2 \sqcup y_2 \re (x_1  =_\bb{C} x_2) ~\kw{andb}~ (y_1  =_\bb{C} y_2) \\
&\_ \sqcup \_ =_\bb{C} \epsilon \re \false \\
&\_ \sqcup \_ =_\bb{C} \cal{P}(\_) \re \false \\
&\cal{P}(x) =_\bb{C} \cal{P}(y) \re (\kw{eq}~x~y) \\
&\cal{P}(\_) =_\bb{C} \_ \sqcup \_ \re \false \\
&\cal{P}(\_) =_\bb{C} \epsilon \re \false \\
&\epsilon =_\bb{C} \epsilon \re \true \\
&\epsilon =_\bb{C} \cal{P}(\_) \re \false \\
&\epsilon =_\bb{C} \_ \sqcup \_ \re \false
\end{align*}
with:
\begin{align*}
&\eq~x~x~ \re \true  & \kw{andb}~\kw{true}~\kw{true} \re \kw{true} \\
&\eq~x~y~ \re \false & \kw{andb}~\kw{false}~\_ \re \kw{false} \\
& & \kw{andb}~\_ \kw{false} \re \kw{false} 
\end{align*}
\label{def:eqC}
The binary operator \kw{eq} is declared as \kw{sequential} so that the second rewrite rule will be applied only if the first one fails.
Its definition ensures that $\kw{eq}~x~y$ holds if and only if the two propositions $x$ and $y$ are identical.
\end{definition}

We now state the correctness theorem, demonstrating that a given clause is a permutation of another.

\begin{lemma}[P-injective]\label{lem:p-inj}
For any $x, y: \prop$, if $\kw{istrue}(\cal{P}(x) =_{\bb{C}} \cal{P}(y))$ then $x = y$.
\begin{proof}
From the definition of $=_{\bb{C}}$ that uses a non-linear sequential rewriting rule,
it follows directly that if $\cal{P}(x) =_{\bb{C}} \cal{P}(y)$ is true then $x$ and $y$ have to be the same.
\end{proof}
\end{lemma}


\begin{theorem}[Correctness]\label{lem:eq-C}
For $c_1, c_2 : \tt{Clause}$, if $\tt{istrue} (\reify{c_1} =_{\bb{C}} \reify{c_2})$ then $\cal{F}\,c_1 = \cal{F}\,c_2$.
\end{theorem}
\begin{proof}
By induction on $c_1$ and $c_2$.
\begin{itemize}
  \item First suppose $c_1 = \blacksquare$ and $c_2 = \blacksquare$. We must show that $\tt{istrue} (\epsilon =_{\bb{C}} \epsilon)$ implies $\cal{F}\, \blacksquare = \cal{F}\, \blacksquare$ which follows directly by reflexivity.
  \item Next, suppose $c_1 = \blacksquare$ and $c_2 = x \veedot xs$. Then it follows from the the rewriting rules of $=_{\bb{C}}$ that we have a contradiction since we supposed that $\tt{istrue}(\epsilon =_{\bb{C}} \cal{P}(x) \sqcup \reify{xs})$.
  \item The case where $c_1 = x \veedot xs$ and $c_2 = \blacksquare$ is symmetrical.
  \item Lastly, suppose $c_1 = x \veedot xs$ and $c_2 = y \veedot ys$, and
  assume that $\tt{istrue}(\reify{c_1} =_{\bb{C}} \reify{c_2})$. 
  Let $d_1 = \reify{(x \veedot xs)}$ and $d_2 = \reify{(y \veedot ys)}$, then $d_1$ must be of the form 
  $\cal{P}(u) \sqcup \reify{u'}$ and $d_2$ must be of the form $\cal{P}(v) \sqcup \reify{v'}$ where 
  the clauses $u'$ and $v'$ are shorter than $xs$ and $ys$, respectively, and such that 
  $\cal{F}\,(u \veedot u') = \cal{F}\,(c_1)$ and similarly
  $\cal{F}\,(v \veedot v') = \cal{F}\,(c_2)$.
  Moreover, from the assumption $\tt{istrue}(d_1 =_{\bb{C}} d_2)$ and \cref{lem:p-inj} it follows that 
  $u = v$, and by induction hypothesis we obtain that $\cal{F}\,u' = \cal{F}\,v'$. Taking everything
  together, we finally obtain that $\cal{F}\,c_1 = \cal{F}\,c_2$.
\end{itemize}
\end{proof}

\begin{example}
The code in \cref{lst:new-reso} demonstrates how \cref{lem:eq-C} is used to move the pivot within a clause.
It introduces a proof of clause permutation using a cut at line 8, where \cref{lem:eq-C} is used to show, by computation, that the clause of step $t1$ is a permutation of another clause with the pivot at the head.
Line 10, the $\tt{trivial}$ is the constructor for the proposition $\top$, and it concludes the proof if the $=_{\bb{C}}$ of \cref{lem:eq-C} returns $\tt{true}$. % AC: Should we mention again that this is because (istrue true) -> True?
Additionally, we utilize the lemma $\tt{subst\_equiv\_clause}$, which states that for any clauses $c_1$ and $c_2$, if $\cal{F}(c_1) = \cal{F}(c_2)$ and there exists a proof of $c_1$, then we can derive a proof of $c_2$.
Thus, we combine in the $\tt{resolution}$ (line 12) this lemma with the permutation proof of $t1$ and the clause of $t2$ to derive the clause asserted by $t3$.

\begin{lstlisting}[mathescape=true, caption={Reflective resolutions}, label={lst:new-reso}, language=Lambdapi]
opaque symbol t1 : Prf$\textcolor{purple}{\smash{^\bullet}}$ (a ⟇ b ⟇ p ⟇ ▩) ≔  begin ... end;

opaque symbol t2 : Prf$\textcolor{purple}{\smash{^\bullet}}$ ((¬ (p)) ⟇ c ⟇ d ⟇ ▩) ≔  begin ... end;

opaque symbol t3 : Prf$\textcolor{purple}{\smash{^\bullet}}$ (a ⟇ b ⟇ c ⟇ d ⟇ ▩) ≔ 
begin
have t1_t2 : Prf$\textcolor{purple}{\smash{^\bullet}}$ (a  ⟇ b  ⟇ c  ⟇ d ⟇ ▩) {
have t1_perm : Prf$\textcolor{purple}{\smash{}}$ (($\cal{F}$ (a ⟇ b ⟇ p ⟇ ▩)) = ($\cal{F}$ (p ⟇ a ⟇ b ⟇ ▩))) {
  apply cl_perm_correct (a  ⟇ b  ⟇ p ⟇ ▩) (p  ⟇ a  ⟇ b ⟇ ▩);
  apply trivial;
};
apply resolution (subst_equiv_clause t1_perm t1) t2;
};
refine t1_t2;
end;
\end{lstlisting}

\end{example}

\subsection{Simplification rules}

The Alethe format includes rules that encode operator-level simplifications typically performed by SMT solvers. \info{ac}{The introduction of Alethe will contain the description of RARE, so we do not need to introduce it here anymore}
A key challenge arises from the fact that the solver does not explicitly specify which transformations are applied, nor the order in which they are performed. This makes certain rules, such as \tt{or\_simplify}, difficult to certify. 
For instance, the rule \texttt{or\_simplify}, presented in \cref{eqn:or-simp}, simplifies disjunctions by applying equivalence-preserving transformations repeatedly until a fixpoint is reached. Its general form is:

\begin{equation}\label{eqn:or-simp}
i. \quad \Gamma~\triangleright \quad l_1 \lor \dots \lor l_n ~ \approx \psi \quad \texttt{or\_simplify}
\end{equation}
where $\psi$ is the transformed term. The possible transformations are:
\begin{enumerate}
\item[(1)] $\bot \lor \dots \lor \bot \Rightarrow \bot$
\item[(2)] $l_1 \lor \dots \lor l_n \Rightarrow l_1' \lor \dots \lor l_m'$ where the right-hand side has some $\bot$ literals removed.
\item[(3)]  $l_1 \lor \dots \lor l_n \Rightarrow l_1' \lor \dots \lor l_m'$ where the right-hand side has some repeated literals removed.
\item[(4)] $l_1 \lor \dots \lor \top \lor \dots \lor l_n \Rightarrow \top$
\item[(5)] $l_1 \lor \dots \lor l_i \lor \dots \lor l_j \lor \dots \lor  l_n \Rightarrow \top$ where $l_i = \neg^{2p} x$, $l_j = \neg^{2q+1} x$.
\end{enumerate}
\info{ac}{reconstruction of or\_simplify need to be improve so I still prove not\_simplify only has example}

To manage these transformations, we leverage the RARE language provided by cvc5 \cite{rare}, which supports elaborated rewrite proofs.
As detailed in \cref{sec:rare-intro}, RARE generates explicit proof terms on demand, using built-in rewrite rules.
The RARE rule used and its arguments are made explicit in the \smtinline{:args} parameter of the rule $\kw{rare\_rewrite}$ in the proof trace.

However, in some cases, cvc5 may emit proof traces using the legacy simplification rules instead of RARE. In such situations, we reconstruct the simplification steps using tactic scripts, as introduced in \cref{ch:intro-lambdapi}.
These scripts allow us to interpret fixpoint-style transformations.

To illustrate this process, we describe how we reconstruct a step involving the \kw{not\_simplify} rule, summarized in \cref{fig:not-simplify}.
Each transformation associated with this rule is implemented by a separate lemma e.g., \kw{not\_simplify1}, \kw{not\_simplify2}, etc. which are then tried sequentially on the current goal.

\begin{figure}
  \footnotesize
  \begin{tabular}{l|l}
  \hline
  \multicolumn{2}{|l|}{R = \kw{not\_simplify}} \\ \hline
  \\
  $i. \quad \Gamma~\triangleright \quad \neg \psi \approx \varphi \quad (\kw{not\_simplify})$ & $\C{i} = \pid (\neg \E{\psi} = \E{\varphi} \cons \nil) $ \\
  $(1) \neg \neg \varphi \Rightarrow \varphi$ &  $\is$ \lpinline{eval not_simplify} \\
  $(2) \neg \bot \Rightarrow \top$  &   \\
  $(3) \neg \top \Rightarrow \bot$  & 
  \end{tabular}
  \caption{Translating the command \kw{not\_simplify}.}
  \label{fig:not-simplify}
\end{figure}

To apply these tactics sequentially, we define a meta-tactic $\mathop{\mathtt{applyAny}}$ that attempts each tactic in the list until one succeeds: 

\begin{align*}
&\mathop{\mathtt{all\_not\_simplify}} \is (\rewrite \kw{not\_simplify1}) \colon\colon  \\
&\quad (\rewrite \kw{not\_simplify2}) \colon\colon (\rewrite \kw{not\_simplify3})
\end{align*}

The combinator $t_1 \orelse t_2$ tries $t_1$ on the current goal; if it fails to make progress, $t_2$ is applied instead. We then define the tactic for reconstructing the simplification step as follows:

\begin{align*}
&\mathop{\mathtt{applyAny}} : \bb{L} \, \kw{tactic} \ra \kw{Tactic} \\
&\mathop{\mathtt{applyAny}} \Box \re \fail \\
&\mathop{\mathtt{applyAny}} (\kw{t} \colon\colon \kw{ts}) \re t \orelse (\mathop{\mathtt{applyAny}} \kw{ts}) \\
\end{align*}

The $t_1 \orelse t_2$ are evaluated respectively to $t_1$ and $t_2$ which must be tactic values.
The tactic value $t_1$ is applied in the current goal and if it fails to progress then $t_2$ is applied.

\begin{align*}
&\mathop{\mathtt{not\_simplify}} \is \repeatT (\mathop{\mathtt{applyAny}} \mathop{\mathtt{all\_not\_simplify}}) \\
&\quad \andT \reflexivity
\end{align*}

Here, $\repeatT$ repeatedly applies the simplification tactics until none can be applied further.
Finally, a step using the \kw{not\_simplify} rule can be reconstructed as shown in \cref{fig:not-simplify}, by simply running the tactic script using the meta-tactic $\eval$.

\subsection{N-ary rules}

\begin{table}
\centering
\caption{N-ary operators rules}
\begin{tabular}{ll}
Rule & Description \\ \hline
and (i)[k] & $i. \triangleright \quad (\varphi_1 \land \dots \land \varphi_n)$ \\
    & $j. \triangleright \quad \varphi_k $ with $1 \leq k \leq n$\\
not\_and (i) & $i. \triangleright \quad \neg (\varphi_1 \land \dots \land \varphi_n)$ \\
    & $j. \triangleright \quad \neg \varphi_1, \dots, \neg \varphi_n $\\
not\_or (i)[k] & $i. \triangleright \quad \neg (\varphi_1 \lor \dots \lor \varphi_n)$\\
    & $j. \triangleright \quad \neg \varphi_k$ with $1 \leq k \leq n$\\
and\_pos [k] & $\triangleright \quad \neg (\varphi_1 \land \dots \land \varphi_n), \varphi_k$ with $1 \leq k \leq n$ \\
and\_neg & $\triangleright \quad (\varphi_1 \land \dots \land \varphi_n), \neg \varphi_1, \dots, \neg \varphi_n$ \\
or\_pos & $\triangleright \quad \neg (\varphi_1 \lor \dots \lor \varphi_n), \varphi_1, \dots, \varphi_n$ \\
or\_neg [k] & $\triangleright \quad \neg (\varphi_1 \lor \dots \lor \varphi_n), \neg \varphi_k$ with $1 \leq k \leq n$ \\
\end{tabular}
\label{table:nary-rules}
\end{table}

The Alethe format includes n-ary tautological rules—relying on arbitrary n-ary conjunctions and disjunction as outlined in \cref{table:nary-rules}.
A direct approach to reconstruct these rules would involve generating tactic scripts during the translation in Carcara.
However, this could lead to proofs requiring hundreds of tactic applications.
To address this, we adopt an alternative strategy: reconstructing these rules via a \emph{proof by reflection} of the first kind.
We illustrate our approach by detailing the reconstruction of \tt{and\_pos}.
In our encoding, n-ary conjunctions and disjunctions are interpreted as values of the abstract type $\kw{list},o$.
We begin by introducing the following configuration:

\begin{itemize}
  \item We define the function $\kw{indexes}: \Pi [a: \set],\, \el\,\bb{L}~a, \ra \bb{L}~\kw{nat}$ that maps a list of elements
  to a list of natural numbers representing the positions (or indices) of the elements in the original list.
  The behavior of indexes is independent of the values of the elements - it is purely structural.
  So, even if the list contains duplicated elements, the indexes function simply returns the list of their positions, not caring whether elements are equal or not.

  \begin{example}[indexes]
  \[
  \mathop{\mathtt{indexes}} (x \colon\colon y \colon\colon x  \colon\colon z \colon\colon \Box) \equivL 0 \colon\colon 1 \colon\colon 2 \colon\colon 3 \colon\colon \Box
  \]
  \end{example}
  \item The function $\in_k : \N \rightarrow \bb{L}~\kw{nat} \rightarrow \bb{B}$  determines whether a given index is present in a list.
  \item The denotation function $\kw{conj}: \bb{L}~o \ra \prop$ decodes a list of propositions into an n-ary conjunction.
  \item The total function $\kw{literal}: \Pi (k: \N),\, \bb{L}~o \ra \prop$ returns the $k$-th element of the list, or $\bot$ otherwise.
\end{itemize}

% ∈ₙ : τ nat → 𝕃 nat → 𝔹

% select (id : τ nat) (cnf: 𝕃 o) : π (id ∈ₙ (indexes cnf)) → π (conj cnf) → π (literal cnf id) ≔
\begin{lemma}[select]
Let $k : \N$ be an index and $c : \bb{L}~o$ a reified conjunction, represented as a list of literals. If
\[
  \prf (\kw{istrue}~(k \in_k (\kw{indexes}~c))) \text{ and } \prf (\kw{conj}~c)
\]
then
\[
  \prf (\neg (\kw{conj}~c) \lor (\kw{literal}~k~c))
\]
That is, if a literal indexed by $k$ appears in the reified conjunction $c$ and the conjunction as a whole holds, then the corresponding literal must also hold.
\label{lemma:select}
\begin{proof}
\question{ac}{Do I need to provide the proof}  
\end{proof}
\end{lemma}

% and_pos2 (id : τ nat) (cnf: 𝕃 o) : π (id ∈ₙ (indexes cnf)) → π (¬ (conj cnf) ∨ (literal cnf id)) ≔
\begin{lemma}[and\_pos]
Given an index $k: \N$ and a list $c: \bb{L}~o$, If
\[
  \prf (\kw{istrue} (k \in_k (\kw{indexes}~c)))
\]
then
\[
  \prf (\neg (\kw{conj}~c) \lor (\kw{literal}~k~c))
\]
\begin{proof}
The proof is direct with \cref{lemma:select}.
\end{proof}
\label{lem:and-pos}
\end{lemma}



\begin{figure}
\centering
\begin{tabular}{|l|}
\hline
  R = \kw{pos\_and} \\ \hline
  $i. \triangleright \quad \neg (\varphi_1 \land \dots \land \varphi_n),~ \varphi_k$ \quad (\kw{pos\_and})[k] \\ \hline
  \begin{tabular}[t]{@{}l}
    $i: \pid (\neg (\E{\varphi_1} \land \dots \land \E{\varphi_n}) \cons \E{\varphi_k} \cons \nil ) $\\
    begin
    \ \ \begin{tabular}[t]{@{}l}
          apply $\lor_{i1}$;\\ %
          apply $\kw{and\_pos}~\E{k}$ $(\E{\varphi_1} \colon\colon \dots \colon\colon \E{\varphi_n} \colon\colon \Box)~ \top_i$
        \end{tabular}\\
    end
  \end{tabular}
  \\\hline
\end{tabular}
\caption{Translating the \kw{pos\_and} command.}
\label{fig:pos-and-recon}
\end{figure}

We can reconstruct the proof such as described in \cref{fig:pos-and-recon}.
We first need to retrieve a disjunctions from a clause by applying the disjunction introduction rule $\lor_{i1}$,
and then we apply \cref{lem:and-pos} with the index $k$ given by Alethe, the conjunction reified $(\E{\varphi_1} \colon\colon \dots \colon\colon \E{\varphi_n} \colon\colon \Box)$ and a proof that $\prf (k \in_k (\kw{indexes}~c))$
which should reduce to $\top$.

% Proof by reflection

\subsection{Quantifiers}

\begin{figure}
\centering
\begin{tabular}{|l|}
\hline
  R = \kw{sko\_forall} \\ \hline
  %
  \ruleAlethe{i}{(\neg \forall \bar{x},\, \varphi) \lor (\varphi[\bar{t}])}{forall\_inst} \\ \hline
  %
  \begin{tabular}[t]{@{}l}
    $i: \pid (\E{\varphi} = \E{\psi} \cons \nil ) \dots $\\
    $k: \pid (\forall x_1,\dots~x_n, \E{\varphi} = \E{\psi} \cons \nil) \coloneq$\\
    begin
    \ \ \begin{tabular}[t]{@{}l}
          apply $\lor_{i1}$;\\ %
          apply imply\_to\_or;\\
          assume H;\\
          refine $\forall_e H$\\
        \end{tabular}\\
    end
  \end{tabular}
\\ \hline
\end{tabular}
\caption{Translating the \kw{forall\_inst} command.}
\label{fig:forall-inst-recon}
\end{figure}

The Alethe format defines rules for quantifier instantiation, substitution, and other manipulations of bound variables.
For instance, the rule \tt{forall\_inst} is used to express quantifier instantiation. It produces a unit clause with a formula of the form $(\neg \forall \bar{x},\, \varphi) \lor (\varphi[\bar{t}])$,
where $\varphi$ is a term containing the free variables $\bar{x}$, and each term $t$ is a ground term of the same sort as the corresponding variable $x$.

\begin{example}[Quantifier instantiation]
The following example shows a simple Alethe proof expressed in the abstract
notation used in this document. It uses quantifier instantiation and resolution to show a
contradiction. The paragraphs below describe the concepts necessary to understand the
proof step by step.
\begin{center}
\begin{tabular}{ l l r}
a0.& $\triangleright \quad \forall x, (P~x)$  & \kw{(assume)}[\,] \\
a1.& $\triangleright \quad \neg(P~x)$  & \kw{(assume)}[\,] \\
t1.& $\triangleright \quad \neg(\forall\,x, P~x) \lor (P~a)$  & \kw{(forall\_inst)}[($x$,$a$)] \\
t2.& $\triangleright \quad \neg(\forall\,x, P~x), (P~a)$  & \kw{(or t1)}[\,] \\
t3.& $\triangleright \quad \bot$ & \kw{(resolution a0 a1 t2)}[\,] \\
\end{tabular}
\end{center}
\end{example}

As described \cref{ssec:encoding-prop}, we encode universal and existential quantifiers using a shallow embedding into Lambdapi's dependent function type $\Pi A, B$.
This allows us to reconstruct the rule \tt{forall\_inst} directly, as shown in \cref{fig:forall-inst-recon}. \question{ac}{need more details?}

\subsection{Skolemization}


\begin{figure}
  \centering
\begin{tabular}{|l|}
\hline
  R = \kw{sko\_forall} \\ \hline
  %
  \begin{tabular}[t]{@{}l}
    $i.$  \begin{tabular}[t]{@{}l}
      $\Gamma, x_1 \mapsto \epsilon\,x_1. \neg \varphi \dots x_n \mapsto \epsilon\, x_n. \neg \varphi$\\
      $\triangleright \varphi \approx \psi~(\dots)$
    \end{tabular}\\
    $k.$ $\Gamma \quad \forall x_1, \dots x_n.~ \varphi \approx \psi$ \qquad $(R)$
  \end{tabular} \\ \hline
  %
  \begin{tabular}[t]{@{}l}
    $i: \pid (\E{\varphi} = \E{\psi} \cons \nil ) \dots $\\
    $k: \pid (\forall x_1,\dots~x_n, \E{\varphi} = \E{\psi} \cons \nil) \coloneq$\\
    begin
    \ \ \begin{tabular}[t]{@{}l}
          apply $\lor_{i1}$;\\ %
          (\,\begin{tabular}[t]{@{}l}
            apply \kw{sko\_forall}; assume $x_i$ $H_i$; rewrite $H_i$;\,)$^n$
          \end{tabular} \\
          reflexivity;
        \end{tabular}\\
    end
  \end{tabular}
\\ \hline
\end{tabular}
\caption{Translating the \kw{sko\_forall} command.}
\label{fig:sko-forall}
\end{figure}


The skolemization rules \kw{sko\_forall} and \kw{sko\_exists} replace the bound variables with \kw{choice} terms instead of fresh symbols. Note that some functions can introduce fresh symbols in the proof trace with the command \smtinline{(define-fun)}.
Nevertheless, Carcara eliminates those commands by unfolding the definition during the elaboration process.
Moreover, cvc5 preprocesses the input formula by converting existential quantifiers into negated universal quantifiers, thus, the proof traces we are working with only use the \kw{sko\_forall} rule.

We now prove a lemma that underlies the translation of the Alethe rule \kw{sko\_forall}.
We first prove that the universal quantifier can be interpreted by the epsilon operator in our encoding.

\smallskip

\begin{lemma}[Reduction of $\forall$ to choice]\label{lemma:eps-forall}
For every $a : \set$ and predicate $p: \el~a \ra \prop$, $(\forall x, p~x) \Leftrightarrow p~(\epsilon\,x, \neg (p~x))$
\end{lemma}
\begin{proof}
\begin{itemize}
\item[\textbf{``$\Rightarrow$'':}]  We have to prove that $\forall x, p\,x$ implies $p(\epsilon\,x, \neg (p\,x))$, which follows immediately from the hypothesis.
\item[\textbf{``$\Leftarrow$'':}]  We prove the contrapositive assertion. Assuming $\neg \forall x, p\,x$, we obtain $\exists x, \neg p\,x$. Combining the elimination rule for $\exists$ and the introduction rule $\epsilon_i$, we conclude $\neg p(\epsilon\,x, \neg (p~x))$.
\end{itemize}
\end{proof}

We now prove the Skolemization lemma for the universal quantifier that used to reconstruct steps using the rule \kw{sko\_forall}.

\smallskip

\begin{lemma}[skolemize forall]\label{lem:sko-forall}
For any $a : \set$, predicate $p : \el{}\,a \ra \prop$ and $q : \prop$, if for every $x: \el{}\,a$, $\prf (x = (\epsilon \, y, \neg (p\,y)))$ implies $\prf (p\,x = q)$,  we have that $\prf ((\forall x, p\,x) = q)$.
\end{lemma}
\begin{proof} We apply rule \kw{prop\_ext} and then prove both directions,
\begin{itemize}
\item[\textbf{``$\Rightarrow$'':}]  We have to prove that $\forall x, p~x$ implies $q$. By \cref{lemma:eps-forall}, the former is equivalent to $p~(\epsilon~\neg (p~x))$, and together with the assumption of the lemma, we obtain $q$.
\item[\textbf{``$\Leftarrow$'':}]  Conversely, we have to prove that $q$ implies $\forall x, p~x$. For $x$ defined as $(\epsilon~y, \neg (p~y))$, we have $p~x = q$ by assumption and thus obtain $p~(\epsilon~y, \neg (p~y))$. By \cref{lemma:eps-forall}, the latter is equivalent to $\forall x, p~x$.
\end{itemize}
\end{proof}

\cref{fig:sko-forall} describes the translation of the \kw{sko\_forall} command. We use the notation $(T)^n$ to express that the tactic $T$ will be repeated $n$ times where $n$ is the number of bound variables on the left, and $x_i, H_i$ are fresh new variables in the context.
The $H_i$ hypotheses stand for the equalities $\prf (x_i = (\epsilon\,y, \neg (p~y)))$ in \cref{lem:sko-forall}.

\subsection{Alethe subproofs}
\label{app:subproof}

Alethe uses subproofs to prove lemmas and to create and manipulate the context $\Gamma$. To prove lemmas, a subproof can introduce local assumptions.
From an assumption $\varphi$ and a formula $\psi$ proved from $\varphi$, the subproof rule deduces the clause $\neg \varphi, \psi$ that discharges the local assumption $\varphi$.
A subproof step cannot use a premise from a subproof nested within the current subproof. Subproofs are also used to manipulate the context.
Alethe contexts are a general mechanism to write substitutions and to change them by attaching new elements.
We recall that a context is a possibly empty list $x_1 \dots x_n$ where each element is either a variable or a variable-term tuple denoted $x \mapsto t$.

As shown in the example of \cref{lst:subproof}, the \smtinline{anchor} command indicates that a subproof will be introduced and it is concluded by a concluding rule such as \texttt{subproof},
\texttt{bind} or \texttt{sko\_forall}. Anchors are provided with two annotations. The annotation \smtinline{:step} provides the name of the step that concludes the subproof whereas the annotation \smtinline{:args} provides the context as sorted variables and assignments. The example shows a proof that uses a subproof with a context to rename a bound variable.
The subproof starts at the \smtinline{anchor} command at line 1 and ends at line 5 with the \emph{bind} rule that concludes the $\alpha$-conversion proof of $z2$ to $vr4$. The sub-steps $t9.t1$ and $t9.t2$ are carried out in the context $\Gamma = \{ z2 \mapsto vr4 \}$, hence, all occurrences of $z2$ in the clauses are substituted by $vr4$, allowing in particular step \texttt{t9.t1} to succeed using rule \texttt{refl}.

% \begin{minipage}{\linewidth}
\begin{lstlisting}[language=SMT,mathescape=true, caption={Alethe subproof example.}, label={lst:subproof}]
(anchor :step t9 :args ((vr4 U) (:= (z2 U) vr4)))
(step t9.t1 (cl (= z2 vr4)) :rule refl)
(step t9.t2 (cl (= (p z2) (p vr4))) :rule cong :premises (t9.t1))
(step t9 (cl (= (forall ((z2 U)) (p z2))
                (forall ((vr4 U)) (p vr4)))) :rule bind)
\end{lstlisting}
% \end{minipage}

We define in \cref{table:subproof-c} the definitions of the function $\mathcal{C}$ for the \kw{subproof} and \kw{bind} commands. The translation of \kw{bind} and \kw{subproof} relies on the following lemmas that have been proved in Lambdapi.

\begin{figure}[tb]
\centering
\begin{tabular}{|l|}
\hline
\textbf{R = \kw{subproof}} \\
\hline
$i_1.\ \Gamma \triangleright \varphi_1$ \quad $(\kw{assume})$ \\
$\vdots$ \\
$i_n.\ \Gamma \triangleright \varphi_n$ \quad $(\kw{assume})$ \\
$\vdots$ \\
$i_j.\ \Gamma \triangleright \psi$ \quad $(\dots)$ \quad with $u \in 1 \dots n$ \\
\ruleAlethe{k}{\neg \varphi_1, \dots, \neg \varphi_n, \psi}{subproof} \\

\hline

$\C{k} = \pid (( \neg \E{\varphi_1} \cons \dots \cons \neg \E{\varphi_n} \cons \E{\psi} ) \cons \nil)$ \\
$\quad \is \kw{apply}~\kw{subproof}_n$ \\
\hline
\textbf{R = \kw{bind}} \\
\hline
$j.\ \Gamma~\overline{y}, \overline{x} \mapsto \overline{y} \triangleright \varphi \approx \psi$ \quad $(\dots)$ \\
$\quad$ with $\overline{a} = a_1 \dots a_n$ and $Q \in \{\forall, \exists\}$ \\
$k.\ \Gamma \triangleright (Q~\overline{x}, \varphi) \approx (Q~\overline{y}, \psi)$ \quad $(\kw{bind})$ \\

\hline

$\C{k} = \pid (\E{Q~\overline{x}, \varphi \approx Q~\overline{y}, \psi} \cons \nil) \is$ \\
 begin
    \ \ \begin{tabular}[t]{@{}l}
          $\kw{apply}~\lor_{i1}; \kw{apply~bindQ};$ \\
          $\kw{assume}~x_j; \kw{apply}~ (\pid{}_l~j);$ 
        \end{tabular}\\
    end
    \\
\hline
\end{tabular}
\caption{Translating \kw{subproof} and \kw{bind} commands.}
\label{table:subproof-c}
\end{figure}


\begin{lemma}[$\kw{subproof}_1$]\label{lem:subproof}
For $\varphi, \psi : \prop{}$, if $\prf{} \varphi$ implies $\prf{} \psi$ then $\pid (\neg \varphi \cons \psi)$.
\end{lemma}


\begin{lemma}[bind$\forall$]\label{lem:bind-forall}
Given an arbitrary $a : \kw{Clause}$ and predicates $p, q : \el{}\,a \ra \prop$, if $\Pi x : \el{}\,a,~ \prf (p~x = q~x)$ then $\prf ((\forall x, p~x) = (\forall y, q~y))$.
\end{lemma}


\begin{lemma}[bind$\exists$]\label{lem:bind-exists}
  Given an arbitrary $a : \kw{Clause}$ and predicates $p, q : \el{}\,a \ra \prop$, if $\Pi x : \el{}\,a,~ \prf (p~x = q~x)$ then $\prf ((\exists x, p~x) = (\exists y, q~y))$.
\end{lemma}

\subsection{The \texttt{\upshape{evaluate}} cvc5 rule}
\label{ssec:eval-recon}

The smt solver cvc5 can produce proof traces with steps generated by an internal theory: \kw{evaluate}, \kw{TRUST\_THEORY\_REWRITE} (TTR).
The solver will then use the special rule ``\kw{hole}'', a placeholder for proof steps that cannot be expressed with Alethe rules.
The Carcara checker simply admits the conclusion of these rules, but here we try to reconstruct such steps using a simple internal or an external solver (why3).

The clauses derived using \kw{evaluate} are propositional and numerical constant equalities proved internally by cvc5, using constant propagation.

In the case of propositions, we reconstruct the proof through an embedded proof procedure for solving tautologies. Similarly to the approach for hyper-resolution illustrated in \cref{fig:reflective-process}, we approach this problem by reflection.
Regarding equalities of numerical constants, we reduce the computation with the rewriting rules defined in the Lambdapi standard library.

cvc5 uses the rule builtin rule \kw{TTR} to describe a step done by the internal theory rewriter.
Since such steps may rewrite quantified propositions, they may be too complex for a tautologies solver.
Instead, we reconstruct them by invoking the first-order automated theorem prover Zenon Modulo \cite{zenonmodulo} with the tactic \lpinline{why3} of Lambdapi.
This prover can output proof certificates in Lambdapi and Dedukti format that we can merge back into our reconstruction.
Although Zenon modulo could in principle be used more extensively during the certification of Alethe proof traces, in order to control the complexity of proof reconstruction we restrict the usage of an external solver to the \kw{TTR} command.


\begin{lstlisting}[language=SMT]
(step ti (cl (= (not true) false))
      :rule hole :args ("evaluate"))
(step tj (cl (= (>= 0.0 -1.0) true))
      :rule hole :args ("evaluate"))
\end{lstlisting}


\begin{figure}
\begin{align*}
& \cal{P} : \type \\
& |~\textbf{pTrue} : \cal{P} \\
& |~\textbf{pAnd} : \cal{P} \ra \cal{P} \ra \cal{P} \\
& |~\textbf{pFalse} : \cal{P} \\
& |~\textbf{pOther} : \N \ra \cal{P} \\
& |~\textbf{pOr} : \cal{P} \ra \cal{P} \ra \cal{P} \\
& |~\textbf{pImpl} : \cal{P} \ra \cal{P} \ra \cal{P} \\
& \kw{propS}: \set \\
& \el\,\kw{propS} \re \cal{P}
\end{align*}
\caption{An inductive type for propositional logic.}
\label{fig:prop}
\end{figure}


We now describe the propositional tautological solver based on \emph{proof by reflection} of first kind.
We start by defining the target theory that represents formulas of propositional logic in negation normal form.
We declare the inductive type $\cal{P}$ with seven constructors given in \cref{fig:prop}.
The constructor \texttt{pOther} encode uninterpreted expressions, including variables.
The index $\mathbb{N}$ will used as an index into a context map $\sigma: \bb{L}~o$ holding the corresponding uninterpreted expressions of type $\prop$.
Our automation will not look into the context mapping $\sigma$, but will be able to determine if two \texttt{pOther} terms reference the same location and are therefore equal.
Note that while our reification of the goal will try to reuse indices in $\sigma$ when values are repeated, we will not be able to prove that two different indices into $\sigma$ represent different values.
We define an interpretation $\reify{\_}: \bb{L}~o \ra \prop \ra \cal{P}$ and a reification $\deno{\_}: \bb{L}~o \ra \cal{P} \ra \prop$ function between $\prop$ and the target theory $\cal{P}$ that refer to a context map $\sigma$.
% We define the function \texttt{provable} that implements our partial decision procedure that checks if a proposition is decidably equal to \kw{true}.

\begin{minipage}{0.6\linewidth}
\small
\begin{flalign*}
&\reify{\top}_\sigma \re  \kw{pTrue} && \\
&\reify{\bot}_\sigma \re  \kw{pFalse} && \\
&\reify{x \lor y}_\sigma \re  \kw{pOr}~(\reify{x}_\sigma) (\reify{y}_\sigma) && \\
&\reify{x \land y}_\sigma \re \kw{pAnd} ~(\reify{x}_\sigma) (\reify{y}_\sigma) && \\
&\reify{x \Rightarrow y}_\sigma \re \kw{pImpl}~(\reify{x}_\sigma) (\reify{y}_\sigma) && \\
&\reify{x}_\sigma \re  \kw{pOther}~(\kw{Index}(\sigma, x)) && \\
\end{flalign*}
\end{minipage}%
\begin{minipage}{0.5\linewidth}
\small
\begin{flalign*}
&\deno{\kw{pTrue}} = \top  &&\\
&\deno{\kw{pFalse}} = \bot  &&\\
&\deno{\kw{pOr}\,x\,y} = \deno{x} \lor \deno{y}  &&\\
&\deno{\kw{pAnd}\,x\,y} = \deno{x} \land \deno{y}  &&\\
&\deno{\kw{pImpl}\,x\,y} = \deno{x} \Rightarrow \deno{y}  &&\\
&\deno{\kw{pOther}~i} = \sigma[i] &&\\
\end{flalign*}
\end{minipage}

\begin{example}[Reification]
Let $\sigma \is a \colon\colon b \colon\colon \Box$, the reification of $a \land b$ is:
\[
  \reify{(a \land b)}_\sigma \equivL \mathop{\mathtt{pAnd}} (\mathop{\mathtt{pOther}} 0) (\mathop{\mathtt{pOther}} 1)
\]
and its denotation
\[
  \deno{(\mathop{\mathtt{pAnd}} (\mathop{\mathtt{pOther}} 0) (\mathop{\mathtt{pOther}} 1))}_\sigma \equivL a \land b.
\]
\end{example}

Next, we define a decidable equality between terms of type $\cal{P}$ based on a decidable equality between $\N$ with the function $=_\N: \N \ra \N \ra \B$.

\begin{definition}[Decidable equality $=_\cal{P} \colon \cal{P} \ra \cal{P} \ra \mathbb{B}$]
\begin{flalign*}
&\kw{pTrue} =_\cal{P} \kw{pTrue} \re \true &&\\
&\kw{pFalse} =_\cal{P} \kw{pFalse} \re \true &&\\
&\kw{pAnd}~l_1\,r_1 =_\cal{P} \kw{pAnd}~l_2\,r_2  \re l_1 =_\cal{P} l_2 ~\kw{andb}~r_1 =_\cal{P} =r_2 &&\\
&\kw{pOr}~l_1\,r_1 =_\cal{P} \kw{pOr}~l_2\,r_2  \re l_1 =_\cal{P} l_2 ~\kw{andb}~r_1 =_\cal{P} =r_2 &&\\
&\kw{pImpl}~l_1\,r_1 =_\cal{P} \kw{pImpl}~l_2\,r_2  \re l_1 =_\cal{P} l_2 ~\kw{andb}~r_1 =_\cal{P} =r_2 &&\\
&\kw{pOther}~x =_\cal{P} \kw{pOther}~y  \re x =_\mathbb{N} y  &&\\
\end{flalign*}
\end{definition}

We know describes the notion of context $\hyps$ that is encoded as a $\bb{L}~\kw{propS}$.
The context will be use for learning proposition introduce by implication in the reified goal $(\kw{pImpl})$.
We define what it means for all members of a context $\hyps$ to represent true propositions,
and we prove some lemmas about this notion.

The predicate \kw{all} (\cref{eq:all-func}) transform a list of $\cal{P}$ into conjonctions to represent a context.
It use a fold right function from the Lambdapi standard library \info{ac}{present it in \cref{ch:intro-lambdapi}}.
\begin{equation}
\kw{all}: \kw{list}~\cal{P} \ra \cal{P} \coloneqq \kw{foldr}~(\kw{pAnd})~\kw{pTrue}
\label{eq:all-func}
\end{equation}
The function \kw{knows} (\cref{eq:know-func}) searches for an element decidably equal to $p$. It also use the function \kw{existsb} from the standard library.
\begin{equation}
\kw{knows}~(p: \cal{P})~(\Gamma: \kw{list}~\cal{P}) \coloneqq \kw{existsb}~(=_\cal{P})~\Gamma
\label{eq:know-func}
\end{equation}

The function \kw{learn} extends the list of known facts $\Gamma$ to include one more fact.
We destruct conjunctions so that we can prove theorems such as $p \land q \Rightarrow p$. For simplicity, in the case of other constructor, we just learn it.
%
\begin{flalign*}
&\kw{learn}~(p: \cal{P})~(\hypst): \kw{list}~\cal{P} &&\\
&\kw{learn}~\kw{pTrue}~\hyps \re \hyps &&\\
&\kw{learn}~\kw{pFalse}~\hyps \re (\kw{pFalse}::\hyps) &&\\
&\kw{learn}~(\kw{pAnd}~x~y)~\hyps \re \kw{learn}~x~(\kw{learn}~y~\hyps) &&\\
&\kw{learn}~p~\hyps \re \kw{learn}~(p :: \hyps)
\end{flalign*}

Correctness of \kw{learn} says that if the original context is valid, and the fact that you are learning is valid, then the learned context is valid.

\begin{lemma}[Correctness of learning]\label{lemma:learning_sound}
Given $\mapty$ and a context $\hypst$ then for any $\kw{p}: \cal{P}$, if
\[
  \prf (\deno{\kw{all}~\hyps}) \text{ and } \prf (\deno{p})
\]
then
\[
  \prf (\deno{\kw{all} (\kw{learn}~\kw{p}~\hyps)})
\]
\end{lemma}
\begin{proof} By induction on $p$.

Since all the cases follow the same patterns, we provide the case for \kw{pAnd}, and a similar approach can be follow for the rest.
We want to prove that $\prf (\deno{\kw{all} (\kw{learn}~(\kw{pAnd}~a~b)~\hyps))}$ which rewrites to $\prf (\deno{(a)} \land \deno{(b)} \land \deno{(\kw{foldr}~\kw{pTrue}~\Gamma))}$ by definition of \kw{All},
and we suppose that $\prf (\deno{\kw{all}~\hyps}$ and $\prf \deno{\kw{pAnd}~a~b))}$.
Then we apply the introduction rule of the conjunction ($\land_i$) giving us two case to prove.
\begin{itemize}
\item Case $\prf \deno{a}$ which follows directly from the hypothesis that $\prf (\deno{\kw{pAnd}~a~b)}$,
\item Case $\prf (\deno{b} \land \deno{\kw{foldr}~\kw{pTrue}~\Gamma)}$ which follows from the hypothesis that $\prf \deno{(\kw{pAnd}~a~b)}$ and $\prf (\deno{\kw{all}~\hyps})$.
\end{itemize}
\end{proof}

Now we want to prove that if our function \kw{knows} returns \kw{true}, then the proposition is implied by the meaning of the context:

\smallskip

\begin{lemma}[knows correct] \label{lemma:know_correct}
Given a mapping $\mapty$ with a context $\hypst$ and a proposition $\kw{p}: \cal{P}$, if the context
$\deno{\kw{all}~\Gamma}$ is sound and $\kw{knowns}~\kw{p}~\Gamma = \true$ then $\deno{\kw{p}}$ is sound.
\end{lemma}
\begin{proof}
By induction on the context list $\Gamma$.
\begin{itemize}
\item[] \textbf{Case} $\Gamma = \square$, trivial because we cannot have $\kw{knows}~p~\square = true$.
\item[] \textbf{Case} $\Gamma = x :: xs $, assume we have $H: \kw{knows}~p~(x::xs) = true$ and $H2: \deno{\kw{all}~(x::xs)}$.
We know by $H$, that $p$ is equal to $x$ or $p$ is equal to an element in $xs$. If $x$ is equal to $p$, one has $\deno{\kw{x}}$ from $H2$, hence we have $\deno{\kw{p}}$.
In the other case, $\deno{\kw{p}}$ follows from the induction hypothesis and H2.
\end{itemize}
\end{proof}


The function \kw{provable} implements our decision procedure. It checks if a proposition $goal: \cal{P}$ is provable in the context $\Gamma$.
%
\begin{flalign*}
&\kw{provable}~(goal: \cal{P})~(\hypst): \mathbb{B} &&\\
&\kw{provable}~\kw{pTrue}~\hyps \re \true &&\\
&\kw{provable}~\kw{pFalse}~\hyps \re \kw{knows}~\kw{pFalse}~\hyps &&\\
&\kw{provable}~(\kw{pAnd}~x~y)~\hyps \re (\kw{provable}~x~\hyps)~\&\&~(\kw{provable}~y~\hyps) &&\\
&\kw{provable}~(\kw{pOr}~x~y)~\hyps \re (\kw{provable}~x~\hyps)~||~(\kw{provable}~y~\hyps) &&\\
&\kw{provable}~(\kw{pImpl}~x~y)~\hyps \re \kw{provable}~y~(\kw{learn}~x~\hyps) &&\\
&\kw{provable}~(\kw{pOther}~i)~\hyps \re \kw{knows}~(\kw{pOther}~i)~\hyps ~||~\kw{knows}~\kw{pFalse}~\hyps  &&\\
\end{flalign*}

\begin{theorem}[Correctness of \kw{provable}]
For any $\kw{goal}: \cal{P}$ and context $\hypst$, if $\prf (\kw{provable}~\kw{goal}~\hyps = \true)$
then given a mapping $\sigma$, if the context $\prf (\deno{\kw{All}~\hyps})$ represent true propositions then the $\prf (\deno{\kw{goal}})$ is true.
\begin{proof} By induction on $p$.
\begin{itemize}
\item[] \textbf{Case} (p = \kw{pTrue}), we have to prove $\deno{\kw{pTrue}}$ which rewrites into $\top$ which hold trivially.
\item[] \textbf{Case} (p = \kw{pFalse}), It follow from the \cref{lemma:know_correct} with our hypothesis \kw{provable} \kw{pFalse} $\hyps = \true$ and $\deno{\kw{All}~\hyps}$ that $\deno{\text{pFalse}}$ hold.
\item[] \textbf{Case} (p = \kw{pAnd a b}), follow directly by induction hypothesis since \kw{provable} \kw{(pAnd a b)} $\hyps = \true$ implies $\kw{provable}~a~\hyps = \true$ and $\kw{provable}~b~\hyps = \true$.
\item[] \textbf{Case} (p = \kw{pOr}\,a\,b), follow directly by induction hypothesis since \kw{provable}\,\kw{pOr}\,a\,b\,$\hyps = \true$ implies $\kw{provable}\,a\,\hyps = \true$ or $\kw{provable}\,b\,\hyps = \true$.
\item[] \textbf{Case} (p = \kw{pImpl}\,a\,b), follow directly by induction hypothesis and \cref{lemma:learning_sound}.
\item[] \textbf{Case} (p = \kw{pOther}~i), let's consider an index $i: \N$, by the hypothesis $\prf (\kw{provable}~\kw{pOther}~i~\hyps = \true)$  we know that $(\kw{pAtom}\,i) \in \Gamma$ or $\kw{pFalse} \in \Gamma$. Therefore,
if $(\kw{pOther}\,i) \in \Gamma$ then by \cref{lemma:know_correct} and the hypothesis $\deno{\kw{All}~\hyps}$ we have $\deno{\kw{pOther}\,i}$. However,
in the case that $\kw{pFalse} \in \Gamma$, by using \cref{lemma:know_correct} and the hypothesis $\deno{\kw{All}~\hyps}$ we derive a contradiction.
\end{itemize}
\end{proof}
\end{theorem}

\begin{lstlisting}[language=Lambdapi]
constant symbol R : TYPE;
constant symbol Index : ℕ → R;
constant symbol New : ℕ → R;

symbol case [a] : R → (ℕ → τ a) → (ℕ → τ a) → τ a;
rule case (Index $i) $f _ ↪ $f $i
with case (New $i) _ $g ↪ $g $i;

sequential symbol index: ℕ → Π [a], τ a → τ(list a) → R;
rule index $k _ □ ↪ New $k
with index $k $x ($x ⸬ _) ↪ Index $k // Here is the magic...
with index $k $x ($y ⸬ $l) ↪ index ($k +1) $x $l;

sequential symbol propReify: (𝕃 o) →  Prop → τ (propS × (list o));
rule propReify $ctx ⊤ ↪ (pTrue ‚ $ctx)
with propReify $ctx ⊥ ↪ (pFalse ‚ $ctx)
with propReify $ctx ($x ∧ $y) ↪ let res1 ≔  (propReify $ctx $x) in
                                let res2 ≔  (propReify (res1 ₂) $y) in
                                (pAnd (res1 ₁) (res2 ₁) ‚ (res2 ₂))
with propReify $ctx ($x ∨ $y) ↪ let res1 ≔  (propReify $ctx $x) in
                                let res2 ≔  (propReify (res1 ₂) $y) in
                                (pOr (res1 ₁) (res2 ₁) ‚ (res2 ₂))
with propReify $ctx ($x ⇒ ⊥) ↪ let res ≔  (propReify $ctx $x) in
                                (pNot (res ₁)‚ (res ₂))
with propReify $ctx ($x ⇒ $y) ↪ let res1 ≔  (propReify $ctx $x) in
                                let res2 ≔  (propReify (res1 ₂) $y) in
                                (pImpl (res1 ₁) (res2 ₁) ‚ (res2 ₂))
with propReify $ctx ($x ⇔ $y) ↪ let res1 ≔  (propReify $ctx $x) in
                                let res2 ≔  (propReify (res1 ₂) $y) in
                                (pIff (res1 ₁) (res2 ₁) ‚ (res2 ₂))
with propReify $ctx $x ↪ 
    case (index _0 $x $ctx) (λ i, pOther i ‚ $ctx) (λ i, pOther i ‚ ($ctx ++ ($x ⸬ □)));

symbol reify goal ≔ propReify □ goal; 

symbol tauto_aux [goal] ≔ let res ≔ reify goal in provable_sound (res ₁) □ (res ₂);

symbol tauto ≔ #refine "(tauto_aux ⊤ᵢ ⊤ᵢ)";

private symbol example1: π ((⊤ ∧ ⊤) ⇒ ⊤ ∨ ⊤ ∧ (⊤ ⇒ ⊤)) ≔
begin eval tauto; end;
\end{lstlisting}


% \begin{example}
% As an illustration of the process described in \cref{fig:tautology-solver}, let us consider a proof goal $\cal{G} \coloneq (p \land \top) \lor \bot \Leftrightarrow p$ and a context map $\sigma \coloneq \{ 0 \mapsto p \}$.
% Reification of $\cal{G}$ yields $\reify{\cal{G}}_\sigma = \kw{pOr}~(\kw{pAnd}~\kw{(pOther 0)}~\kw{})~\kw{pFalse} \Leftrightarrow \kw{(pOther 0)}$. Then by using \cref{theorem:provable-sound},
% we obtain that $\prf (\kw{provable}~\reify{\cal{G}}_\sigma = \texttt{true})$ implies the desired assertion $\prf ((p \land \top) \lor \bot \Leftrightarrow p)$.
% \end{example}


\section{Reconstruction of linear arithmetic}
\label{sec:lia-reconstruction}

% Proof by reflection \cite{reflection-origin-coq} is a technique for writing certified procedures for automated reasoning. It reduces the validity of a logical statement to a symbolic computation.
% Let $P: Z \ra \prop$ be a predicate over a data type Z and $f: Z \ra \tt{bool}$ be a function such that the following theorem holds:

% \begin{equation*}
% \tt{f\_correct} : \forall z: Z, (f~z = \tt{true}) \ra (P~z)
% \end{equation*}

% If $\mathop{f} z$ reduces to \tt{true}, then the proof term  $\tt{f\_correct}~z~(\tt{refl}~\tt{bool}~\tt{true})$ with $\tt{refl}: \Pi A: \set,\, \Pi x: \el\,A,\, \prf (x = x)$, constitutes a proof of predicate $(P~z)$. In step 6 of checking an application of rule \tt{la\_generic},
% the primary challenge lies in reasoning modulo associativity and commutativity when manipulating expressions over $\Z$.
% The key idea is to provide a normalization function that transforms a $\Z$ expression into a canonical form.
% % such that it can be reduced to a constant because variables will cancel each other, as is the case with the constant $f$ in \cref{ex:la_generic_example_red}.


\subsection{Representation}
\label{ssec:representation}

The procedure is based on an algebraic group structure, denoted as  $\bb{G}$ defined in \cref{fig:grp}, which represents linear polynomials.
The base type for its elements is $\bb{G}: \type$. The unary operator $\tt{cst}$ injects constants from $\Z$ into $\bb{G}$.
The term $\tt{var}~c~x$ is intended for representing expressions $c \times x$ that appear as constituents of linear inequalities, where $c$ is an integer coefficient and $x$ a $\Z$ term, in particular a variable.
The constructor $\tt{mul}$  represents the multiplication of an element of $\bb{G}$ by a constant. The constructor $\tt{opp}$ corresponds to unary minus.
Lastly, the constructor $\add{}{}$ represents the addition between two elements of $\bb{G}$.

Lambdapi provides modifiers %\lstinline[language=Lambdapi,basicstyle=\ttfamily\footnotesize\upshape]{associative commutative} 
for supporting associative and commutative operations,
ensuring that terms are systematically transformed into a canonical form w.r.t.\ a builtin ordering relation \cite{univAC,ACorigin}. We declare the operator $\add{}{}$ as \lstinline[language=Lambdapi,basicstyle=\ttfamily\footnotesize\upshape]{associative commutative},
ensuring that expressions involving sums of elements of $\bb{G}$ are systematically canonicalized. 
%In particular, terms of the form $\tt{var}~c~x$ for equal variables will be placed next to each other, facilitating simplification.

\begin{figure}[t]
\scriptsize
\begin{align*}
& \bb{G}: \type & & \reify{} : \Z \ra \bb{G} & & \den{}: \bb{G} \ra \Z \\
&|~\add{}{}: \bb{G} \ra \bb{G} \ra \bb{G} & & \reify{\ZO} \re \cst{\ZO} & & \den{\cst{c}} \re c \\
&|~\tt{var}: \Z \ra \Z \ra \bb{G} & & \mathop{\reify{\ZPos}} c \re \cst{(\ZPos c)} & & \den{\opp{x}} \mathrel{\re}  \mathop{\sim (\den{x})} \\
&|~\tt{mul}: \Z \ra \bb{G} \ra \bb{G} & & \mathop{\reify{\ZNeg}} c \re \cst{(\ZNeg c)} & & \den{\mul{c}{x}} \re  c \times (\den{x}) \\
&|~\tt{opp}: \bb{G} \ra \bb{G} & & \reify{(x + y)} \re \add{(\reify{x})}{(\reify{y})} & & \den{\add{x}{y}} \re (\den{x}) + (\den{y}) \\
&|~\tt{cst}: \Z \ra \bb{G} & & \reify{(\sim x)} \re \opp{\reify{x}} & & \den{\var{c}{x}} \re  c \times x \\
&\tt{grp}: \set & & \mathop{\reify{((\mathop{\ZPos} c) * x})} \re \mul{c}{(\reify{x})}  & & \\
&\el~\tt{grp} \re \bb{G} & & \mathop{\reify{((\mathop{\ZNeg} c) * x)}} \re \mul{c}{(\reify{x})} & & \\
& & & \mathop{\reify{(x * (\mathop{\ZPos} c))}} \re \mul{c}{(\reify{x})}  & & \\
& & & \mathop{\reify{(x * (\mathop{\ZNeg} c))}} \re \mul{c}{(\reify{x})} & & \\
& & & \mathop{\reify{x}} \re \var{1}{x} & &
\end{align*}
\caption{Definition of $\bb{G}$  Algebra and its reification ($\reify{}$) and denotation ($\den{}$) functions.}
\label{fig:grp}
\end{figure}

\subsection{Associative Commutative Normalization}
\label{ssec:normalization}

\begin{figure}[t]
\begin{align}
&\add{\var{c_1}{x}}{\var{c_2}{x}} \re \var{(c_1 + c_2)}{x} \\
&\add{\var{c_1}{x}}{(\add{\var{c_2}{x}}{y})} \re \add{\var{(c_1 + c_2)}{x}}{y} \\
&\add{\cst{c_1}}{\cst{c_2}} \re \cst{c_1 + c_2} \\
&\add{\cst{c_1}}{(\add{\cst{c_2}}{y})} \re \add{\cst{c_1 + c_2}}{y} \\
&\add{\cst{0}}{x} \re x \\
&\add{x}{\cst{0}} \re x \\
&\opp{\var{c}{x}} \re \var{(-c)}{x} \\
&\opp{\cst{c}} \re \cst{(-c)} \\
&\opp{(\opp{x})} \re x \\
&\opp{(\add{x}{y})} \re \add{(\opp{x})}{(\opp{y})} \\
&\opp{(\mul{k}{x})} \re \mul{(-k)}{x} \\
&\mul{k}{\var{c}{x}} \re \var{(k * c)}{x} \\
&\mul{k}{(\opp{x})} \re \mul{(-k)}{x} \\
&\mul{k}{(\add{x}{y})} \re \add{(\mul{k}{x})}{(\mul{k}{y})} \\
&\mul{k}{\cst{c}} \re \cst{(k * c)} \\
&\mul{c_1}{(\mul{c_2}{x})} \re \mul{(c_1 * c_2)}{x}
\end{align}
\caption{Rewrite system on canonical forms.}
\label{fig:grp-rw}
\end{figure}

%% sm: not sure if this is important. If you think it is, it should go to the section where AC and canonicalization are introduced.
%For \lstinline[language=Lambdapi,basicstyle=\ttfamily\footnotesize\upshape]{associative commutative} symbols, Lambdapi does not use matching modulo AC \cite{matching-mod-AC,kirchner_rsp} as this problem is NP-complete \cite{ac-modulo-np-complete}.
The transformation to canonical form implemented in Lambdapi ensures that sum expressions of the form $\var{c_1}{x_1} \oplus \cst{k_1} \oplus \var{c_2}{x_2} \oplus \dots \oplus \cst{k_m} \oplus \dots \oplus \var{c_n}{x_n}$ will be normalized such that any pair of terms $\var{p}{x}$ and $\var{q}{x}$ involving the same variable $x$ are placed next to each other,
and all $\cst{k_i}$ will be placed at the left before the first variable $\var{c_j}{x_j}$.
We will use the rewriting rules shown in \cref{fig:grp-rw} for reducing $\bb{G}$ expressions. Notably, the resulting normal forms do not contain the constructors $\tt{mul}$ and $\tt{opp}$, as the associated rewrite rules eliminate them in favor of $\tt{var}, \tt{add}$ and $\tt{cst}$.

\begin{definition}%[AC-canonical form]
The $\leq$ builtin total order on $\bb{G}$-terms is defined as follows:
Terms are ordered such that $\tt{cst}(c_1) \leq \tt{cst}(c_2) < \var{p}{x}$ for any constants $c_1, c_2$ and any variable term $\var{p}{x}$, with $c_1 \leq c_2$.
For variable terms, $\var{p}{x} \leq \var{q}{y}$ if either $x < y$, or $x = y$ and $p \leq q$.
Let $\twoheadrightarrow^{AC}$ be the relation mapping every term t to its unique AC-canonical form denoted $[t]$.
\end{definition}

Two terms $t$ and $u$ are AC-equivalent (written $t \simeq_{AC} u$) iff their AC-canonical forms are equal.

\begin{definition}%[Rewriting modulo AC-canonization]
The relation $\ACcanon$ is defined as $\re_\Sigma\,\twoheadrightarrow^{AC}$, where $\Sigma$ contains the rewrite rules of \cref{fig:arith-ops,fig:grp-rw}. 
\end{definition}

An $\ACcanon$ step is a standard $\re_\Sigma$ step with syntactic matching followed by AC-canonicalization. We now prove that the relation $\ACcanon$ terminates and is confluent.

\begin{lemma} 
	The relation $\mathop{\rwModAC} \mathrel{=} \mathop{\simeq_{AC} \, \re_\Sigma \, \simeq_{AC}}$ of matching modulo AC, which contains $\ACcanon$, terminates.
\end{lemma}
\begin{proof} 
AProVE \cite{aprove} automatically proves the termination of $\rwModAC$. 
\end{proof}


\begin{lemma} 
	$\ACcanon$ is locally confluent on AC-canonical terms.
\end{lemma}
\begin{proof}
We show that every critical pair is joinable using $\ACcanon$ and confluence of $\ra_\Z$ and $\ra_\bb{P}$ from \cref{lemma:confluenceZP}.
We use the notation $\MRAC$ to denote a multistep rewriting with AC-canonical form.

% t ≔ opp (add (var $k $x) (var $c $x))
% t ↪[] add (opp (var $k $x)) (opp (var $c $x)) ↪* var (— $k + — $c) $x
%   with opp (add $x' $y') ↪ add (opp $0') (opp $1')
% t ↪[1] opp (var ($0 + $2) $1) ↪* var (— ($0 + $2)) $1
%   with add (var $k $x) (var $c $x) ↪ var ($0 + $2) $1
\begin{center}
\cp
{
  \opp{(\underline{\var{c_1}{x} \oplus \var{c_2}{x}})}
}
{
  \opp{\var{c_1}{x}} \oplus \opp{\var{c_2}{x}}
}
{
  \opp{\var{(c_1 + c_2)}{x}}
}
{11}{2}
\end{center}

But $\opp{\var{c_1}{x}} \oplus \opp{\var{c_2}{x}} \MRAC \var{(\sim c_1 + \sim c_2)}{x}$
and $\opp{\var{(c_1 + c_2)}{x}} \MRAC \var{\sim (c_1 + c_2)}{x}$ converge by the confluence of $\ra_\Z$.

% t ≔ opp (add (var $k $x) (add (var $l $x) $y))
% t ↪[] add (opp (var $k $x)) (opp (add (var $l $x) $y)) ↪* add (var (— $k + — $l) $x) (opp $y)
%   with opp (add $x' $y') ↪ add (opp $0') (opp $1')
% t ↪[1] opp (add (var ($0 + $2) $1) $3) ↪* add (var (— ($0 + $2)) $1) (opp $3)
%   with add (var $k $x) (add (var $l $x) $y) ↪ add (var ($0 + $2) $1) $3
\cp
{
  \opp{\underline{(\var{c_1}{x} \oplus (\var{c_2}{x} \oplus y))}}
}
{
  \opp{\var{c_1}{x}} \oplus \opp{(\var{c_2}{x} \oplus y)}
}
{
  \opp{\var{(c_1 + c_2)}{x} \oplus y)}
}
{11}{3}

We note that $\opp{\var{c_1}{x}} \oplus \opp{(\var{c_2}{x} \oplus y)} \MRAC \add{\var{(\sim c_1 + \sim c_2)}{x}}{(\opp{y})}$
and $\opp{\var{(c_1 + c_2)}{x} \oplus y} \MRAC \add{\var{(\sim (c_1 + c_2))}{x}}{(\opp{y})}$
both reduce to the same term, as guaranteed by the confluence of $\ra_\Z$.

% t ≔ opp (add (cst $k) (cst $l))
% t ↪[] add (opp (cst $k)) (opp (cst $l)) ↪* cst (— $k + — $l)
%   with opp (add $x' $y') ↪ add (opp $0') (opp $1')
% t ↪[1] opp (cst ($0 + $1)) ↪* cst (— ($0 + $1))
%   with add (cst $k) (cst $l) ↪ cst ($0 + $1)
\cp{
  \opp{(\underline{\cst{c_1} \oplus \cst{c_2}})}
}
{
  \opp{\cst{c_1}} \oplus \opp{\cst{c_2}}
}
{
  \opp{\cst{(c_1 + c_2)}}
}
{11}{4}

We observe that $\opp{\cst{c_1}} \oplus \opp{\cst{c_2}} \MRAC \cst{(\sim c_1) + (\sim c_2)}$
and $\opp{\cst{(c_1 + c_2)}} \MRAC \cst{\sim (c_1 + c_2)}$ reduce to the same result due to the confluence of $\ra_\Z$.


% t ≔ opp (add (cst $k) (add (cst $l) $y))
% t ↪[] add (opp (cst $k)) (opp (add (cst $l) $y)) ↪* add (cst (— $k + — $l)) (opp $y)
%   with opp (add $x' $y') ↪ add (opp $0') (opp $1')
% t ↪[1] opp (add (cst ($0 + $1)) $2) ↪* add (cst (— ($0 + $1))) (opp $2)
%   with add (cst $k) (add (cst $l) $y) ↪ add (cst ($0 + $1)) $2
\cp
{
  \opp{(\underline{\cst{c_1} \oplus (\cst{c_2} \oplus y)})}
}
{
  \opp{\cst{c_1}} \oplus \opp{(\cst{c_2} \oplus y)}
}
{
  \opp{(\cst{c_1 + c_2} \oplus y)}
}
{11}{5}

The expressions $\opp{\cst{c_1}} \oplus \opp{(\cst{c_2} \oplus y)} \MRAC \cst{(\sim c_1) + (\sim c_2)} \oplus \opp{y}$
and $ \opp{(\cst{c_1 + c_2} \oplus y)} \MRAC \add{ \cst{\sim (c_1 + c_2)} }{\opp{y}}$
both reduce to a common term, which follows from the confluence property of $\ra_\Z$.

% t ≔ add (var $k' $x) (add (var $k $x) (add (var $l $x) $y))
% t ↪[] add (var ($0' + $k) $x) (add (var $l $x) $y) ↪* add (var (($0' + $k) + $l) $x) $y
%   with add (var $k' $x') (add (var $l' $x') $y') ↪ add (var ($0' + $2') $1') $3'
% t ↪[1] add (var $k' $x) (add (var ($0 + $2) $1) $3) ↪* add (var ($k' + ($0 + $2)) $x) $3
%   with add (var $k $x) (add (var $l $x) $y) ↪ add (var ($0 + $2) $1) $3

\cp
{
  \var{c_1}{x} \oplus \underline{(\var{c_2}{x} \oplus (\var{c_3}{x} \oplus y))}
}
{
  \var{(c_1 + c_2)}{x} \oplus ((\var{c_3}{x} \oplus y))
}
{
  \var{c_1}{x} \oplus (\var{(c_2 + c_3)}{x} \oplus y))
}{3}{3}

The terms $\var{(c_1 + c_2)}{x} \oplus ((\var{c_3}{x} \oplus y)) \MRAC \add{\var{(c_1 + (c_2 + c_3))}{x}}{y}$
and $\var{c_1}{x} \oplus (\var{(c_2 + c_3)}{x} \oplus y)) \MRAC \add{\var{((c_1 + c_2) + c_3)}{x}}{y}$
both reduce to the same result due to the confluence of $\ra_\Z$.

% t ≔ add (cst $k') (add (cst $k) (add (cst $l) $y))
% t ↪[] add (cst ($0' + $k)) (add (cst $l) $y) ↪* add (cst (($0' + $k) + $l)) $y
%   with add (cst $k') (add (cst $l') $y') ↪ add (cst ($0' + $1')) $2'
% t ↪[1] add (cst $k') (add (cst ($0 + $1)) $2) ↪* add (cst ($k' + ($0 + $1))) $2
%   with add (cst $k) (add (cst $l) $y) ↪ add (cst ($0 + $1)) $2

\cp
{\cst{c_1} \oplus \underline{(\cst{c_2} \oplus (\cst{c_3} \oplus y))}}
{\cst{(c_1 + c_2)} \oplus (\cst{c_3} \oplus y) }
{\cst{c_1} \oplus (\cst{(c_2 + c_3)} \oplus y) }
{5}{5}

We observe that $\cst{c_1 + c_2} \oplus (\cst{c_3} \oplus y) \MRAC \add{\cst{((c_1 + c_2) + c_3)}}{y}$
and $\cst{c_1} \oplus (\cst{(c_2 + c_3)} \oplus y) \MRAC \add{\cst{(c_1 + (c_2 + c_3)}}{y}$
both reduce to the same expression due to the confluence property of $\ra_\Z$.

% t ≔ mul $k' (mul $k (mul $l $z))
% t ↪[] mul ($0' * $k) (mul $l $z) ↪* mul (($0' * $k) * $l) $z
%   with mul $k' (mul $l' $z') ↪ mul ($0' * $1') $2'
% t ↪[1] mul $k' (mul ($0 * $1) $2) ↪* mul ($k' * ($0 * $1)) $2
%   with mul $k (mul $l $z) ↪ mul ($0 * $1) $2
\cp
{ \mul{c_1}{\underline{(\mul{c_2}{(\mul{c_3}{z})})}} } 
{ \mul{(c_1)}{ (\mul{(c_2 * c_3)}{z}) } }
{ \mul{(c_1 * c_2)}{(\mul{c_3}{z}})} 
{16}{16}

Finally, we have $\mul{(c_1)}{(\mul{(c_2 * l)}{z})} \MRAC \mul{((c_1 * c_2) * c_3)}{z})$
and $\mul{(c_1 * c_2)}{(\mul{c_3}{z}}) \MRAC \mul{(c_1 * (c_2 * c_3))}{z})$ that converge by the confluence of $\ra_\Z$.

\end{proof}

We compare two $\Z$-terms $t_1$ and $t_2$ wrt $\ACcanon$ by reifying them into their corresponding $\bb{G}$-terms, denoted $[g_1]$ and $[g_2]$, using the reification function $\reify{}$,
and normalizing them using $\twoheadrightarrow^{AC}$. Following the reduction rules specified in \cref{fig:grp-rw}, we can then compare their corresponding $\Z$-terms by applying the denotation function $\den{}$.
To validate this procedure, it is necessary to establish the correctness of the following diagram, formally expressed by \cref{thm:normalization}.

\begin{figure}
\centering
% % https://q.uiver.app/#q=WzAsOCxbMSwyLCJcXGJ1bGxldCJdLFsxLDAsIlxcYnVsbGV0Il0sWzMsMiwiXFxidWxsZXQiXSxbMywwLCJcXGJ1bGxldCJdLFswLDIsInRfMSA9X1xcbWF0aGJie1p9IHRfMiJdLFswLDAsIlxcRG93bmFycm93KFxcVXBhcnJvdyh0XzEpKSA9X1xcbWF0aGJie1p9IFxcRG93bmFycm93KFxcVXBhcnJvdyh0XzIpKSJdLFs0LDAsIlxcRG93bmFycm93KFtnXzFdKSA9X1xcbWF0aGJie1p9IFxcRG93bmFycm93KFtnXzJdKSJdLFs0LDIsImdfMSA9X1xcbWF0aGJie1p9IGdfMiJdLFswLDEsIlxcRG93bmFycm93KFxcVXBhcnJvdyhcXF8pKSJdLFswLDIsIlxcaWZmIiwxLHsic3R5bGUiOnsiYm9keSI6eyJuYW1lIjoiZG90dGVkIn0sImhlYWQiOnsibmFtZSI6Im5vbmUifX19XSxbMSwzLCJbXFxfXSIsMCx7InN0eWxlIjp7ImJvZHkiOnsibmFtZSI6ImRhc2hlZCJ9fX1dLFszLDIsIlxcRG93bmFycm93KFxcXykiXSxbMSwyLCIiLDAseyJzdHlsZSI6eyJuYW1lIjoiY29ybmVyIn19XV0=
\(\begin{tikzcd}[ampersand replacement=\&]
	{\Uparrow(t_1) =_\bb{G} (\Uparrow(t_2)} \& \bb{G} \&\& \bb{G} \& {[g_1] =_\bb{G} [g_2]} \\
	\\
	{t_1 =_\Z t_2} \& \Z \&\& \Z \& {\den{g_1} =_\Z \den{g_2}}
	\arrow["{[\_]}", dashed, from=1-2, to=1-4]
	\arrow["\lrcorner"{anchor=center, pos=0.125}, draw=none, from=1-2, to=3-4]
	\arrow["{\Downarrow(\_)}", from=1-4, to=3-4]
	\arrow["{\Uparrow(\_)}", from=3-2, to=1-2]
	\arrow["\iff"{description}, dotted, no head, from=3-2, to=3-4]
\end{tikzcd}\)
\end{figure}

\begin{theorem}[Correctness of normalization]\label{thm:normalization}
For all $\bb{G}$-terms $t$, we have $(\den{[t]}) = (\den{t})$ where $[t]$ is the AC-canonical form of $t$ with respect to $\longrightarrow^{AC}_\Sigma$.
\end{theorem}
\begin{proof}
  The proof proceeds by induction on $t$, and the key case is the one where $t = t_1 \oplus t_2$.
% This is a meta-level proof, proceeding by structural induction on $t$.
% Assume that the normalization function $[\_]$ is implemented using a merge sort algorithm over the multiset of subterms $\bb{G}$, with respect to the associative-commutative operator $\oplus$.
% We focus on the inductive case where $t = t_1 \oplus t_2$.
We have to show that $\mathop{\den{[t_1 \oplus t_2]}} = \mathop{(\den{t_1}) + (\den{t_2})}$.
By the induction hypothesis, we have
$\mathop{\den{[t_1]}} = \mathop{\den{t_1}}$ and $\mathop{\den{[t_2]}} = \mathop{\den{t_2}}$.
Hence,
\[
  (\den{t_1}) + (\den{t_2})
  = (\den{[t_1]}) + (\den{[t_2]})
  = \mathop{\den{([t_1] \oplus [t_2])}}
\]
It remains to show that
$\mathop{\den{([t_1] \oplus [t_2])}} = \mathop{\den{[t_1 \oplus t_2]}}$.
Now, $[t_1]$, $[t_2]$, and $[t_1 \oplus t_2]$ are terms built solely from \tt{cst}, \tt{var}, and $\oplus$ since the remaining operators have been eliminated by applying the rules in \cref{fig:grp-rw}, and the terms on both sides of the equation contain the same multisets of subterms. The two terms are therefore identified by AC-canonicalization.
%
% $[t_1 \oplus t_2]$ is the canonical (i.e., sorted) form of the multiset of subterms in $t_1$ and $t_2$,
% and that merge-sorting two normalized (i.e., already sorted) linear polynomials yields the same result as normalizing (i.e sorting) their merge.
% Therefore, since the normalization preserves denotation, we conclude that $\den{[t]} = \mathop{\den{t}}$ for all $\bb{G}$-terms $t$.
\qed
\end{proof}

We make use of \cref{lem:conv} to embed $\Z$-terms into $\bb{G}$ to normalize and subsequent comparison.
In addition, we leverage this normalization process to support the \tt{arith-poly-norm} rule.

\begin{lemma}[Conversion]\label{lem:conv}
For all $x: \Z$, we have $x = (\mathop{\den{(\reify{x})}})$.
\end{lemma}
\begin{proof}
By induction on $x$. We consider the three cases: $x = \ZPos(n)$, $x = \ZNeg(n)$, and $x = \ZO$.  
In each case, $\reify{(x)}$ yields the corresponding constant $\cst{x}$, and by definition of the denotation function, $x = \mathop{\den{(\cst{x})}}$.
Hence, $x = (\mathop{\den{(\reify{x})}})$ in all cases.
\end{proof}

The full proof \cref{lst:smtexampleproof} translated into Lambdapi can be found in \cref{app:example-translation}.

\section{Reconstruction of bitvector}
\label{sec:bv-reconstruction}
