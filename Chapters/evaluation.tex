%*****************************************
\chapter{Evaluation}\label{ch:evaluation}
%*****************************************

\begin{figure}
\begin{tikzpicture}[
    node distance=1,
    box/.style={rectangle, draw, minimum width=5pt, minimum height=0.8cm, align=center, font=\footnotesize},
    arrow/.style={->, >=Stealth, thick},
    group/.style={rectangle, draw, rounded corners, inner sep=2pt, label={[font=\footnotesize]above:Carcara}}
]
\node[box] (proof) {\faFileTextO~*.smt2};
\node[box, right=of proof] (cvc5) {cvc5};
\node[box, right=of cvc5] (carcara_elab) {Elaboration};
\node[box, draw=RoyalBlue, right=of carcara_elab] (carcara_recon) {Translation};
\node[box, right=of carcara_recon] (lambdapi) {Lambdapi};

% Group box around the two Carcara nodes
\node[group, fit=(carcara_elab) (carcara_recon)] (carcara_group) {};

% Arrows
\draw[arrow] (proof) -- (cvc5);
\draw[arrow] (cvc5) -- (carcara_elab);
\draw[arrow] (carcara_elab) -- (carcara_recon);
\draw[arrow] (carcara_recon) -- (lambdapi);
\end{tikzpicture}
\caption{Pipeline of the benchmarks}
\label{fig:bench-pipeline}
\end{figure}

\section{Benchmark Suite and Evaluation Settings}
\label{sec:benchs-and-setting}


We evaluate our approach to SMT-proof reconstruction on benchmarks drawn from SMT-LIB and the TLAPS proof assistant.
We chose SMT-LIB because it is an actively maintained, community-curated suite used in the SMT-COMP \cite{SMT-COMP},
and because the Carcara checker likewise benchmarks on SMT-LIB \cite[\S 4]{carcara}. We included TLAPS proofs to align with our objective of verifying proofs produced by the TLAPS solver, as outlined in \cref{sec:problem-tlaps-proof}.

Our evaluation targets exactly the fragments supported by our current encoding of uninterpreted functions and linear integer arithmetic (\cref{ch:reconstruction-ul}, \cref{ch:reconstruction-la}).
Accordingly, we select the SMT-LIB samples \tt{QF\_UF}, \tt{UF}, \tt{LIA},  \tt{UFLIA} and \tt{QF\_LIA}.
These choices ensure that the benchmark suite exercises precisely the reasoning capabilities our reconstruction currently implements.
However, we do not yet include \tt{LRA}: support for real arithmetic (\cref{sec:reconstruction-lra}) remains experimental, and we have so far evaluated it only on small illustrative examples.

\paragraph{pipeline}

As illustrated in \cref{fig:bench-pipeline}, each benchmark starts from an SMT-LIB input file (\tt{*.smt2}) that we feed to cvc5 to produce an Alethe proof.
The proof is then processed by Carcara in two phases: an \emph{elaboration} pass that checks and enriches the trace, followed by our \emph{translation} pass that reconstructs the proof into Lambdapi terms.
We execute \emph{elaboration} and \emph{translation} as two distinct steps so their costs can be measured independently.
The resulting Lambdapi file is finally type-checked by the Lambdapi kernel.
Each phase is invoked separately and its wall-clock time recorded, allowing us to report elaboration and reconstruction throughput without confounding effects from the other phase.
The commands used to run cvc5, Alethe and Lambdapi are as follows:

\noindent Generate an Alethe proof with cvc5.
\begin{lstlisting}[language=bash,numbers=none]
cvc5 --produce-proofs --dump-proofs
  --proof-format-mode=alethe
  --proof-granularity=dsl-rewrite
  --proof-alethe-res-pivots
  --proof-elim-subtypes
  --print-arith-lit-token
  *.smt2
\end{lstlisting}

\noindent Elaborate with Carcara.
\begin{lstlisting}[language=bash,numbers=none]
carcara elaborate --no-print-with-sharing
  --expand-let-bindings
  -i --log off
  *.alethe
\end{lstlisting}

\noindent Type-check the reconstructed proof with Lambdapi.
\begin{lstlisting}[language=bash,numbers=none]
lambdapi check -w -v0 *.lp
\end{lstlisting}

\paragraph{Setting}

The experiments presented in this chapter were conducted on the {Grid'5000} \cite{grid5000} infrastructure.
All experiments were run on a server equipped with:
\begin{itemize}
  \item $2$ CPU AMD EPYC $9754$ processor,
  \item $256$ hardware cores ($512$~threads) at $2.4$~GHz,
  \item  $1024$ GB RAM,
  \item $1490$ GB SSD,
  \item configured with a Ubuntu $24.04$ LTS.
\end{itemize} 

We selected this configuration to support a multi-stage pipeline that emits numerous intermediate and large final artifacts.
The workflow spawns many independent jobs, so a high core count enables broad parallelism to reduce end-to-end runtime.
Substantial memory is required to hold large terms, caches, and in-memory indices without excessive swapping.
A fast SSD mitigates I/O bottlenecks from frequent reads and writes of intermediate files.
In preliminary runs on a smaller machine, we encountered operational limitsâ€”including file descriptor exhaustion and sporadic I/O stalls motivating the move to a higher capacity setup.
The benchmarks infrastructure has been published \footnote{\url{https://ithub.com:NotBad4U/benchmarks-reconstruction.git}} to ensure reproducibility with a {grid'5000} ready for being reproduce by anyone with access to the platform,
however, the benchmarks can be reproduce on any platform.

\paragraph{Managing identifiers.} Names are an important source of conflicts because the class of identifiers
of SMT and Lambdapi language is different. We need to replace identifiers of the SMT input problem that are
invalid in the Lambdapi language by valid identifiers. For example, the character `\$' is not allowed in Lambdapi identifiers,
or some reserved keywords such as ``\lpinline{apply}'' in Lambdapi cannot be used as identifiers but are used in some input problems.

\begin{figure}[t]
\resizebox{\linewidth}{!}{%
\pgfkeys{/forest,
  my rounded corners/.append style={rounded corners=2pt},
}
\begin{forest}
  for tree={
      font=\sffamily,
      line width=1pt,
      s sep=20pt,   % space between siblings
      l sep=6pt,    % space between levels
      fit=rectangle,
      inner xsep=6pt,    % horizontal padding
      inner ysep=4pt,    % vertical padding
      edge={thick, >={Triangle[]}, ->},
      where level=0{%
        l sep+=15pt,
        calign=child,
        calign child=2,
        align=center,
        my rounded corners,
        for descendants={%
          calign=first,
        },
      }{%
        where level=1{%
          my rounded corners,
          align=center,
          parent anchor=south west,
          tier=three ways,
          for descendants={%
            child anchor=west,
            parent anchor=west,
            align=left,
            anchor=west,
            edge path={
              \noexpand\path[\forestoption{edge}]
              (!to tier=three ways.parent anchor) |-
              (.child anchor)\forestoption{edge label};
            },
          },
        }{}%
      },
  }
  [\faFileText~Main.lp
    [\faFileTextO~chunck\_1..N
      [\faFileText~definitions.lp]
    ]
    [\faFileTextO~Chunck\_N..N+$k$
      [\faFileText~Definitions.lp
        [\faFileTextO~Axioms\_1..N.lp ]
      ]
    ]
    [$\dots$]
    [\faFileTextO~Chunck\_M..M'+$k$
      [\faFileText~Definitions.lp
        [\faFileTextO~Axioms\_1..N.lp
            [ \faFileTextO~Axioms\_N..N+$k$.lp
              [$\dots$] ]
        ]
      ]
    ]
  ]
\end{forest}
}
\caption{Parallel translation and checking.}
\label{fig:parallel-check}
\end{figure}

\section{Parallel reconstruction and checking optimizations}
\label{ssec:parallel}


\paragraph{Parallel checking.}

Translating proof traces with several thousand steps can yield Lambdapi files so large that type checking becomes unwieldy.
Lambdapi is not yet optimized for very large files \cite[\S 4]{blanqui:hal-04613926}, and checking may take minutes or even hours.
To accelerate the verification, we exploit parallelism across CPU cores.
The key observation is locality: translating step $k$ of Alethe proof does not require knowledge of any future step $k' > k$.
The only global constraint is ordering in the final build: the translation that defines the evidence for step $k$ must be available before any file that uses it.

As sketched in \cref{fig:parallel-check}, we partition the trace into fixed-size chunks of $k$ consecutive steps and translate each chunk independently.
For every chunk $[N..M]$ we generate two files: one file with lemmas and their proofs (\tt{Chunk\_N..M.lp}), and one with the same statements declared as axioms (\tt{Axioms\_N..M.lp}) to be imported by later chunks.
Each \tt{Chunk\_N..M.lp} depends on \tt{definitions.lp} and on prior \tt{Axioms\_*.lp} files as required.
A main file (\tt{main.lp}) then includes the chunk files in order.

With these dependency edges in place, the project can be built in parallel using \texttt{make -jN}, which checks independent chunk files concurrently.
We do not yet perform a final ``gluing'' pass that eliminates the axioms by substituting the corresponding proved lemmas, but this is unnecessary for checking correctness.
Such a post-processing step would be needed only if one intends to reuse the resulting proof objects for further developments.

\paragraph{Term sharing.}
In addition, to reduce the memory usage and checking time of Lambdapi, we define a constant for any closed subterm that is used more than three times in the Alethe proof trace.
This is similar to the behavior of SMT \kw{:named} attribute of SMT-LIB used by solvers with \lstinline|--dag-thresh N| dagify common sub expressions appearing more than N times.
However, this can make proof reconstruction more difficult because \lpinline{rewrite} tactics may need to unfold these definitions.


\section{Evaluation FOL}
\label{sect:evaluation-fol}

\begin{table}[t]
\centering
{%
\scriptsize
\pgfplotstabletypeset[
  font=\ttfamily,
  col sep=comma,
  every even row/.style={
    before row={\rowcolor[gray]{0.9}}},
  every head row/.style={
    before row=\toprule,after row=\midrule},
  every last row/.style={
    after row=\bottomrule},
  columns={name,benchmark_type, cvc5_count,cvc5_results, elaboration_results},
  columns/name/.style={string type,column name={Name}},
  columns/benchmark_type/.style={string type, column name={Logic}},
  columns/cvc5_count/.style={column name={Samples}},
  columns/cvc5_results/.style={string type, column name={cvc5}},
  columns/elaboration_results/.style={string type, column name={Carcara}},
]{Assets/benchs/pass.csv}%
}
\caption{
  Summary of benchmark.\\
  The format $S-F-T$ indicates respectively the number of success (S), failed (F) and timeout (T) samples.
} 
\label{tab:benchmarks}
\end{table}


\begin{table}[t]
\centering
{%
\scriptsize
\pgfplotstabletypeset[
  font=\ttfamily,
  col sep=comma,
  every even row/.style={
    before row={\rowcolor[gray]{0.9}}},
  every head row/.style={
    before row=\toprule,after row=\midrule},
  every last row/.style={
    after row=\bottomrule},
  columns={name,translate_small_results, lambdapi_small_check_results, translate_large_results, lambdapi_large_check_results},
  columns/name/.style={string type,column name={Name}},
  columns/translate_small_results/.style={string type, column name={Translate}},
  columns/translate_large_results/.style={string type, column name={Translate XL}},
  columns/lambdapi_small_check_results/.style={string type, column name={Check}},
  columns/lambdapi_large_check_results/.style={string type, column name={Check XL}},
]{Assets/benchs/pass.csv}%
}
\caption{
  Translation and checking results.\\
  The format $S-F-T$ indicates respectively the number of success (S), failed (F) and timeout (T) samples.
} 
\label{tab:benchmarks-translate-check}
\end{table}

\begin{table}[t]
\centering
{%
\scriptsize
\pgfplotstabletypeset[
  col sep=comma,
  font=\ttfamily,
  every even row/.style={
    before row={\rowcolor[gray]{0.9}}},
  every head row/.style={
    before row=\toprule,after row=\midrule},
  every last row/.style={
    after row=\bottomrule},
  columns={name,weighted_mean_time,min_lp,q1_lp,median_lp,q3_lp,max_lp},
  columns/name/.style={string type},
  columns/weighted_mean_time/.style={column name={Mean}},
  columns/min_lp/.style={column name={Min}},
  columns/q1_lp/.style={column name={Q1}},
  columns/median_lp/.style={column name={Median}},
  columns/q3_lp/.style={column name={Q3}},
  columns/max_lp/.style={column name={Max}},
]{Assets/benchs/pass.csv}%
}
\caption{Lambdapi checking times (in ms).} 
\label{tab:benchmarks-times}
\end{table}



% https://tex.stackexchange.com/questions/399163/create-boxplots-from-file
% https://tex.stackexchange.com/questions/117435/read-boxplot-prepared-values-from-a-table/117439#117439
\pgfplotsset{
    boxplot prepared from table/.code={
        \def\tikz@plot@handler{\pgfplotsplothandlerboxplotprepared}%
        \pgfplotsset{
            /pgfplots/boxplot prepared from table/.cd,
            #1,
        }
    },
    /pgfplots/boxplot prepared from table/.cd,
        table/.code={\pgfplotstablecopy{#1}\to\boxplot@datatable},
        row/.initial=0,
        make style readable from table/.style={
            #1/.code={
                \pgfplotstablegetelem{\pgfkeysvalueof{/pgfplots/boxplot prepared from table/row}}{##1}\of\boxplot@datatable
                \pgfplotsset{boxplot/#1/.expand once={\pgfplotsretval}}
            }
        },
        make style readable from table=lower whisker,
        make style readable from table=upper whisker,
        make style readable from table=lower quartile,
        make style readable from table=upper quartile,
        make style readable from table=median,
        make style readable from table=lower notch,
        make style readable from table=upper notch
}
\makeatother


\pgfplotstableread[col sep=comma]{Assets/benchs/passtime.csv}\datatable

\pgfplotstablegetrowsof{\datatable}
\pgfmathtruncatemacro{\NumRows}{\pgfplotsretval} % total number of rows

% Put this in the preamble or before the figure:
\pgfplotscreateplotcyclelist{benchcolors}{%
  {draw=rxpurple, fill=rxpurple!10},
  {draw=rxpink, fill=rxpink!10},
  {draw=darkpurple, fill=darkpurple!10},
  {draw=midpurple,  fill=midpurple!10},
  {draw=purple2,    fill=purple2!10},
  {draw=RoyalBlue,  fill=RoyalBlue!10},
  {draw=black,      fill=black!10},
  {draw=MidnightBlue,  fill=MidnightBlue!10},
}

\begin{figure}[t]
\begin{tikzpicture}
\begin{axis}[
  width=0.9\textwidth,
  boxplot/draw direction=x,
  cycle list name=benchcolors,
  ytick={1,...,\NumRows},
  yticklabels from table={\datatable}{acronym},
  yticklabel style={font=\scriptsize\ttfamily},
  xmode=log,
  log basis x=10,
  xlabel={Checking time (ms), $\log(1 + t)$ scale},
  xlabel style={ font=\ttfamily },
  ylabel={Benchmarks},
  ylabel style={ font=\ttfamily },
  legend cell align={left},
  legend style={
    font=\ttfamily\scriptsize,
    at={(0.5,-0.25)},
    anchor=north,
    % draw=none, % optional: no box around legend
  },
  legend columns=2,
]
% \pgfplotstablegetrowsof{\datatable}
\pgfmathtruncatemacro\TotalRows{\NumRows-1}
\pgfplotsinvokeforeach{0,...,\TotalRows}
{
  \addplot+[
  boxplot prepared from table={
    table=\datatable,
    row=#1,
    lower whisker=min,
    lower quartile=q1,
    upper quartile=q3,
    upper whisker=max,
    median=median
  },
  boxplot prepared,
  area legend
  ] coordinates{};

    % --- single point at lt for this sample ---
  \pgfplotstablegetelem{#1}{mean}\of\datatable
  \pgfmathsetmacro{\meanvalue}{\pgfplotsretval} % x = lt
  \pgfmathtruncatemacro{\cat}{#1+1}           % y = 1,2,3,... (row index)

  \addplot+[
    only marks,
    mark=*,
    mark size=1.2pt,
    forget plot,    % do not create legend entries for every point
  ] coordinates {(\meanvalue,\cat)};


  % \pgfplotstablegetelem{#1}{name}\of\datatable
  % \addlegendentryexpanded{\pgfplotsretval}
  % \pgfplotstablegetelem{#1}{acronym}\of\datatable
  % \edef\thisacro{\pgfplotsretval}
    % --- legend entry: name(acronym) ---
  \pgfplotstablegetelem{#1}{name}\of\datatable
  \edef\thisname{\pgfplotsretval}
  \pgfplotstablegetelem{#1}{acronym}\of\datatable
  \edef\thisacro{\pgfplotsretval}
  \addlegendentryexpanded{\thisname\;(\thisacro)}
}
\end{axis}
\end{tikzpicture}
\label{fig:benchmarks-times-boxplot}
\caption{Lambdapi checking time variations between samples}
\end{figure}

The boxes are plotted as $log(1 + time)$ to make them comparable. The mean is indicated by a dot.

% \subsection{Benchmarks}

% Our benchmark \cref{tab:benchmarks-description} is composed of files from the SMT-LIB benchmarks\footnote{\url{https://smtlib.cs.uiowa.edu/benchmarks.shtml}} of \kw{QF\_UF} and \kw{UF} theories, and additional proof obligations from the SMT backend of the TLAPS proof system.
% Our work is aimed at reconstructing proofs found by SMT solvers called by proof assistants such as Coq, Isabelle, Rodin or TLAPS. One particular goal of our development is the reconstruction of theorems expressed in the set theory of TLA\textsuperscript{+} (i.e., not involving temporal logic) in Lambdapi.
% TLA\textsuperscript{+} \cite{lamport:specifying} is a language based on set theory and linear-time temporal logic for formally specifying and verifying systems, particularly concurrent and distributed algorithms.
% Its interactive proof environment TLAPS \cite{tla-proofs} relies on users guiding the proof effort; it integrates automatic backends, including SMT solvers, to discharge proof obligations \cite{smttlaps, ABZrosalie}. TLAPS encodes set theory as \kw{UF} constraints, which makes this SMT-LIB theory an attractive target for our work. Support of arithmetic reasoning is left as future work.

% \begin{table}%[tb]%[H]
%     \begin{tabular}{|l c c c c c c|}
%     \hline
%     Name & Logic & Samples & Steps & Elaborated & Translated & Checked \\
%     \hline
%     sledgehammer & UF & 1403 & 1/143/2301 & 1226 & 1209 & 994 \\
%     allocator & UFNIA & 38 & 5/107/810 & 38 & 38 & 38 \\
%     eq\_diamond & QF{\_}UF & 100 & 9/686/3579 & 100  & 100 & 74 \\
%     2018-Goel-hwbench & QF{\_}UF & 229 & 12/166/83149 & 213 & 192 & 160\\
%     EWD840 & UFNIA & 19 & 9/140/1000 & 19 & 19 & 11 \\
%     20170829-Rodin & QF{\_}UF & 20 & 1/13/107 &  20 & 20 & 16\\
%     \hline
%     \end{tabular}
%     \caption{Benchmark samples.}
%     \label{tab:benchmarks-description}
% \end{table}

% We therefore chose samples related to proof assistants in the SMT-LIB benchmarks, e.g. Sledgehammer, and we have two benchmarks from TLA\textsuperscript{+} community modules.
% The Allocator module \cite{allocator} is a case study for the specification and analysis of reactive systems in TLA\textsuperscript{+}. EWD840 \cite{ewd840} formalizes a termination detection algorithm for distributed computations due to Dijkstra.

% \cref{tab:benchmarks-description} contains the details and results of each group of benchmarks.
% The column \emph{Samples} describes the number of problems available with status \emph{unsat}. 
% The column \emph{Steps} indicates the smallest, average and largest number of steps that appear in the proof traces of the samples in the group, excluding \kw{assume} steps.
% For example, the \emph{2018-Goel-hwbench} collection contains proof traces varying between 12 to 83149 steps, with 166 steps on average.
% We only reconstruct proof traces that can be handled by Carcara.
% The column \emph{Elaborated} indicates the number of proof traces checked and elaborated by Carcara.
% The column \emph{Translated} indicates the number of elaborated proof that can be translated into a Lambdapi proof.
% The remaining proof traces could not be reconstructed due to limitations in our current work, mainly due to unsupported Alethe commands.
% The column \emph{Checked} gives the number of proof traces for which a Lambdapi proof could be constructed.
% We did not impose a time restriction for the Carcara elaboration and our translation because that time is negligibly small.
% However, we set a timeout of 20 seconds for Lambdapi to check the proof.
% The parallel checking described in \cref{ssec:parallel} is used only on proof traces with more than 3000 steps (excluding \kw{assume}). 

% To evaluate the impact of elaboration on the proof size, we measured the number of steps of each proof before and after elaboration, as well as the number of steps of each relevant rule (namely \texttt{resolution}, \texttt{contraction} and \texttt{reordering}). \cref{tab:elaboration-impact} shows these results. The average number of steps increased moderately with elaboration, as did the fraction of \texttt{resolution} and \texttt{contraction} steps, which is an expected effect from the elaboration of \texttt{resolution} steps. As expected, all \texttt{reordering} steps were eliminated.

% \begin{table}%[tb]%[H]
%     \begin{tabular}{|l c c c c|}
%     \hline
%     & Average number of steps & \texttt{resolution} & \texttt{contraction} & \texttt{reordering} \\ \hline
%     Original   & 21093.89 & 18.39 \% & 3.31 \% & 3.61 \% \\
%     Elaborated & 26160.01 & 20.82 \% & 6.53 \% & 0.00 \% \\
%     \hline
%     \end{tabular}
%     \caption{Average number of steps before and after elaboration, and the proportion of these steps that use each of the relevant rules.}
%     \label{tab:elaboration-impact}
% \end{table}

% The boxes in \cref{fig:benchmarks-graph} are plotted as $log(1 + time)$  to make them comparable. But in y-axis we present the original values of $time$ for readability.
% In \cref{tab:benchmarks-times} and \cref{fig:benchmarks-graph}, we can observe that the majority of reconstructed proofs can be checked by Lambdapi in a few milliseconds and less than 3 seconds (red line in \cref{fig:benchmarks-graph}).
% %We intend to include our work in proof assistants such as TLAPS, so we seek a tolerable reconstruction time. 
% Some samples cannot be reconstructed because some simple deduction and RARE rules are not yet implemented. 
% Other samples cannot be reconstructed because some rules that expect a number of parameters such as $\kw{cong}_n$ or $\kw{subproof}_n$  are not yet defined, for example
% samples in $\kw{eq\_diamond}$ failed because the lemma $\kw{subproof\_98}$ is not defined. We are considering to review this rule to make it scale.
% Moreover, nested \kw{bind} rules can make the proof reconstruction fail in EWD840 or 2018-Goel-hwbench because there is a naming collision with fresh variables introduced in the context. We plan to fix this problem by reviewing our generation of variable names.
% We should be able to increase the number of proofs reconstructed in these categories with little effort.
% Some RARE rules failed to reconstruct because Lambdapi is not able to infer some implicit arguments. We have to modify the proof generated by giving explicitly some arguments.
% Concerning the large proofs in 2018-Goel-hwbench, use of the technique described in \cref{ssec:parallel} allows us to reconstruct some, but not all parts of the proof, and we consider it a failed case.
% Although these do not appear in \cref{fig:benchmarks-graph} and \cref{tab:benchmarks-times}, we have been able to manually adjust some large proofs (of 10-30k lines) and have them checked within 2 seconds with parallel processing.
% For benchmarks using the LIA (sub-)logic, we only reconstruct those proof steps where arithmetic reasoning does not play an essential role (beyond simplification).
% Some samples take more than 3 seconds to be certified. We suspected, and this has been confirmed by the authors of Lambdapi, that there is a bottleneck in the unification of AC terms.

% \begin{figure}
%     \centering
%     \begin{tikzpicture}
%     \begin{axis}[
%         xtick={1,2,3,4,5,6},
%         yticklabels={0, 0.50, 2, 4, 10},
%         ytick={0, 0.17, 0.5, 0.7, 1.04},
%         xticklabels={sledge, alloc, eq, goel, ewd, rodin},
%         ylabel={Time (s)},
%         boxplot/draw direction=y,
%         /pgfplots/boxplot/box extend=0.3
%         ]
%         % Sledge
%         \addplot+ [boxplot prepared={lower whisker=0.055, lower quartile=0.094, median=0.178,
%         upper quartile=0.397, upper whisker=2.825},] table[row sep=\\,y index=0] {\\};
    
%         % Alloc
%         \addplot+ [boxplot prepared={lower whisker=0.055, lower quartile=0.065, median=0.138,
%         upper quartile=0.343, upper whisker=2.075},] table[row sep=\\,y index=0] {\\};
    
%         % Eq
%         \addplot+ [boxplot prepared={lower whisker=0.055, lower quartile=0.108, median=0.180,
%         upper quartile=0.291, upper whisker=1.1448},] table[row sep=\\,y index=0] {\\};
    
%          % Goel
%          \addplot+ [boxplot prepared={lower whisker=0.057, lower quartile=0.065, median=0.069,
%          upper quartile=0.119, upper whisker=1.012},] table[row sep=\\,y index=0] {\\};
    
%         % Ewd
%         \addplot+ [boxplot prepared={lower whisker=0.058, lower quartile=0.078, median=0.086,
%         upper quartile=0.110, upper whisker=0.925},] table[row sep=\\,y index=0] {\\};
    
%         % Rodin
%         \addplot+ [boxplot prepared={lower whisker=0.053, lower quartile=0.055, median=0.057,
%         upper quartile=0.060, upper whisker=0.076},] table[row sep=\\,y index=0] {\\};
    
%         \draw[red] (axis cs:0,0.6) -- (axis cs:7,0.6); % Comfort line
%     \end{axis}
%     \end{tikzpicture}
%     \caption{Checking time variations between samples.}
%     \label{fig:benchmarks-graph}
% \end{figure}

% \begin{table}%[tb]%[H]
%     \begin{tabular}{|l c c c c c |}
%     \hline
%     Name & Min & Q1 & Mean & Q3 & Max \\
%     \hline
%     sledgehammer & 56 & 98 & 195 & 487 & 15853  \\
%     allocator & 56 & 67 & 148 & 408 & 6967 \\
%     eq\_diamond & 57 & 114 & 196 & 337 & 3254 \\
%     2018-Goel-hwbench & 58 & 66 & 71 & 126 & 1751 \\
%     EWD840 & 59 & 81 & 89 & 116 & 1522  \\
%     20170829-Rodin & 54 & 56 & 58 & 61 & 79  \\
%     \hline
%     \end{tabular}
%     \caption{Lambdapi checking times in milliseconds.}
%     \label{tab:benchmarks-times}
% \end{table}


% Our work revealed that some proof obligations in Allocator initially failed to be reconstructed. In fact, the proof trace found by the SMT solver became incorrect after elaboration by Carcara. This allowed us to detect multiple bugs in the Carcara elaborator, which have since been corrected.
% Moreover, one reconstruction failure was due to one of the set theory axioms of TLA\textsuperscript{+} being incorrectly encoded in SMT, and this issue has also been fixed.
% Compared to our previous work \cite{ColtellacciMD24}, we have been able to significantly increase the number of proofs that can be reconstructed, as well as the efficiency of reconstruction.




% \section{Evaluation LIA}
% \label{sec:evaluation-lia}

% \begin{table}[t]
% \centering
% \begin{tabular}{|c|c|c|c|c|c|c|}
% \hline                                                             % Succ - Err -Timeout   % Succ - Error        % Succ - Err - Timeout % Succ - Err - Timeout
% \textbf{Logic}                & \textbf{Bench}  & \textbf{Samples} & \textbf{Proofs}       & \textbf{Elaborate} & \textbf{Translate} & \textbf{Check} \\ \hline
% \multirow{4}{*}{\tt{LIA}}     & tptp            & 36               &  36 - 0 - 0           &  36 - 0             & 36 - 0 - 0          & 28 - 8 - 0       \\ \cline{2-7} 
%                               & Ultimate        & 153              &  120 - 0 - 33         &  73 - 80            & 68 - 5 - 0          & 50 - 18 - 0      \\ \cline{2-7} 
%                               & Svcomp'19      & 27               &  27 - 0 - 0           &  25 - 2             & 0 - 25 - 0          & 0                \\ \cline{2-7} 
%                               & psyco           & 50               &  48 - 0 - 2           &  48 - 2             & 43 - 0 - 5          & 0 - 39 - 6       \\ \hline
% \multirow{2}{*}{\tt{QFLIA}}   & SMPT            & 1568             &  1501 - 67 - 0        &  1491 - 32          & 1470 - 0 - 21       & 804 - 638 - 34   \\ \cline{2-7}
%                               & rings           & 294              &  63 - 0 - 231         &  49 - 21            & 49 - 0 - 0          & 7 - 0 - 42       \\ \cline{2-7} 
%                               & CAV2009       & 85               &  85 - 0 - 0           &  19 - 0             & 19 - 0 - 0          & 19 - 0 - 0       \\ \hline
% \multirow{2}{*}{\tt{UFLIA}}   & sledgeh    & 1521             &  1343 - 0 - 178       &  1278 - 222         & 1258 - 13 - 7       & 713 - 467 - 80   \\ \cline{2-7} 
%                               & tokeneer        & 1732             &  1732 - 0 - 0         & 1689 - 43           & 1689 - 0 - 0        & 1482 - 197 - 10  \\ \hline
% \end{tabular}
% \caption{Benchmark results.}
% \label{table:benchmarks-description}
% \end{table}

% Our benchmark suite, \cref{table:benchmarks-description} is composed of files from the SMT-LIB benchmarks\footnote{\url{https://smtlib.cs.uiowa.edu/benchmarks.shtml}}.
% The suite includes a total of 5,466 samples drawn from 9 benchmarks spanning 3 SMT-LIB logics: \texttt{LIA}, \texttt{QFLIA}, and \texttt{UFLIA} that correspond to those covered by our method.
% %These were selected because our previous work supported the \texttt{QF} and \texttt{UF} fragments.
% Within the logics \texttt{QFLIA} and \texttt{UFLIA}, we prioritized benchmarks with the most significant number of available samples.
% Table~\ref{table:benchmarks-description} provides a detailed breakdown of the benchmarks and corresponding results.
% The \emph{Logic} column indicates the SMT theory used, while the \emph{Bench} column lists abbreviated benchmark names.
% The column \emph{Samples} describes the number of problems available with status \emph{unsat}. 
% Each of the columns \emph{Proofs}, \emph{Translate}, and \emph{Check} reports a triple in the format \tt{success - error - timeout}, representing respectively the number of successful executions, failed attempts, and timeouts. 
% The \emph{Proofs} column reports the number of proofs generated by cvc5\footnote{cvc5 version 1.2.1-dev.144.38fcc340e5 [git 38fcc340e5 on branch main]} that do not contain \lstinline[language=SMT,basicstyle=\ttfamily\footnotesize]|to_real| cast operator.
% The \emph{Elaborate} column shows a pair of values: the number of proofs that were successfully elaborated by Carcara, and the number that failed. Only proofs successfully elaborated by Carcara are considered for translation.
% The \emph{Translate} column gives the number of proof traces successfully translated into Lambdapi proofs, while the \emph{Check} column indicates the number of these translated proofs that were successfully type-checked by Lambdapi. 

% We enforced a timeout of 30 seconds for cvc5 to find a proof and 30 seconds for the translation step with Carcara.
% No timeout was imposed during the elaboration step, as the runtime is negligible.
% A timeout of 20 seconds was set for Lambdapi when type-checking the final proofs to ensure that proof verification remains as fast as possible.\footnote{All benchmarks were executed in parallel using GNU parallel \cite{tange_2025_15071920} with an Apple silicon M2.} % Ask by the tool to be cited

% All nine benchmarks demonstrated consistently reliable proof generation, with few or no timeouts, except for the \emph{rings} benchmark.
% The elaboration phase was generally robust, except in the \emph{Ultimate} benchmark, where an error in the elaborator caused failures.
% For \texttt{LIA}, performance in the translation and checking stages was mixed. In particular, for \emph{Svcomp'19} and \emph{psyco}, no or few proofs could be translated or verified, mainly due to currently unsupported simplification rules involving the \texttt{ite} operator.
% The \texttt{QFLIA} benchmarks exhibited more reliable proof checking in \emph{SMPT} and \emph{CAV2009}, while only a small number of proofs from the \emph{rings} benchmark were successfully checked.
% The errors encountered during the elaboration of the \emph{CAV2009} come from a bug in the elaborator. Since the samples in this benchmark are derived from a common base problem while increasing in size, the bug propagated across all samples that depend on the same base instance.
% For \emph{rings}, this limitation is due to the presence of \texttt{la\_generic} terms with hundreds of uninterpreted variables; the current normalization mechanism, described in \cref{ssec:normalization}, relies on a built-in term ordering that is not sufficiently efficient in this setting.
% Benchmarks under \texttt{UFLIA} performed better throughout the pipeline. Most proofs were successfully generated and elaborated, and a large portion were translated and verified by Lambdapi, particularly in the \emph{tokeneer} dataset.
% The higher number of errors in \emph{SMPT} and \emph{sledgeh} is primarily due to unsupported RARE rules related to \tt{QF\_UF} logic, as well as unhandled cases in the \texttt{evaluate} rule for \texttt{LIA} and \texttt{QF\_UF}.

% \begin{table}[t]
% \centering
% \begin{tabular}{|c|c|c|c|c|c|}
% \hline
% \textbf{Bench}      & \textbf{Min} & \textbf{Q1} & \textbf{Mean} & \textbf{Q3} & \textbf{Max} \\ \hline
% tptp                & 240          & 262         & 263           & 267         & 336          \\ \hline
% Ultimate            & 82           & 96          & 100           & 111         & 346          \\ \hline
% SMPT                & 52           & 55          & 55            & 56          & 293          \\ \hline
% rings               & 670          & 704         & 773           & 826         & 1197         \\ \hline
% CAV2009           & 54           & 296         & 403           & 498         & 683          \\ \hline
% sledgeh             & 53           & 166         & 354           & 552         & 1594         \\ \hline
% tokeneer            & 55           & 60          & 61            & 248         & 753          \\ \hline
% \end{tabular}
% \caption{Lambdapi checking times in milliseconds.}
% \label{table:benchmarks-list}
% \end{table}

% Table~\ref{table:benchmarks-list} reports the Lambdapi proof-checking times in milliseconds, presenting the minimum, first quartile (Q1), mean, third quartile (Q3), and maximum durations for each benchmark.
% In most cases, the checking time remains below one second.
% % , with the exception of a few outliers particularly in the \emph{sledgehammer} and \emph{rings} benchmarks that exhibit higher upper tails.

% \section{Validating \tlaplus SMT proof}
% \label{sec:tla-eval}

% Following our approach, we collect the Alethe proof produced by the SMT solver and reconstruct it in Lambdapi.
% However, we do not currently re-integrate the reconstructed proof back into \tlaplus.
% Supporting this step would be important to ensure that the reconstruction indeed corresponds to the original theorem stated in \tlaplus, particularly because the SMT encoding produced by the backend has not yet been fully formalized.
% Moreover, since the SMT solver performs \emph{skolemization} during preprocessing, recovering the original problem would require an additional \emph{deskolemization} phase \cite{desko}.
% In the absence of this feedback mechanism, the reconstruction provides an additional but still partial layer of assurance.


% \subsection{Reconstruction integrated to the Toolbox}
% \label{ssec:tlaps-toolbox}

% TODO

% \subsection{Evaluation of TLAPS reconstruction}
% \label{ssec:tlaps-evaluation-results}

% TODO