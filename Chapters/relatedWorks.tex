%*****************************************
\chapter{Related Works}\label{ch:relatedworks}
%*****************************************

\section{The Eunoia proof format}
Eunoia is a ongoing development of a logical framework that provides a formally defined language for representing proof systems and serves as the specification basis for the recently introduced Cooperating Proof Calculus (CPC) employed by the SMT solver cvc5.
%
\footnote{See \url{https://cvc5.github.io/docs/cvc5-1.2.1/proofs/output_cpc.html}. A complete
list of the proof rules in CPC can be found at \url{https://cvc5.github.io/docs/cvc5-1.
2.1/api/cpp/enums/proofrule.html}. The semantics of the rules is also defined in the
Eunoia logical framework, described in the user manual of the Ethos proof checker:
\url{https://github.com/cvc5/ethos/blob/main/user_manual.md}.}
%
It is grounded in the SMT-LIB $3$  standard \footnote{\url{https://smt-lib.org/version3.shtml}}, which generalizes and extends the widely adopted SMT-LIB $2$ language in order to support higher-order logic with polymorphism and dependent types but classical semantics.
The current general syntax for dependent types is:
\begin{lstlisting}[language=Eunoia,numbers=none]
(→ (! A :var x) B) 
\end{lstlisting}
The symbol $\ra$ will denote the function type constructor, where \tt{x} is a bound variable whose scope is \tt{B}. This syntax can be understood as an abbreviation of the $\lambda\Pi$ type or kind $\Pi\,x:A, B$.

In spirit, Eunoia is comparable to the \emph{Alethe} proof format.
However, while Alethe primarily aims to provide a standardized exchange format for SMT solver proofs, Eunoia is conceived as a more general logical framework in which proof systems can be defined, extended, and modularly verified.
Unlike Alethe, which relies on a predefined set of proof rules, Eunoia allows users to define their own custom rules using the \smtinline{declare-rule} command, offering greater flexibility and extensibility in proof construction.
For example:

\begin{lstlisting}[label={lst:eunoia},caption={An Eunoia proof example},language=Eunoia]
(declare-parameterized-const = ((T Type :implicit)) (→ T T Bool))
(declare-rule symm ((T Type) (t T) (s T))
    :premises ((= t s))
    :conclusion (= s t))
(declare-type Int ())
(declare-const a Int)
(declare-const b Int)
(assume @p0 (= a b))
(step @p1 (= b a) :rule symm :premises (@p0))
\end{lstlisting}

The rule \smtinline{symm} (at line 2) specifies symmetry of equality. This rule takes as premise an equality \smtinline{(= t s)} and no arguments.
In detail, an application of this proof rule for premise proof \smtinline{(= a b)} for concrete terms $a,b$ will compute the substitution $[t \mapsto a, s \mapsto b]$ and apply it to the conclusion term to obtain \smtinline{(= b a)}.
The Eunoia proof format follows a structure that is almost identical to that of Alethe (\smtinline{assume}, \smtinline{step}) as we can observe lines 8 and 9.

The \cref{lst:eunoia} shows an example of an Eunoia proof script. Line 1, a polymorphic binary predicate $=$ is declared.
The proof rule \tt{symm} (lines 2 to 5) is then defined to capture the symmetry property of equality: if \smtinline{t = s}, then \smtinline{s = t}.
Following this, an integer type \smtinline{Int} (line 6) and two integer constants, \tt{a} and \tt{b}, are declared (lines 7,8).
The proof begins line 8 by assuming the equality of \tt{a} and \tt{b}, labelled as \smtinline{@p0}.
Finally, at line 9, the symmetry rule \tt{symm} is applied to derive the equality of \tt{b} and \tt{a}, labelled as \smtinline{@p1}, using the assumption \smtinline{@p0} as the premise.
This concise proof demonstrates Eunoia's capability to formally represent and verify basic properties of equality, highlighting its support for polymorphic types and structured proof rules.

Recent work\footnote{https://github.com/cvc5/AletheInEunoia} has focused on embedding the Alethe proof format within Eunoia, ensuring backward compatibility and enabling users to leverage existing Alethe proofs in the more general Eunoia framework.

\section{Proof reconstruction for hammers}

Several proof assistants employ \emph{hammers} for discharging goals to ATPs, including SMT solvers. Examples include Sledgehammer \cite{Sledgehammer} for Isabelle/HOL and CoqHammer \cite{coqhammer1,coqhammer2} for Coq.
The hammer translates the conjecture and facts supplied by the user or harvested
from the context to the input language of the back-end, invokes it, and in the
case of success attempts to reconstruct the proof in the logic of the proof
assistant, based on a trace of the proof found by the back-end.

This process can benefit significantly from detailed proofs by the back-ends.
For example, adoption by Sledgehammer of the Alethe format generated by the SMT solver veriT \cite{isabelle1,isabelle2} cut the failure rate of reconstruction by 50\%.
According to Sledgehammer benchmarks, proof reconstruction now succeeds in over 90\% of cases \cite{verit-recon, SledgehammerReconImprove}, a substantial improvement over previous formats.
Across other formalizations, including the Prime Number Theorem and Simplex algorithm, the failure rate was reduced by 56\% to 63\%, consistently enhancing the reliability of the proof reconstruction pipeline.
The introduction of fine-grained proof formats and optimized solver strategies not only increased the number of automatically reconstructed proofs but also reduced the total reconstruction time by up to 15\%.
These results encouraged us to base our approach on the Alethe trace format.

In Sledgehammer, the reconstruction procedure uses the RARE framework with IsaRare \cite{IsaRare}, a tool that can automatically translate RARE rules into Isabelle/HOL lemmas.
For arithmetic steps, it uses Isabelle's procedure \tt{linarith}. This tactic is a decision procedure for real numbers, but not for integers or natural numbers.
Internally, it uses the Fourier–Motzkin elimination \cite{linear-arith-book}: it derives a contradiction via a linear combination of the equations.

In CoqHammer, proof reconstruction is performed by an \emph{auto}-type algorithm implemented in Ltac \cite{ltac}.
The proof search procedure does primarily backward Prolog-style reasoning modifying the goal by applying hypotheses from the context.
The core of the search procedure may be seen as an extension of the Ben-Yelles algorithm to first-order intuitionistic logic with all connectives \cite{urzyczyn_intuitionistic_2016}.
The proof reconstruction procedure is augmented with  the use of existential metavariables like in \tt{eauto}, a looping check, some limited forward reasoning, the use of the \tt{congruence tactic}, and heuristic
rewriting using equational hypotheses.
CoqHammer is typically evaluated on a benchmark consisting of 4841 lemmas from the Coq standard library and the Mathematical Components library, which serves as the standard benchmark for hammering in Coq.
The reconstruction mechanism currently is able to re-prove only 85.2\% (4215 out of 4841) of the proofs founds by the ATPs.
It is capable of re-proving over 40\% of Coq standard library lemmas.

\section{SMT integration in proof assistants}

In contrast to Hammers, which are designed to interface with general-purpose automated theorem provers (ATPs) such as Vampire \cite{vampire}, E Prover \cite{eprover}, or SMT solvers \cite{z3}, other approaches establish direct connections between proof assistants and SMT solvers.  
For instance, SMTCoq \cite{smtcoq} and Lean-SMT \cite{lean-smt} integrate Coq and Lean, respectively, with external SAT and SMT solvers, thereby leveraging the theory reasoning capabilities of SMT solvers that are not fully exploited by Hammers.

\paragraph{SMTCoq} is a fully certified Coq plugin that checks proof witnesses coming from external SAT and SMT solvers. For proof reconstruction, SMTCoq relies on computational reflection: the certificate is directly processed by the reduction mechanism of Coq's kernel.
We initially attempted to convert the SMTCoq proof certificate to Lambdapi. However, we found the proof term generated by computational reflection, including subterms corresponding to arithmetic decision procedures in Micromega \cite{micromega}, to be too complex to be converted to Lambdapi.
%
Moreover, SMTCoq is based on an old version of the Alethe proof format, which is only supported by older versions of the veriT solver.

\paragraph{Lean-SMT} is a tactic that provides SMT solver integration in the Lean proof assistant, similar to how SMTCoq integrates SMT solvers with Coq.
Lean-SMT operates by translating Lean proof goals into SMT-LIB problems and leveraging the proof-producing SMT solver cvc5 to generate proofs, which are then reconstructed as native Lean proofs.
Lean-SMT employs the Cooperating Proof Calculus (CPC) based on Eunoia.
Unlike SMTCoq, which employs a formally verified checker that validates entire SMT proofs within Coq, Lean-SMT uses a proof replay approach that reconstructs each individual proof step within Lean.
This choice was motivated by performance considerations: while Coq excels at efficient proof checking, Lean does not \cite{lean-perf}.
Additionally, the proof replay approach offers greater flexibility compared to SMTCoq's verified checker, as modifications to the supported proof format only require changes to the corresponding reconstruction tactics rather than re-proving the entire checker's correctness theorem.
Lean-SMT currently supports around 200 of cvc5's proof rules which amounts to approximately 30\%, and has been evaluated on both Sledgehammer benchmarks and SMT-COMP benchmarks, showing competitive performance with other proof checkers while maintaining a small trusted base.


\section{Proof Checkers for SMT Solvers}

\paragraph{Carcara} \cite{carcara} is an independent tool, implemented in Rust \cite{rust}, that acts as both a \emph{proof checker} and a \emph{proof elaborator} for SMT proof traces in the Alethe format.
As a proof checker, it ensures the correctness of proofs by validating each step against the logical rules, thus guaranteeing the soundness of the entire trace.
As a proof elaborator, it refines high-level or incomplete proofs into fully detailed, low-level versions by filling in implicit steps or normalizing terms.
Unlike certified checkers such as SMTCoq or Lean-SMT, Carcara supports the elaboration of coarse-grained proof traces—including implicit steps—into fine-grained ones, which can simplify verification in proof assistants.
This capability is particularly valuable for our work, as it compensates for the limited meta-programming support in Lambdapi’s vernacular language.

\paragraph{Ethos} is a proof checker currently under active development \footnote{\url{https://github.com/cvc5/ethos/tree/main}}, written in C++, designed to verify proofs produced in the Eunoia format.
Analogously, Ethos plays a role similar to that of Carcara, which provides an independent proof checker for SMT proofs.


\section{The Unverified Backend Problem in Formal Verification Tools}
\label{sec:problem-tlaps-proof}

Beyond the hammer and SMT integration approaches discussed,
we highlight formal verification tools that rely on SMT solvers for automation but lacks proof verification capabilities,
thereby presenting an opportunity to apply the reconstruction methods developed in this thesis.

\paragraph{The B method}

The B method \cite{Bmethod} has been increasingly adopted in the development of high-assurance software systems, particularly in safety-critical domains such as railways.
The verification of B models is facilitated by integrated development environments such as Atelier B \cite{AtelierB} and Rodin \cite{AbrialRodin}, which provide a unified framework for both system development and formal verification.
Proof obligations are systematically generated from B components and translated into machine-verifiable formats to be fed into automated solvers. 
In these environments, proof obligations are automatically generated from the B components and translated into machine-verifiable formulas for processing by automated solvers.
One class of such solvers is SMT solver, a dedicated backend \cite{DeharbeBSMT}, and its modern successor BEer \cite{Beer}, can encode B proof obligations into SMT.
However, while SMT solvers are effective at finding proofs, the correctness of the proofs they produce still requires independent verification to ensure complete trustworthiness.
In this context, we can see a direct application of the work presented in this thesis, as our reconstruction framework can serve as a foundation for certifying SMT proofs generated during the verification of B models.

\paragraph{\tlaplus and TLAPS}

\tlaplus is a specification language based on the Temporal Logic of Actions and Zermelo–Fraenkel set theory with the Axiom of Choice (ZFC) \cite{tlabook,tla-ref}.
It is particularly used for specifying concurrent and distributed systems.
The \tlaplus Proof System (TLAPS) extends the language with a formal proof syntax and a tactical proof language \cite{tla-proofs}.

TLAPS includes a \emph{Proof Manager} that decomposes proofs into individual proof obligations, which are then dispatched to various backend provers.
These currently include Isabelle/\tlaplus \cite{isabelle-hol-ref}, Zenon \cite{zenonmodulo},
the SMT solvers cvc5 \cite{cvc5}, veriT \cite{verit} and Z3 \cite{z3}, and finally the LS4 prover for temporal logic.
Each obligation is translated into the logic supported by the corresponding backend.
For SMT solvers \cite{new-encoding-tlaps}, the supported logics include \textbf{UF}, \textbf{LIA}, and \textbf{NIA}.
At present, TLAPS does not verify the correctness of solver outputs, except in the case of Zenon, whose proofs can be independently validated by Isabelle,
and in the case of Isabelle/\tlaplus backend.

The work that will be discussed in \cref{part:contributions}  can be leveraged to verify \tlaplus proofs from the SMT solver backend.
The proposed approach involves extracting the output generated by the SMT backend, retrieving the corresponding proof from cvc5 or veriT, and reconstructing it within Lambdapi to establish its validity.
 

\subsection*{Validating TLAPS proofs}
\label{sec:validating-tlaps-proof}

% -------------- MODULE Cantor1 -----------------
% THEOREM cantor ==
%   \A S :
%     \A f \in [S -> SUBSET S] :
%       \E A \in SUBSET S :
%         \A x \in S :
%           f [x] # A
% PROOF
%   <1>1. TAKE S
%   <1>2. TAKE f \in [S -> SUBSET S]
%   <1>3. DEFINE T == { z \in S : z \notin f[z] }
%   <1>4. WITNESS T \in SUBSET S
%   <1>5. TAKE x \in S
%   <1>6. QED BY x \in T \/ x \notin T
\begin{figure}[tb]
\centering
\begin{nomodule}
\topbar{Cantor}
\[\begin{noj}
  \THEOREM\ cantor\ \deq \\
  \A S : \\
  \quad \A f \in [S \rightarrow  \SUBSET\ S] : \\
  \quad\quad \exists A \in \SUBSET\ S : \\
  \quad\quad\quad \forall x \in S : \\
  \quad\quad\quad\quad f \sq{x}{} \mathbin{\#} A \\
  \ps{1}{1.}\ \textsc{take}\ S \\
  \ps{1}{2.}\ \textsc{take}\ f \in [S \rightarrow \SUBSET\ S]\\
  \ps{1}{3.}\ \textsc{define}\ T\ \deq\ \{ z \in S : z \notin f[z] \}\\
  \ps{1}{4.}\ \textsc{witness}\ T\ \in \SUBSET\ S \\
  \ps{1}{5.}\ \textsc{take}\ x \in S \\
  \ps{1}{6.}\ \QED\ \BY\ x \in T \lor x \notin T
\end{noj}\]
\bottombar
\end{nomodule}
\caption{Cantor theorem in \tlaplus}
\label{fig:cantor-tlaps}
\end{figure}

\tlaplus proofs are hierarchically structured and are generally written top-down.
The assertion that the Cantor theorem stating that no function ($f$) from a set ($S$) to its power set (\SUBSET\ $S$) can be surjective is formalized in \tlaplus as the theorem in \cref{fig:cantor-tlaps}.
Each proof in the hierarchy ends with a \QED\ step that asserts the proof's goal.
However, in \cref{fig:cantor-tlaps}, the proof is flat and concludes with a unique \QED\ step that asserts the proof's goal.
Proofs are incrementally decomposed into simpler subproofs across multiple levels. Each proof consists of labelled steps $\ps{i}{k.}$, that reflect their depth in the proof tree, where level $i$ indicates the nesting depth.
Steps may introduce assumptions, intermediate claims, or invoke previously proven results (with \BY), using TLAPS tactics such as \ASSUME/\PROVE\, \TAKE\ or \WITNESS.
The proof is completed when the root goal is reduced to a collection of leaf obligations marked as \QED\ and discharged by backend provers.

For each step $\ps{i}{k.}$ in \tlaplus proof, there is a set of proof obligations that has to be proved.
The obligation contains a context of known facts, definitions, declarations, and a goal.
Obligations are dispatched by the proof manager (PM) to the available backends (SMT solvers, Zenon, Isabelle/TLA) in a default order (SMT, Zenon, Isabelle) until one of them successfully proves the obligation.
In the case of \cref{fig:cantor-tlaps}, we will have 5 proof obligations ($\ps{1}{1} - \ps{1}{6}$ except $\ps{1}{3}$) that will be discharged to the backend.
For example, the proof obligation relative to the final step $\ps{1}{6.}$ is given as follows:

% ===============================================


% ;;	ASSUME NEW CONSTANT CONSTANT_S_,
% ;;	       NEW CONSTANT CONSTANT_f_ \in [CONSTANT_S_ -> SUBSET CONSTANT_S_],
% ;;	       NEW CONSTANT CONSTANT_x_ \in CONSTANT_S_,
% ;;	       CONSTANT_x_
% ;;	       \in {CONSTANT_z_ \in CONSTANT_S_ :
% ;;	              CONSTANT_z_ \notin CONSTANT_f_[CONSTANT_z_]}
% ;;	       \/ CONSTANT_x_
% ;;	          \notin {CONSTANT_z_ \in CONSTANT_S_ :
% ;;	                    CONSTANT_z_ \notin CONSTANT_f_[CONSTANT_z_]} 
% ;;	PROVE  CONSTANT_f_[CONSTANT_x_]
% ;;	       # {CONSTANT_z_ \in CONSTANT_S_ :
% ;;	            CONSTANT_z_ \notin CONSTANT_f_[CONSTANT_z_]}
\begin{figure}[tb]
\centering
\[\begin{noj}
  \quad\begin{noj2}
    \ASSUME & \textsc{new}\ \CONSTANT\ S, \\
            & \textsc{new}\ \CONSTANT\ f  \in [ S \ra \SUBSET\ S ], \\
            & \textsc{new}\ \CONSTANT\ X  \in S, \\
            & \quad X \in T \lor X \notin T \\
    \PROVE  & f[X] \neq T
  \end{noj2}
\end{noj}\]
\caption{Proof obligation of step  $\ps{1}{6.}$}
\label{fig:cantor-po}
\end{figure}

It assumes an arbitrary set $S$, a function $f \in [S \ra \SUBSET\ S]$, and an arbitrary element $X \in S$.
The goal is to prove that $f[X] \neq \{ z \in S \mid z \notin f[z] \}$.
This corresponds to the diagonalization step: given the definition $T \deq \{ z \in S \mid z \notin f[z] \}$ from $\ps{1}{3.}$, we aim to show that $T$ is not in the image of $f$.
To this end, we must show that for any $X \in S$, $f[X] \neq T$.
The assumption $X \in T \lor X \notin T$ provides a complete case split, and in either case, the assumption $f[X] = T$ leads to a contradiction, which suffices to discharge the proof obligation.


\smallskip

\lstinputlisting[language=SMT, caption={Proof obligation of step $\ps{1}{6.}$ in Cantor theorem},label={lst:cantor-smt}]{Assets/Cantor.smt2}

\smallskip

There would be 4 proof obligations that will be covered by the SMT solvers, and 2 by Zenon. 
The SMT backend of \tlaplus generates the corresponding SMT input problem presented in \cref{lst:cantor-smt}.
Since \tlaplus is based on ZFC which is untyped, the backend introduces a universal uninterpreted sort \tt{Idv} (line 2) to represent the domain of all values.
Within this setting,  the function symbol \tt{Mem} (line 3) denotes set membership ($\in$)  ,  while \tt{FunApp} (line 4) encodes function application (i.e. $f[x]$) .
The declared constant symbols \tt{S} and \tt{f} correspond to the set $S$ and function $f$ in the original proof.
The auxiliary function \tt{SetSt\_flatnd\_1} defines the diagonal set $T = \{ z \in S \mid z \notin f[z] \}$ by comprehension; this is specified by a universally quantified axiom stating that an element $X$ belongs to \tt{SetSt\_flatnd\_1 A} if and only if $X \in A$ and $X \notin f[X]$.
This axiom captures the definition of $T$ in a first-order setting.
The disjunctive assertion \tt{(or (Mem x ...) (not (Mem x ...)))} line 39 encodes a \emph{classical} reasoning by cases over whether $x$ belongs to $T$, reflecting how the proof splits based on $x \in T$ or $x \notin T$ in the original \tlaplus argument. 
Finally, the goal is asserted as the double negation of the equation \tt{(FunApp f x) = (SetSt\_flatnd\_1 S)}, encoded via a triggerable equality predicate \tt{TrigEq\_Idv}.
Triggers play a crucial role in optimizing the encoding, as discussed in \cite[\S3]{new-encoding-tlaps}.
%
This encoding faithfully mirrors the structure of the original \tlaplus proof obligation \cref{fig:cantor-po}.
We used the \textit{Cantor} example to illustrate the general approach taken to encode set-theoretic reasoning, as all proof obligations produced by the backend follow a similar structure.
Full details of the SMT encoding for \tlaplus are provided in \cite{new-encoding-tlaps}.

By leveraging the work presented in this thesis, we can establish a complete verification pipeline for TLAPS proofs as illustrated in \cref{"Complete Verification Pipeline for TLAPS Proofs"
}: the SMT solver proof traces can be elaborated using Carcara to produce detailed Alethe format proofs, which are then reconstructed in Lambdapi using our reconstruction framework to verify their correctness.
This approach would transform TLAPS from a partially verified proof assistant into a fully certified system where all SMT-backed proofs undergo rigorous verification, thereby enhancing the trustworthiness of TLA+ specifications and their proofs.

\begin{figure}
\begin{tikzpicture}[
    node distance=1,
    box/.style={rectangle, draw, minimum width=2cm, minimum height=0.8cm, align=center, font=\footnotesize},
    arrow/.style={->, >=Stealth, thick}
]
\node[box] (tlaps) {TLAPS};
\node[box, right=of tlaps] (cvc5) {cvc5};
\node[box, right=of cvc5] (carcara_elab) {Carcara/\\Elaboration};

\node[box, below=1.5cm of carcara_elab] (carcara_recon) {Carcara/\\Reconstruction};
\node[box, left=of carcara_recon] (lambdapi) {Lambdapi};

% Draw arrows
\draw[arrow] (tlaps) -- (cvc5);
\draw[arrow] (cvc5) -- (carcara_elab);
\draw[arrow] (carcara_elab) -- (carcara_recon);
\draw[arrow] (carcara_recon) -- (lambdapi);
\end{tikzpicture}

\caption{Complete Verification Pipeline for TLAPS Proofs}
\label{"Complete Verification Pipeline for TLAPS Proofs"
}
\end{figure}